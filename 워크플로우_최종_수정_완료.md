# 워크플로우 최종 수정 완료 보고서

## 📋 사용자 요구사항 워크플로우

```
start (채팅 인풋)
    |
--- LLM 판별 ---
|                |
[자료 충분]   [자료 부족]
|                |
컨텐츠 생성      질문 생성
|                |
(진짜 종료)      |
  end            |
                 ↓
         (새로운 채팅 input 수신)
                 ↓
               start
```

## ✅ 구현 완료 사항

### 1. START 라우터 추가
- **위치**: `graph_builder.py`의 `start_router` 함수
- **기능**: 
  - 최초 실행: `context_fetched = False` → `FETCH_CONTEXT` 실행
  - 사용자 답변 후: `context_fetched = True` → `LLM_DECISION`으로 바로 이동 (FETCH_CONTEXT 건너뛰기)

### 2. FETCH_CONTEXT 수정
- **변경사항**: 
  - `context_fetched: True` 플래그 추가
  - `next_step: "LLM_DECISION"`으로 변경 (기존: "GENERATE_QUERY")

### 3. 그래프 구조 최종 수정

#### 최초 실행 경로:
```
START (context_fetched=False)
  ↓
FETCH_CONTEXT (목차+가이드+도메인지식 로드, context_fetched=True 설정)
  ↓
LLM_DECISION (LLM 판단)
  ├─ [자료 충분] → GENERATE_DRAFT → END (진짜 종료)
  └─ [자료 부족] → GENERATE_QUERY → ASK_USER → END (질문 출력, 사용자 입력 대기)
```

#### 사용자 답변 후 경로:
```
START (context_fetched=True)
  ↓ (FETCH_CONTEXT 건너뛰기)
LLM_DECISION (LLM 판단)
  ├─ [자료 충분] → GENERATE_DRAFT → END (진짜 종료)
  └─ [자료 부족] → GENERATE_QUERY → ASK_USER → END (질문 출력, 사용자 입력 대기)
```

## 🔄 전체 워크플로우 동작

### 시나리오 1: 최초 요청 (정보 부족)
```
1. 사용자: "기획서 작성해줘"
2. START → FETCH_CONTEXT (목차+가이드 로드)
3. LLM_DECISION (LLM 판단: 자료 부족)
4. GENERATE_QUERY (질문 생성)
5. ASK_USER (질문 출력: "어떤 사업을 하시나요?")
6. END (사용자 입력 대기)
```

### 시나리오 2: 사용자 답변 후 (여전히 정보 부족)
```
1. 사용자: "AI 스타트업입니다"
2. START (context_fetched=True) → LLM_DECISION (FETCH_CONTEXT 건너뛰기)
3. LLM_DECISION (LLM 판단: 여전히 자료 부족)
4. GENERATE_QUERY (추가 질문 생성)
5. ASK_USER (질문 출력: "주요 서비스는 무엇인가요?")
6. END (사용자 입력 대기)
```

### 시나리오 3: 사용자 답변 후 (정보 충분)
```
1. 사용자: "AI 챗봇 서비스입니다"
2. START (context_fetched=True) → LLM_DECISION (FETCH_CONTEXT 건너뛰기)
3. LLM_DECISION (LLM 판단: 자료 충분)
4. GENERATE_DRAFT (본문 생성)
5. END (진짜 종료, 생성된 본문을 채팅으로 출력)
```

## 🎯 핵심 개선 사항

1. **FETCH_CONTEXT 최초 1회만 실행**
   - `context_fetched` 플래그로 중복 실행 방지
   - 사용자 답변 후에는 컨텍스트를 다시 로드하지 않음

2. **순환 구조 명확화**
   - 사용자 답변 → START → LLM_DECISION (FETCH_CONTEXT 건너뛰기)
   - 정보가 충분해질 때까지 반복

3. **진짜 종료**
   - GENERATE_DRAFT 후 바로 END로 종료
   - 더 이상 루프를 돌지 않음

## 📝 주요 수정 파일

1. **`graph_builder.py`**
   - `start_router` 함수 추가
   - START에 조건부 엣지 추가

2. **`fetch_context.py`**
   - `context_fetched: True` 플래그 추가
   - `next_step: "LLM_DECISION"`으로 변경

3. **`llm_decision_router.py`**
   - 기존 유지 (LLM 판단 로직)

4. **`generate_draft.py`**
   - `next_step: "FINISH"` 설정 (종료 처리)

## ✅ 완료 체크리스트

- [x] START 라우터 추가 (context_fetched 확인)
- [x] FETCH_CONTEXT 최초 1회만 실행되도록 수정
- [x] 사용자 답변 후 START → LLM_DECISION 직접 이동
- [x] 생성 경로: GENERATE_DRAFT → END (진짜 종료)
- [x] 질문 경로: GENERATE_QUERY → ASK_USER → END (사용자 입력 대기)
- [x] 순환 구조: 사용자 답변 → START → LLM_DECISION

## 🧪 테스트 방법

1. **최초 요청 테스트**
   - 사용자: "기획서 작성해줘"
   - 예상: FETCH_CONTEXT 실행 → LLM 판단 → 질문 생성

2. **정보 수집 테스트**
   - 사용자: "AI 스타트업입니다"
   - 예상: FETCH_CONTEXT 건너뛰기 → LLM 판단 → 추가 질문 또는 생성

3. **생성 테스트**
   - 충분한 정보 수집 후
   - 예상: LLM 판단 → 본문 생성 → 진짜 종료



