from fastapi import APIRouter
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from openai import OpenAI
import json
import re
import requests
import os

router = APIRouter()
client = OpenAI()

# Spring ë°±ì—”ë“œ URL (í™˜ê²½ë³€ìˆ˜ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
SPRING_BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8081")


class DraftCompareRequest(BaseModel):
    project_idx: int
    draft_json: Dict[str, Any]


# ===============================
# ê³µí†µ ìƒìˆ˜ / ìœ í‹¸
# ===============================

# ğŸ”¹ ì„¹ì…˜ì—ì„œ ì•„ì˜ˆ ë¬´ì‹œí•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë“¤ (ì‚¬ì—…ê³„íšì„œ ì‘ì„±ìš”ë ¹/ëª©ì°¨ ë“±)
SECTION_EXCLUDE_KEYWORDS = [
    "ì‚¬ì—…ê³„íšì„œ ì‘ì„±ìš”ë ¹",
    "ì‚¬ì—…ê³„íšì„œ ì‘ì„± ë°©ë²•",
    "ì‚¬ì—…ê³„íšì„œ ì‘ì„±ë°©ë²•",
    "ì‚¬ì—…ê³„íšì„œ ëª©ì°¨",
    "ì‹ ì²­ì„œ ì‘ì„±ìš”ë ¹",
    "ì‹ ì²­ì„œ ì‘ì„± ë°©ë²•",
    "ì‹ ì²­ì„œ ì‘ì„±ë°©ë²•",
    "ì´ˆì•ˆ ì‘ì„±ìš”ë ¹",
    "ì‘ì„± ì˜ˆì‹œ",
]

# ğŸ”¹ ì„¹ì…˜ ì œëª©ì—ì„œ ë¹¼ê³  ì‹¶ì€ í”í•œ ë‹¨ì–´ë“¤ (í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œìš©)
SECTION_STOPWORDS = [
    "ì‚¬ì—…ê³„íšì„œ",
    "ì‹ ì²­ì„œ",
    "ê³„íš",
    "ë‚´ìš©",
    "ì‚¬í•­",
    "ê¸°íƒ€",
    "ë“±",
    "ë°",
    "ê´€ë ¨",
    "ìš”ì•½",
    "êµ¬ì„±",
    "ê°œìš”",
    "ì„¤ëª…",
]


def should_exclude_section(title: str) -> bool:
    """ì‚¬ì—…ê³„íšì„œ ì‘ì„±ìš”ë ¹/ëª©ì°¨ ê°™ì€ ì„¹ì…˜ì€ ë¹„êµ ëŒ€ìƒì—ì„œ ì œì™¸."""
    for kw in SECTION_EXCLUDE_KEYWORDS:
        if kw in title:
            return True
    return False


def normalize_title_text(text: str) -> str:
    """
    ì„¹ì…˜ ì œëª©/headingì„ ë¹„êµí•˜ê¸° ìœ„í•´ ì •ê·œí™”:
    - ì•ìª½ ë²ˆí˜¸/ê¸°í˜¸ ì œê±° (ì˜ˆ: '9.1 ', '(1)', 'â‘ ' ë“±)
    - ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°
    """
    if not text:
        return ""
    s = str(text)
    # ì•ì˜ ë²ˆí˜¸/ê¸°í˜¸ ì œê±°
    s = re.sub(r"^[\d\.\-\)\(â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©\s]+", "", s)
    # ê³µë°±/íƒ­ ì œê±°
    s = re.sub(r"\s+", "", s)
    return s


def extract_core_keywords(title: str) -> List[str]:
    """
    ì„¹ì…˜ ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë§Œ ë½‘ê¸°.
    ì˜ˆ) '9.1 íŒŒê¸‰íš¨ê³¼ ë° í™œìš©ë°©ì•ˆ' -> ['íŒŒê¸‰íš¨ê³¼', 'í™œìš©ë°©ì•ˆ']
    """
    if not title:
        return []
    # ë²ˆí˜¸ ì œê±° í›„ í† í°í™”
    s = re.sub(r"^[\d\.\-\)\(â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©\s]+", "", title).strip()
    tokens = re.split(r"[Â·,/()\[\]\s]+", s)
    keywords = []
    for t in tokens:
        t = t.strip()
        if not t:
            continue
        if t in SECTION_STOPWORDS:
            continue
        if len(t) < 2:
            continue
        keywords.append(t)
    return keywords


def is_section_covered_by_headings(toc_title: str, draft_headings: List[str]) -> bool:
    """
    'ëª©ì°¨ ì„¹ì…˜ ì œëª©'ì´ ì´ˆì•ˆì˜ heading ì¤‘ ì–´ëŠ í•˜ë‚˜ì™€ë¼ë„
    'ì¶©ë¶„íˆ ë¹„ìŠ·í•œ ì œëª©'ì´ë©´ í•´ë‹¹ ì„¹ì…˜ì„ ì‘ì„±í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼.

    - ì •í™•íˆ ê°™ì€ ë¬¸ìì—´ì¼ í•„ìš”ëŠ” ì—†ìŒ.
    - ë²ˆí˜¸(1., 1.1 ë“±) / ê³µë°±ì€ ë¬´ì‹œ.
    - 'íŒŒê¸‰íš¨ê³¼ ë° í™œìš©ë°©ì•ˆ' vs 'íŒŒê¸‰íš¨ê³¼' vs 'ê¸°ëŒ€íš¨ê³¼ ë° í™œìš©ë°©ì•ˆ' ë“± ìœ ì—°í•˜ê²Œ ì²˜ë¦¬.
    - í•˜ì§€ë§Œ 'ë³¸ë¬¸ ë‚´ìš©'ë§Œ ë³´ê³  íŒë‹¨í•˜ì§€ ì•Šê³ , ë°˜ë“œì‹œ heading(ì œëª©)ì—ë§Œ ì˜ì¡´.
    """
    if not toc_title or not draft_headings:
        return False

    norm_toc = normalize_title_text(toc_title)
    toc_keywords = extract_core_keywords(toc_title)

    for h in draft_headings:
        norm_h = normalize_title_text(h)
        if not norm_h:
            continue

        # 1) ì •ê·œí™”ëœ ë¬¸ìì—´ë¼ë¦¬ ë¶€ë¶„ í¬í•¨ ê´€ê³„ë©´ ë§¤ì¹­
        if norm_toc and (norm_toc in norm_h or norm_h in norm_toc):
            return True

        # 2) í•µì‹¬ í‚¤ì›Œë“œê°€ heading ì•ˆì— í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ë§¤ì¹­ ì¸ì •
        if toc_keywords:
            overlap = sum(1 for kw in toc_keywords if kw and kw in norm_h)
            if overlap >= 1:
                return True

    return False


# -------------------------------
# JSON / TEXT UTILITIES
# -------------------------------
def extract_json_from_response(text: str) -> str:
    """GPT ì‘ë‹µì—ì„œ ```json``` ë¸”ë¡ë§Œ ì¶”ì¶œ"""
    codeblock = re.search(r"```(?:json)?\s*(.*?)\s*```", text, re.DOTALL)
    return codeblock.group(1).strip() if codeblock else text.strip()


def extract_text_from_tiptap(doc_json: Dict[str, Any]) -> str:
    """tiptap JSONì—ì„œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
    texts: List[str] = []
    for block in doc_json.get("content", []):
        if "content" in block:
            for item in block["content"]:
                if "text" in item:
                    texts.append(item["text"].strip())
    return "\n".join(texts)


def extract_section_headings(doc_json: Dict[str, Any]) -> List[str]:
    """tiptap JSONì—ì„œ heading íƒ€ì… ì„¹ì…˜ ì œëª©ë§Œ ì¶”ì¶œ"""
    headings: List[str] = []
    for block in doc_json.get("content", []):
        if block.get("type") == "heading":
            text_items = [
                c.get("text") for c in block.get("content", [])
                if "text" in c
            ]
            if text_items:
                headings.append(" ".join(text_items))
    return headings


# -------------------------------
# GPT: ì„¹ì…˜ ë§¤í•‘ (í‘œì‹œìš©)
# -------------------------------
def map_sections_ai(draft_sections: List[str], toc_sections: List[str]) -> List[dict]:
    """
    ì´ˆì•ˆ ì„¹ì…˜ ì œëª© vs ê³µê³ ë¬¸ ëª©ì°¨ë¥¼ ì˜ë¯¸ì ìœ¼ë¡œ ë§¤í•‘.
    - ì´ê±´ "í‘œì‹œìš©" ë§¤í•‘ì´ë¼, ëˆ„ë½ íŒë‹¨ì—ëŠ” ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³ 
      í”„ë¡ íŠ¸ì—ì„œ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©.
    """
    if not draft_sections or not toc_sections:
        return []

    prompt = {
        "role": "user",
        "content": f"""
ì•„ë˜ëŠ” ê³µê³ ë¬¸ì˜ ëª©ì°¨ì…ë‹ˆë‹¤:
{toc_sections}

ì•„ë˜ëŠ” ì´ˆì•ˆì˜ ì„¹ì…˜ ì œëª©ì…ë‹ˆë‹¤:
{draft_sections}

ì´ˆì•ˆ ì„¹ì…˜ì´ ê³µê³ ë¬¸ ëª©ì°¨ì˜ ì–´ë–¤ í•­ëª©ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

JSON ONLY:
[
  {{
    "draft_title": "...",
    "matched": "... ë˜ëŠ” null",
    "score": 0.0
  }}
]
"""
    }

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[prompt],
        temperature=0
    )
    clean = extract_json_from_response(res.choices[0].message.content)

    try:
        return json.loads(clean)
    except Exception:
        print("âŒ ë§¤í•‘ JSON íŒŒì‹± ì‹¤íŒ¨:", clean)
        return []


# -------------------------------
# GPT: Feature í¬í•¨ ì—¬ë¶€ ì²´í¬ (ok / partial / missing)
# -------------------------------
def match_features_ai(draft_text: str, features: List[Dict[str, Any]]) -> List[dict]:
    """
    ê° featureì— ëŒ€í•´ ì´ˆì•ˆì´
    - ok: ê³µê³ ë¬¸ ê¸°ì¤€ìœ¼ë¡œ ì¶©ë¶„íˆ ë°˜ì˜
    - partial: ê´€ë ¨ ë‚´ìš©ì€ ìˆì§€ë§Œ ì„¸ë¶€ ì¡°ê±´/ì •ëŸ‰ ì§€í‘œ ë“±ì´ ë¶€ì¡±
    - missing: ê´€ë ¨ ë‚´ìš©ì´ ê±°ì˜/ì „í˜€ ì—†ìŒ
    ì„ íŒì •í•˜ë„ë¡ GPTì— ìš”ì²­.
    """
    feature_items_for_prompt = []
    for f in features:
        name = (
            f.get("title")
            or f.get("feature_name")
            or f.get("name")
            or f.get("summary")  # ì°¨ì„ ì±…
        )
        if not name:
            continue

        summary = f.get("summary") or ""
        source_section = f.get("source_section") or f.get("section") or ""
        feature_items_for_prompt.append(
            f"- ì´ë¦„: {name}\n  ìš”ì•½: {summary}\n  ì¶œì²˜ ì„¹ì…˜: {source_section}"
        )

    if not feature_items_for_prompt:
        print("âš ï¸ match_features_ai: ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” feature ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    features_block = "\n".join(feature_items_for_prompt)

    prompt = {
        "role": "user",
        "content": f"""
ë‹¹ì‹ ì€ 'ì •ë¶€ì§€ì›ì‚¬ì—… ê¸°íšì„œ ê²€í†  ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.

[ì´ˆì•ˆ ë‚´ìš©]
{draft_text}

[ê³µê³ ë¬¸ì—ì„œ ì¶”ì¶œí•œ Feature ëª©ë¡]
{features_block}

ê° featureê°€ ì´ˆì•ˆì— ì–´ëŠ ì •ë„ë¡œ ë°˜ì˜ë˜ì–´ ìˆëŠ”ì§€
ë‹¤ìŒ 3ë‹¨ê³„ë¡œë§Œ ìƒíƒœë¥¼ íŒì •í•˜ì„¸ìš”.

- "ok": ì´ˆì•ˆì— í•´ë‹¹ ì¡°ê±´/ë‚´ìš©ì´ ê³µê³ ë¬¸ ê¸°ì¤€ìœ¼ë¡œ ì¶©ë¶„íˆ ë°˜ì˜ë˜ì–´ ìˆìŒ
- "partial": ê´€ë ¨ ë‚´ìš©ì€ ìˆì§€ë§Œ, ì„¸ë¶€ ì¼ì •/ì •ëŸ‰ ì§€í‘œ/ì¡°ê±´ ì¼ì¹˜ ë“±ì—ì„œ ë³´ì™„ì´ í•„ìš”í•¨
- "missing": ì´ˆì•ˆì— ì´ featureì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì´ ê±°ì˜ ë˜ëŠ” ì „í˜€ ì—†ìŒ

âš ï¸ ì¤‘ìš”:
- ì´ˆì•ˆì— ê´€ë ¨ ë‚´ìš©ì´ 'ì¡°ê¸ˆì´ë¼ë„' ì–¸ê¸‰ë˜ì–´ ìˆìœ¼ë©´ ì ˆëŒ€ë¡œ "missing"ìœ¼ë¡œ ë‘ì§€ ë§ˆì„¸ìš”.
- ê·¸ ê²½ìš° ê³µê³ ë¬¸ ìˆ˜ì¤€ì— ë¯¸ì¹˜ì§€ ëª»í•œë‹¤ê³  íŒë‹¨ë˜ë©´ "partial"ë¡œ ë‘ê³ ,
  ì–´ë–¤ ì ì´ ë¶€ì¡±í•œì§€ reasonì— ì¨ ì£¼ì„¸ìš”.
- ì •ë§ë¡œ ê´€ë ¨ ë‚´ìš©ì´ ê±°ì˜/ì „í˜€ ì—†ì„ ë•Œë§Œ "missing"ìœ¼ë¡œ ë‘ì„¸ìš”.

JSON ONLY ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

[
  {{
    "feature": "ê³µê³ ë¬¸ì—ì„œì˜ feature ì´ë¦„ ê·¸ëŒ€ë¡œ",
    "status": "ok" | "partial" | "missing",
    "reason": "ë‘ì„¸ ë¬¸ì¥ìœ¼ë¡œ ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ ì„¤ëª…"
  }}
]
"""
    }

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[prompt],
        temperature=0
    )

    clean = extract_json_from_response(res.choices[0].message.content)

    try:
        parsed = json.loads(clean)
        for item in parsed:
            if "status" not in item:
                included_val = str(item.get("included")).lower()
                item["status"] = "ok" if included_val == "true" else "missing"
        return parsed
    except Exception:
        print("âŒ Feature JSON íŒŒì‹± ì‹¤íŒ¨:", clean)
        return []


# -------------------------------
# GPT: ì„¹ì…˜ ëˆ„ë½ í›„ë³´ ì„¤ëª…/ë³´ì™„ ê°€ì´ë“œ ìƒì„±ìš©
# -------------------------------
def refine_missing_sections_ai(draft_text: str, sections: List[str]) -> List[dict]:
    """
    1ì°¨ í•„í„°ì—ì„œ 'missing_sections'ë¡œ ì¡íŒ ì„¹ì…˜ë“¤ì— ëŒ€í•´
    ì™œ ë¶€ì¡±í•œì§€ / ì–´ë–»ê²Œ ë³´ì™„í•˜ë©´ ì¢‹ì€ì§€ reasonë§Œ ë°›ì•„ì˜¤ê¸° ìœ„í•œ ìš©ë„.
    (ì—¬ê¸°ì„œëŠ” statusë¥¼ ê·¸ëŒ€ë¡œ ë¯¿ì§€ ì•Šê³ , ë°˜ë“œì‹œ missingìœ¼ë¡œ ìœ ì§€í•¨)
    """
    if not sections:
        return []

    sections_block = "\n".join([f"- {s}" for s in sections])

    prompt = {
        "role": "user",
        "content": f"""
ë‹¹ì‹ ì€ 'ì •ë¶€ì§€ì›ì‚¬ì—… ê¸°íšì„œ ê²€í†  ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.

[ì´ˆì•ˆ ë‚´ìš©]
{draft_text}

[ê³µê³ ë¬¸ ì„¹ì…˜ í›„ë³´ ëª©ë¡]
{sections_block}

ê° ì„¹ì…˜ì´ ì´ˆì•ˆì— ì–´ë–¤ ì ì—ì„œ ë¶€ì¡±í•œì§€,
ê·¸ë¦¬ê³  ì–´ë–»ê²Œ ë³´ì™„í•˜ë©´ ì¢‹ì„ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

JSON ONLY ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

[
  {{
    "section": "ê³µê³ ë¬¸ ì„¹ì…˜ ì´ë¦„ ê·¸ëŒ€ë¡œ",
    "status": "ok" | "partial" | "missing",
    "reason": "ë‘ì„¸ ë¬¸ì¥ìœ¼ë¡œ ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€ ì„¤ëª…"
  }}
]
"""
    }

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[prompt],
        temperature=0
    )

    clean = extract_json_from_response(res.choices[0].message.content)

    try:
        parsed = json.loads(clean)
        return parsed
    except Exception:
        print("âŒ ì„¹ì…˜ ì¬í‰ê°€ JSON íŒŒì‹± ì‹¤íŒ¨:", clean)
        return []


# -------------------------------
# GPT: ì‹¤ë¬´í˜• ë³´ì™„ ê°€ì´ë“œ ìƒì„±
# -------------------------------
def generate_suggestion(feature_or_section: str) -> str:
    """
    í•´ë‹¹ í•­ëª©ì´ ì–´ë–¤ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•˜ëŠ”ì§€
    2~4ì¤„ì˜ ì‹¤ë¬´í˜• ê¸°íšì„œ ë³´ì™„ ê°€ì´ë“œë¥¼ ìƒì„±.
    """
    prompt = {
        "role": "user",
        "content": f"""
ë‹¤ìŒ í•­ëª©ì„ ê¸°íšì„œì— ë³´ì™„í•´ì•¼ í•©ë‹ˆë‹¤:
í•­ëª©: {feature_or_section}

ì´ í•­ëª©ì€ ì •ë¶€ì§€ì›ì‚¬ì—… ê¸°íšì„œì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì–´ë–¤ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•˜ëŠ”ì§€
ì‹¤ë¬´ìê°€ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ 2~4ì¤„ë¡œ í•µì‹¬ ê°€ì´ë“œë¼ì¸ë§Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

'-' ë¦¬ìŠ¤íŠ¸ ì—†ì´ ë¬¸ì¥í˜•ìœ¼ë¡œë§Œ ì‘ì„±í•˜ê³ ,
'~ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.' í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
    }

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[prompt],
        temperature=0.2
    )

    return res.choices[0].message.content.strip()


# -------------------------------
# Spring ì‘ë‹µì—ì„œ ëª©ì°¨/Feature ë½‘ê¸°
# -------------------------------
def get_toc_titles(ctx_data: Dict[str, Any]) -> List[str]:
    """
    Spring ì‘ë‹µì—ì„œ result_toc / sections / toc ë“±ì—ì„œ ì„¹ì…˜ titleì„ ìµœëŒ€í•œ ë½‘ì•„ëƒ„.
    - result_tocê°€ ë¬¸ìì—´(JSON string)ì´ì–´ë„ ì²˜ë¦¬
    - ì¼ë¶€ 'ì‚¬ì—…ê³„íšì„œ ì‘ì„±ìš”ë ¹' ê°™ì€ ê±´ SECTION_EXCLUDE_KEYWORDSë¡œ í•„í„°ë§
    """
    if not isinstance(ctx_data, dict):
        return []

    sections: Optional[List[Any]] = None

    toc_raw = (
        ctx_data.get("result_toc")
        or ctx_data.get("resultToc")
        or ctx_data.get("toc")
    )

    if isinstance(toc_raw, str):
        try:
            print("ğŸ“˜ result_tocê°€ strì´ë¼ JSON íŒŒì‹± ì‹œë„:", toc_raw[:120], "...")
            toc_raw = json.loads(toc_raw)
        except Exception as e:
            print("âŒ result_toc JSON íŒŒì‹± ì‹¤íŒ¨:", e)

    if isinstance(toc_raw, dict):
        sections = toc_raw.get("sections") or toc_raw.get("toc")
    elif isinstance(toc_raw, list):
        sections = toc_raw

    if sections is None and isinstance(ctx_data.get("sections"), list):
        sections = ctx_data["sections"]

    if not sections:
        print("âš ï¸ get_toc_titles: sections ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. result_toc íƒ€ì…:", type(toc_raw))
        return []

    titles: List[str] = []

    for sec in sections:
        title = None
        if isinstance(sec, dict):
            title = sec.get("title") or sec.get("sectionTitle") or sec.get("name")
        else:
            title = str(sec)

        if not title:
            continue

        # ì‘ì„±ìš”ë ¹/ëª©ì°¨ ë“± ë¶ˆí•„ìš” ì„¹ì…˜ í•„í„°ë§
        if should_exclude_section(str(title)):
            continue

        titles.append(str(title))

    return titles


def get_features(ctx_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Spring ì‘ë‹µì—ì„œ extracted_features ë˜ëŠ” featuresë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    """
    if not isinstance(ctx_data, dict):
        return []

    features = ctx_data.get("extracted_features")
    if features is None:
        features = ctx_data.get("features")

    if not isinstance(features, list):
        print("âš ï¸ get_features: featuresê°€ listê°€ ì•„ë‹™ë‹ˆë‹¤.", type(features), features)
        return []

    return features


# -------------------------------
# Main Compare API
# -------------------------------
@router.post("/draft")
def compare_draft_ai(request: DraftCompareRequest):
    """
    ì´ˆì•ˆ(tiptap JSON)ê³¼ ê³µê³ ë¬¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•´
    ëˆ„ë½ ì„¹ì…˜/Feature + ë³´ì™„ ê°€ì´ë“œ ë°˜í™˜

    âœ… ë³€ê²½ í¬ì¸íŠ¸:
    - ëª©ì°¨ ê¸°ì¤€ìœ¼ë¡œ "ì œëª©ì´ ìˆëŠ”ì§€"ë¥¼ ë¨¼ì € strictí•˜ê²Œ íŒë‹¨
    - ì œëª©ì´ ì „í˜€ ì—†ìœ¼ë©´, ë³¸ë¬¸ ë‚´ìš©ì´ ë¹„ìŠ·í•´ë„ ë¬´ì¡°ê±´ missing_sectionsì— í¬í•¨
    - ë‹¨, ì œëª© ë§¤ì¹­ì€ 'ì •í™• ì¼ì¹˜'ê°€ ì•„ë‹ˆë¼ í•µì‹¬ í‚¤ì›Œë“œ ê¸°ë°˜ fuzzy ë§¤ì¹­
    - ë³„ë„ë¡œ ëª©ì°¨ ê¸°ì¤€ progress(%)ë„ ê³„ì‚°í•´ì„œ ë‚´ë ¤ì¤Œ
    """
    try:
        print(f"ğŸ“„ /compare/draft ìš”ì²­ ìˆ˜ì‹ : project_idx={request.project_idx}")

        # 1) ì´ˆì•ˆ í…ìŠ¤íŠ¸/ì„¹ì…˜ ì¶”ì¶œ
        draft_text = extract_text_from_tiptap(request.draft_json)
        draft_sections = extract_section_headings(request.draft_json)
        print("âœï¸ ì´ˆì•ˆ heading ëª©ë¡:", draft_sections)

        # 2) Spring ê³µê³ ë¬¸ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            spring_res = requests.get(
                f"{SPRING_BACKEND_URL}/api/analysis/get-context",
                params={"projectIdx": request.project_idx},
                timeout=10,
            )
        except Exception as e:
            print("âŒ Spring ì„œë²„ í˜¸ì¶œ ì‹¤íŒ¨:", e)
            return {
                "status": "error",
                "message": f"Spring backend í˜¸ì¶œ ì‹¤íŒ¨: {e}",
            }

        if spring_res.status_code != 200:
            print("âŒ Spring ì‘ë‹µ ìƒíƒœ ì½”ë“œ:", spring_res.status_code, spring_res.text)
            return {
                "status": "error",
                "message": f"Spring backend ì‘ë‹µ ì˜¤ë¥˜: {spring_res.status_code}",
            }

        spring_json = spring_res.json()
        ctx_data = spring_json.get("data") or spring_json

        if isinstance(ctx_data, dict):
            print("ğŸ” get-context ctx_data keys:", list(ctx_data.keys()))
        else:
            print("ğŸ” get-context ctx_data type:", type(ctx_data))

        # 3) ëª©ì°¨ title, feature ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        toc_titles = get_toc_titles(ctx_data)
        features = get_features(ctx_data)

        print("ğŸ“š ê³µê³ ë¬¸ ëª©ì°¨ titles:", toc_titles)

        # -------------------------
        # 4) ì„¹ì…˜ ë§¤í•‘ (í‘œì‹œìš©)
        # -------------------------
        section_mapping = map_sections_ai(draft_sections, toc_titles)

        # -------------------------
        # 5) "ëª©ì°¨ ì œëª© ê¸°ì¤€" missing ì„¹ì…˜ ê³„ì‚°
        # -------------------------
        effective_toc_titles = toc_titles[:]  # í•„í„°ë§ëœ ìƒíƒœ ê·¸ëŒ€ë¡œ ì‚¬ìš©

        written_sections: List[str] = []
        strict_missing_sections: List[str] = []

        for title in effective_toc_titles:
            if is_section_covered_by_headings(title, draft_sections):
                written_sections.append(title)
            else:
                strict_missing_sections.append(title)

        print("âœ… heading ê¸°ì¤€ ì¡´ì¬ ì„¹ì…˜:", written_sections)
        print("âŒ heading ê¸°ì¤€ ëˆ„ë½ ì„¹ì…˜:", strict_missing_sections)

        # ğŸ”¹ ëª©ì°¨ ê¸°ì¤€ progress ê³„ì‚°
        total_toc_count = len(effective_toc_titles)
        written_count = len(written_sections)
        toc_progress_percent = (
            int(round(written_count / total_toc_count * 100))
            if total_toc_count > 0 else 0
        )

        # -------------------------
        # 6) GPTë¡œ missing ì„¹ì…˜ ìƒì„¸ reason/suggestion ìƒì„±
        #     (statusëŠ” í•­ìƒ missingìœ¼ë¡œ ê³ ì •)
        # -------------------------
        section_eval = (
            refine_missing_sections_ai(draft_text, strict_missing_sections)
            if strict_missing_sections else []
        )
        section_eval_map = {item.get("section"): item for item in section_eval}

        final_missing_sections: List[str] = []
        section_details: List[Dict[str, Any]] = []

        for sec in strict_missing_sections:
            info = section_eval_map.get(sec)
            raw_status = (info or {}).get("status", "missing")
            reason = (info or {}).get("reason")

            # âœ… ì œëª©ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´, GPTê°€ statusë¥¼ ok/partialë¡œ ì¤˜ë„
            #    "í˜•ì‹ìƒ ëˆ„ë½"ìœ¼ë¡œ ê°•ì œ missing ìœ ì§€
            status = "missing"

            if not reason:
                reason = f"ì´ˆì•ˆì— '{sec}' í•­ëª©ì€ ë³„ë„ì˜ ì„¹ì…˜ ì œëª©ì´ë‚˜ ë‚´ìš© êµ¬ì¡°ë¡œ ê±°ì˜ ë°˜ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."

            section_details.append({
                "section": sec,
                "status": status,
                "reason": reason,
                "suggestion": generate_suggestion(sec),
            })
            final_missing_sections.append(sec)

        missing_sections = final_missing_sections

        # -------------------------
        # 7) Feature ë§¤ì¹­ (Featureê°€ ìˆì„ ë•Œë§Œ)
        # -------------------------
        feature_eval = match_features_ai(draft_text, features) if features else []

        missing_features: List[str] = []
        feature_details: List[Dict[str, Any]] = []

        for f in feature_eval:
            feature_name = f.get("feature")
            if not feature_name:
                continue

            status = f.get("status")
            if not status:
                included_val = str(f.get("included")).lower()
                status = "ok" if included_val == "true" else "missing"

            status = status.lower()
            if status not in ("ok", "partial", "missing"):
                status = "missing"

            if status == "missing":
                missing_features.append(feature_name)

            if status in ("partial", "missing"):
                feature_details.append({
                    "feature": feature_name,
                    "status": status,
                    "reason": f.get("reason"),
                    "suggestion": generate_suggestion(feature_name),
                })

        # -------------------------
        # 8) ìµœì¢… Response
        # -------------------------
        return {
            "status": "success",

            # ì„¹ì…˜ ë§¤í•‘ (í‘œì‹œìš©)
            "mapped_sections": section_mapping,       # ëª©ì°¨ ì—†ìœ¼ë©´ []

            # ëˆ„ë½ ì •ë³´
            "missing_sections": missing_sections,     # ì œëª© ê¸°ì¤€ìœ¼ë¡œ ì§„ì§œ ëˆ„ë½ëœ ì„¹ì…˜ë§Œ
            "feature_mismatch": missing_features,     # ì§„ì§œ missingì¸ featureë§Œ

            # ëª©ì°¨ ê¸°ì¤€ progress ì •ë³´
            "toc_progress": {
                "total_sections": total_toc_count,
                "written_sections": written_count,
                "progress_percent": toc_progress_percent,
            },

            "section_analysis": {
                "missing_sections": missing_sections,
                "details": section_details,           # ê° ì„¹ì…˜ë³„ reason + suggestion
            },
            "feature_analysis": {
                "missing_features": missing_features,
                "details": feature_details,           # partial/missingë§Œ, status í¬í•¨
            },

            "draft_sections": draft_sections,
        }

    except Exception as e:
        print("âŒ /compare/draft ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸:", e)
        return {
            "status": "error",
            "message": f"ì´ˆì•ˆ ë¹„êµ ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {e}",
        }
