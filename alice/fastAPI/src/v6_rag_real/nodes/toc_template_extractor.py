"""
ì–‘ì‹ ê¸°ë°˜ ëª©ì°¨ ì¶”ì¶œ ëª¨ë“ˆ
ì œì•ˆì„œ ì–‘ì‹ íŒŒì¼ì—ì„œ ëª©ì°¨ë¥¼ ì¶”ì¶œí•˜ëŠ” ì„¸ë¶€ ë¡œì§

âš ï¸ [DEPRECATED] ì´ íŒŒì¼ì€ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

Vision API ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ê°€ ë„ì…ë˜ë©´ì„œ ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì¶œ ë°©ì‹ì€ 
toc_extraction.pyì˜ extract_toc_from_template í•¨ìˆ˜ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.

í˜„ì¬ ëª©ì°¨ ì¶”ì¶œ ì „ëµ:
- extract_toc_from_template: Vision APIë¡œ ëª©ì°¨ í˜ì´ì§€ ë²”ìœ„ë¥¼ ì°¾ê³  
  ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ëª©ì°¨ë¥¼ ì¶”ì¶œí•˜ë©° ê° í•­ëª©ì˜ ì‘ì„±ìš”ë ¹ë„ í•¨ê»˜ ì°¾ìŠµë‹ˆë‹¤.

ì´ íŒŒì¼ì€ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ìœ ì§€ë˜ë©°, ì‹¤ì œ ì‹¤í–‰ ê²½ë¡œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
"""

import json
import re
from typing import List, Dict, Tuple, Optional
from datetime import datetime

from .toc_util import (
    find_toc_table,
    parse_toc_table,
    extract_sections_from_symbols,
    create_default_toc,
    client
)


def extract_subsections_from_range(
    lines_block: List[str],
    parent_number: str,
    base_line_index: int,
    end_line_index: int,
    start_counter: int = 1
) -> List[Dict]:
    """
    ì£¼ì–´ì§„ ë¼ì¸ ë¸”ë¡ì—ì„œ í•˜ìœ„ ì„¹ì…˜ íŒ¨í„´(ï¿­, 1), (ê°€) ë“±)ì„ ì¶”ì¶œ
    """
    SUBSECTION_PATTERNS = [
        (re.compile(r'^ï¿­\s*(.+)$'), 1),
        (re.compile(r'^â–ª\s*(.+)$'), 1),
        (re.compile(r'^â–«\s*(.+)$'), 1),
        (re.compile(r'^[-â€“â€”]\s*(.+)$'), 1),
        (re.compile(r'^â—\s*(.+)$'), 1),
        (re.compile(r'^â—‹\s*(.+)$'), 1),
        (re.compile(r'^([0-9]{1,2})\)\s*(.+)$'), 2),
        (re.compile(r'^\(([0-9]{1,2})\)\s*(.+)$'), 2),
        (re.compile(r'^([ê°€-í£])\)\s*(.+)$'), 2),
        (re.compile(r'^\(([ê°€-í£])\)\s*(.+)$'), 2),
    ]

    subsections = []
    counter = start_counter
    for offset, line in enumerate(lines_block):
        clean = line.strip()
        if not clean:
            continue
        for pattern, group_idx in SUBSECTION_PATTERNS:
            match = pattern.match(clean)
            if match:
                title = match.group(group_idx).strip()
                if len(title) < 2:
                    break
                subsection_number = f"{parent_number}.{counter}"
                absolute_index = base_line_index + offset
                subsections.append({
                    'number': subsection_number,
                    'title': title,
                    'level': 'sub',
                    'parent_number': parent_number,
                    'line_index': absolute_index
                })
                counter += 1
                break

    for idx, sub in enumerate(subsections):
        next_line = subsections[idx + 1]['line_index'] if idx + 1 < len(subsections) else end_line_index
        sub['next_line_index'] = next_line

    return subsections


def prepare_template_context(template_doc: Dict, state: Dict, template: Dict) -> str:
    """
    í…œí”Œë¦¿ ë¬¸ì„œì—ì„œ LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ

    ìš°ì„ ìˆœìœ„:
    1. page_texts (ì›ë³¸ í˜ì´ì§€ êµ¬ì¡° ë³´ì¡´)
    2. all_chunks (í˜ì´ì§€ë³„ ì²­í¬)
    3. full_text ì¼ë¶€
    """
    page_texts = template_doc.get('page_texts', {})
    chunk_context = ""

    if page_texts:
        print(f"    âœ… page_texts ì‚¬ìš©: {len(page_texts)}ê°œ í˜ì´ì§€")
        sorted_pages = sorted(page_texts.items(), key=lambda x: x[0])
        page_context_parts = []

        MAX_PAGES = 20
        for page_num, page_text in sorted_pages[:MAX_PAGES]:
            text_snippet = page_text[:1500]
            page_context_parts.append(f"[í˜ì´ì§€ {page_num}]\n{text_snippet}")

        chunk_context = '\n\n'.join(page_context_parts)
        print(f"    ğŸ“„ í˜ì´ì§€ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(chunk_context):,}ì (ìµœëŒ€ {MAX_PAGES}í˜ì´ì§€)")

    # Fallback: all_chunks ì‚¬ìš©
    if not chunk_context:
        print(f"    âš ï¸  page_texts ì—†ìŒ â†’ all_chunks fallback ì‹œë„")
        all_chunks = state.get('all_chunks', [])
        template_chunks = []
        template_file_name = template['file_name']

        for chunk in all_chunks:
            if chunk.get('file_name') == template_file_name:
                template_chunks.append(chunk)

        template_chunks.sort(key=lambda c: (c.get('page', 0) or 0, c.get('chunk_id', '')))

        MAX_TEMPLATE_CHUNKS = 20
        chunk_context_parts = []
        for chunk in template_chunks[:MAX_TEMPLATE_CHUNKS]:
            page = chunk.get('page', '?')
            section = chunk.get('section', 'ì„¹ì…˜')
            text_snippet = chunk.get('text', '')[:800]
            chunk_context_parts.append(f"[í˜ì´ì§€ {page} | {section}]\n{text_snippet}")

        chunk_context = '\n\n'.join(chunk_context_parts)
        print(f"    ğŸ“¦ ì²­í¬ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(chunk_context):,}ì ({len(template_chunks)}ê°œ ì²­í¬)")

    # ìµœì¢… fallback: full_text
    if not chunk_context:
        full_text = template_doc.get('full_text', '')
        chunk_context = full_text[:5000]
        if chunk_context:
            print(f"    âš ï¸  ì²­í¬ ì—†ìŒ â†’ full_text ì¼ë¶€ ì‚¬ìš© (ê¸¸ì´ {len(chunk_context):,}ì)")

    return chunk_context


def build_base_sections(
    symbol_sections: List[Dict],
    full_text: str
) -> Tuple[List[Dict], List[Dict]]:
    """
    íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œí•œ ì„¹ì…˜ì—ì„œ base_sectionsì™€ section_contexts ìƒì„±

    symbol_sectionsì— ì´ë¯¸ main/sub ì„¹ì…˜ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ,
    ê° ì„¹ì…˜ì˜ ë³¸ë¬¸ excerptë§Œ ì¶”ê°€í•˜ì—¬ ë°˜í™˜

    Returns:
        (base_sections, section_contexts) íŠœí”Œ
    """
    base_sections: List[Dict] = []
    section_contexts: List[Dict] = []
    full_lines = full_text.split('\n')
    total_lines = len(full_lines)

    # symbol_sectionsë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, excerptë§Œ ì¶”ê°€
    for sec in symbol_sections:
        start_line = sec.get('line_index', 0)
        end_line = sec.get('next_line_index', total_lines)
        block_lines = full_lines[start_line:end_line]
        block_text = '\n'.join(block_lines).strip()

        # excerpt ì¶”ê°€
        sec_entry = {
            'number': sec['number'],
            'title': sec['title'],
            'level': sec.get('level', 'main'),
            'parent_number': sec.get('parent_number'),
            'line_index': start_line,
            'next_line_index': end_line
        }

        # ë³¸ë¬¸ ë°œì·Œ ì¶”ê°€
        if block_text:
            max_excerpt = 800 if sec.get('level') == 'main' else 600
            sec_entry['excerpt'] = block_text[:max_excerpt]
            section_contexts.append({
                'number': sec_entry['number'],
                'title': sec_entry['title'],
                'excerpt': sec_entry['excerpt']
            })

        base_sections.append(sec_entry)

    return base_sections, section_contexts


def extract_template_text(full_text: str) -> str:
    """
    full_textì—ì„œ ëª©ì°¨ ì„¹ì…˜ë§Œ ì¶”ì¶œ

    í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ "< ë³¸ë¬¸", "ì‘ì„± ëª©ì°¨" ë“±ì„ ì°¾ì•„ì„œ í•´ë‹¹ êµ¬ê°„ ì¶”ì¶œ
    """
    template_text = ''

    toc_start_keywords = [
        '< ë³¸ë¬¸', '<ë³¸ë¬¸', 'ë³¸ë¬¸>',
        'ì‘ì„± ëª©ì°¨', 'ì œì¶œì„œë¥˜ ëª©ì°¨', 'ê³„íšì„œ ëª©ì°¨',
        'ì‘ì„±í•­ëª©', 'ì œì¶œí•­ëª©', 'ê¸°ì¬ì‚¬í•­'
    ]
    toc_section_start = -1
    for keyword in toc_start_keywords:
        idx = full_text.find(keyword)
        if idx != -1:
            toc_section_start = idx
            print(f"    ğŸ“ ëª©ì°¨ ì‹œì‘ í‚¤ì›Œë“œ ë°œê²¬: '{keyword}' (ìœ„ì¹˜: {idx})")
            break

    if toc_section_start != -1:
        text_after_start = full_text[toc_section_start:]
        end_keywords = [
            '< ë³¸ë¬¸ 2', '<ë³¸ë¬¸ 2', 'ë³¸ë¬¸ 2>',
            'ì‘ì„±ìš”ë ¹', 'ì‘ì„± ìš”ë ¹', 'ì£¼ì˜ì‚¬í•­', 'ìœ ì˜ì‚¬í•­',
            'ì°¸ê³ ì‚¬í•­', 'ê¸°ì¬ìš”ë ¹', 'ì²¨ë¶€ì„œë¥˜',
            'â€» ì°¸ê³ ', 'ã€ì°¸ê³ ', '[ì°¸ê³ '
        ]
        toc_end = len(text_after_start)
        for end_kw in end_keywords:
            end_idx = text_after_start.find(end_kw)
            if end_idx != -1 and end_idx < toc_end:
                toc_end = end_idx
                print(f"    ğŸ“ ëª©ì°¨ ë í‚¤ì›Œë“œ ë°œê²¬: '{end_kw}' (ìƒëŒ€ ìœ„ì¹˜: {end_idx})")
                break
        template_text = text_after_start[:min(toc_end, 5000)]
        print(f"    âœ… ëª©ì°¨ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(template_text)}ì)")
    else:
        # ë²ˆí˜¸ íŒ¨í„´ ê¸°ë°˜ íƒìƒ‰
        pattern = r'^[1-9]\.\s+[ê°€-í£]{2,}'
        lines = full_text.split('\n')
        toc_line_start = -1
        consecutive_numbered = 0
        for i, line in enumerate(lines):
            if re.search(pattern, line.strip()):
                if toc_line_start == -1:
                    toc_line_start = i
                consecutive_numbered += 1
                if consecutive_numbered >= 3:
                    toc_lines = lines[toc_line_start:toc_line_start + 100]
                    template_text = '\n'.join(toc_lines)[:5000]
                    print(f"    âœ… ë²ˆí˜¸ íŒ¨í„´ ê¸°ë°˜ ëª©ì°¨ ë°œê²¬ (ë¼ì¸: {toc_line_start}, ê¸¸ì´: {len(template_text)}ì)")
                    break
            else:
                consecutive_numbered = 0

        if not template_text:
            template_text = full_text[:15000]
            print(f"    âš ï¸  ëª©ì°¨ íŒ¨í„´ ë¯¸ë°œê²¬ â†’ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš© (15000ì)")

    return template_text


def build_llm_prompt(
    template: Dict,
    template_doc: Dict,
    tables: List,
    table_sections: List[Dict],
    symbol_sections: List[Dict],
    template_text: str,
    chunk_context: str,
    skeleton_json: str,
    section_contexts: List[Dict]
) -> Tuple[str, str]:
    """
    LLMì— ì „ë‹¬í•  system_promptì™€ user_prompt êµ¬ì„±
    """
    system_prompt = """ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… ì‹ ì²­ì„œ/ì œì•ˆì„œ ì–‘ì‹ì„ ë¶„ì„í•˜ì—¬ ì‹¤ì œ ì‘ì„±í•´ì•¼ í•˜ëŠ” ë³¸ë¬¸ ëª©ì°¨ë¥¼ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš” ê·œì¹™:
1. **í¼ ì…ë ¥ í•„ë“œëŠ” ì ˆëŒ€ ëª©ì°¨ë¡œ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:**
   - âŒ ì œì™¸: "ê¸°ì—…ëª…", "ëŒ€í‘œì", "ì—°ë½ì²˜", "ì£¼ì†Œ", "ì „í™”", "íŒ©ìŠ¤", "mail", "íœ´ëŒ€ì „í™”", "ìƒë…„ì›”ì¼", "ì„±ë³„", "ì§ìœ„", "ë¶€ì„œ" ë“±
   - âŒ ì œì™¸: "1)ê¸°ì—…í˜„í™©", "2)ëŒ€í‘œì", "3)ì‹¤ë¬´ì±…ì„ì" ê°™ì€ í¼ ì„¹ì…˜ ë²ˆí˜¸
   - âœ… í¬í•¨: "â–¡ ê¸°ì—…í˜„í™©", "â–¡ ëŒ€í‘œì ë° ê²½ì˜ì§„ í˜„í™©", "â–¡ ëª©í‘œ" ê°™ì€ ë³¸ë¬¸ ì‘ì„± ì„¹ì…˜

2. **ë³¸ë¬¸ ì‘ì„± í•­ëª©ë§Œ ëª©ì°¨ë¡œ ì¶”ì¶œ:**
   - â–¡, â– , â—, ï¿­ ê°™ì€ ê¸°í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ì„¹ì…˜ ì¶”ì¶œ
   - "1.", "2.", "3." ê°™ì€ ìˆ«ì+ì  í˜•ì‹ë„ ì£¼ìš” ì„¹ì…˜
   - **âŒ ì œì™¸: "< ë³¸ë¬¸ 1 >", "< ë³¸ë¬¸ 2 >" ê°™ì€ ì–‘ì‹ êµ¬ë¶„ì**ëŠ” ëª©ì°¨ê°€ ì•„ë‹˜
   - **âŒ ì œì™¸: "ì‘ì„±ìš”ë ¹", "ì‘ì„± ìš”ë ¹", "ê¸°ì¬ìš”ë ¹" ì„¹ì…˜**
   - ê° ì„¹ì…˜ì€ ì‹¤ì œë¡œ ì„œìˆ í•´ì•¼ í•  ë‚´ìš©ì„ ìš”êµ¬í•˜ëŠ” í•­ëª©ì´ì–´ì•¼ í•¨

3. **ê³„ì¸µ êµ¬ì¡°:**
   - **ì£¼ìš” ì„¹ì…˜ (main)**: "1.", "2.", "3." ë˜ëŠ” â–¡, â– , â—
   - **í•˜ìœ„ ì„¹ì…˜ (sub)**: "1)", "2)", "3)" ë˜ëŠ” "ê°€)", "ë‚˜)", "ë‹¤)" ë˜ëŠ” ï¿­, â–ª, â–«
   - **ì˜ˆì‹œ:**
     ```
     1. ì—°êµ¬ê°œë°œê³¼ì œì˜ ëª©í‘œ ë° ë‚´ìš©  â† main
        1) ì—°êµ¬ê°œë°œê³¼ì œì˜ ëª©í‘œ        â† sub
        2) ì—°êµ¬ê°œë°œê³¼ì œì˜ ë‚´ìš©        â† sub
     2. ì—°êµ¬ê°œë°œì„±ê³¼ì˜ í™œìš©ë°©ì•ˆ      â† main
        1) í™œìš©ë°©ì•ˆ                   â† sub
     ```

4. **JSON í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ê³ , ì„¹ì…˜ì€ ìµœì†Œ 10ê°œ ì´ìƒ ì¶œë ¥í•˜ì„¸ìš”.**
"""

    if skeleton_json:
        system_prompt += "\n\nâš ï¸ ë§¤ìš° ì¤‘ìš”: ì œê³µëœ ìŠ¤ì¼ˆë ˆí†¤ì„ ì°¸ê³ í•˜ë˜, ì¤‘ë³µì´ë‚˜ ì˜ëª»ëœ ê³„ì¸µ êµ¬ì¡°ê°€ ìˆìœ¼ë©´ ìˆ˜ì •í•˜ì„¸ìš”. ìŠ¤ì¼ˆë ˆí†¤ì˜ number/titleì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, descriptionì„ ì¶”ê°€í•˜ê³  í•„ìš”ì‹œ ê³„ì¸µì„ ì¡°ì •í•˜ì„¸ìš”."
    else:
        system_prompt += "\n\nâš ï¸ ë§¤ìš° ì¤‘ìš”: ìŠ¤ì¼ˆë ˆí†¤ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ì—ì„œ â–¡, â– , â—ë¡œ ì‹œì‘í•˜ëŠ” ë³¸ë¬¸ ì‘ì„± ì„¹ì…˜ë§Œ ì¶”ì¶œí•˜ì„¸ìš”. í¼ ì…ë ¥ í•„ë“œ(ê¸°ì—…ëª…, ëŒ€í‘œì, ì—°ë½ì²˜, mail, íŒ©ìŠ¤, íœ´ëŒ€ì „í™” ë“±)ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."

    if section_contexts:
        system_prompt += "\n\nâš ï¸ ì¤‘ìš”: 'ì„¹ì…˜ë³„ ë³¸ë¬¸ ë°œì·Œ'ì— ì œê³µëœ í…ìŠ¤íŠ¸ëŠ” ê° â–¡ ì„¹ì…˜ì˜ ì‹œì‘ë¶€í„° ë‹¤ìŒ â–¡ ì„¹ì…˜ ì§ì „ê¹Œì§€ì˜ ì‹¤ì œ ì›ë¬¸ì…ë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ëŒì²˜ëŸ¼ ì½ì–´ì„œ í•´ë‹¹ êµ¬ê°„ì—ì„œ ìš”êµ¬í•˜ëŠ” í•˜ìœ„ í•­ëª©(ï¿­, 1), (ê°€) ë“±)ì„ ì¶”ì¶œí•˜ê³ , ì„¹ì…˜ì˜ ì‹¤ì œ ë‚´ìš©ì„ íŒŒì•…í•˜ì—¬ ëª©ì°¨ë¥¼ êµ¬ì„±í•˜ì„¸ìš”."

    # detected_outline ìƒì„±
    def summarize_sections(sections: List[Dict], label: str, limit: int = 10) -> str:
        if not sections:
            return f"- {label}: ê°ì§€ë˜ì§€ ì•ŠìŒ"
        lines = [f"- {label} (ìƒìœ„ {min(len(sections), limit)}ê°œ)"]
        for sec in sections[:limit]:
            lines.append(f"  â€¢ {sec.get('number', '-')}: {sec.get('title', '')}")
        if len(sections) > limit:
            lines.append(f"  â€¢ ... ì™¸ {len(sections) - limit}ê°œ")
        return '\n'.join(lines)

    detected_outline = '\n'.join([
        summarize_sections(table_sections, "í‘œ ê¸°ë°˜ í›„ë³´"),
        summarize_sections(symbol_sections, "ê¸°í˜¸/íŒ¨í„´ ê¸°ë°˜ í›„ë³´")
    ])

    user_prompt_parts = [
        f"""## í…œí”Œë¦¿ ì •ë³´
- íŒŒì¼ëª…: {template['file_name']}
- í˜ì´ì§€ ìˆ˜: {template_doc.get('page_count', '?')}
- í‘œ ìˆ˜: {len(tables)}""",
        f"""## ì‚¬ì „ ê°ì§€ëœ ëª©ì°¨ í›„ë³´ (ì°¸ê³ ìš©)
{detected_outline}""",
        f"""## ëª©ì°¨ í…ìŠ¤íŠ¸ (í‚¤ì›Œë“œ/íŒ¨í„´ ê¸°ë°˜)
{template_text}""",
        f"""## ì²¨ë¶€ ì–‘ì‹ í…ìŠ¤íŠ¸ (page_texts ë˜ëŠ” ì²­í¬)
{chunk_context}"""
    ]

    if skeleton_json:
        user_prompt_parts.append(f"""## ê°•ì œ ëª©ì°¨ ìŠ¤ì¼ˆë ˆí†¤ (number/titleì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
{skeleton_json}""")

    if section_contexts:
        MAX_CONTEXT_SECTIONS = 20
        trimmed_contexts = []
        for ctx in section_contexts:
            excerpt = ctx.get('excerpt', '').strip()
            if not excerpt:
                continue
            trimmed_contexts.append({
                'number': ctx['number'],
                'title': ctx['title'],
                'excerpt': excerpt[:600]
            })
            if len(trimmed_contexts) >= MAX_CONTEXT_SECTIONS:
                break

        if trimmed_contexts:
            context_json = json.dumps(trimmed_contexts, ensure_ascii=False, indent=2)
            user_prompt_parts.append(f"""## ì„¹ì…˜ë³„ ë³¸ë¬¸ ë°œì·Œ (ìƒìœ„ {len(trimmed_contexts)}ê°œ)
âš ï¸ ì¤‘ìš”: ì•„ë˜ ê° ì„¹ì…˜ì˜ "excerpt"ëŠ” í•´ë‹¹ â–¡ ì„¹ì…˜ì˜ ì‹œì‘ë¶€í„° ë‹¤ìŒ â–¡ ì„¹ì…˜ ì§ì „ê¹Œì§€ì˜ ì‹¤ì œ ì›ë¬¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ì„œ í•´ë‹¹ êµ¬ê°„ì—ì„œ ìš”êµ¬í•˜ëŠ” í•˜ìœ„ í•­ëª©(ï¿­, 1), (ê°€) ë“±)ê³¼ ì‹¤ì œ ì‘ì„± ë‚´ìš©ì„ íŒŒì•…í•˜ì„¸ìš”.

{context_json}""")

    user_prompt_parts.append("""---
ğŸ“‹ ìš”êµ¬ ì‚¬í•­:

1. **í¼ ì…ë ¥ í•„ë“œëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:**
   - âŒ ì œì™¸: "ê¸°ì—…ëª…", "ëŒ€í‘œì", "ì—°ë½ì²˜", "ì£¼ì†Œ", "ì „í™”", "íŒ©ìŠ¤", "mail", "íœ´ëŒ€ì „í™”", "ìƒë…„ì›”ì¼", "ì„±ë³„", "ì§ìœ„", "ë¶€ì„œ", "E-mail" ë“±
   - âŒ ì œì™¸: "1)ê¸°ì—…í˜„í™©", "2)ëŒ€í‘œì", "3)ì‹¤ë¬´ì±…ì„ì" ê°™ì€ í¼ ì„¹ì…˜ ë²ˆí˜¸
   - âœ… í¬í•¨: "â–¡ ê¸°ì—…í˜„í™©", "â–¡ ëŒ€í‘œì ë° ê²½ì˜ì§„ í˜„í™©", "â–¡ ëª©í‘œ" ê°™ì€ ë³¸ë¬¸ ì‘ì„± ì„¹ì…˜

2. **ì–‘ì‹ êµ¬ë¶„ì ë° ì‘ì„±ìš”ë ¹ ì œì™¸:**
   - âŒ ì œì™¸: "< ë³¸ë¬¸ 1 >", "< ë³¸ë¬¸ 2 >" (ì´ê²ƒì€ ì–‘ì‹ì˜ êµ¬ë¶„ìì¼ ë¿, ëª©ì°¨ í•­ëª©ì´ ì•„ë‹˜)
   - âŒ ì œì™¸: "ì‘ì„±ìš”ë ¹", "ì‘ì„± ìš”ë ¹", "ê¸°ì¬ìš”ë ¹" ì„¹ì…˜

3. **ê³„ì¸µ êµ¬ì¡° ëª…í™•íˆ:**
   - "1."ë¡œ ì‹œì‘í•˜ë©´ ì£¼ìš” ì„¹ì…˜ (number: "1", "2", "3" ...)
   - "1)"ë¡œ ì‹œì‘í•˜ë©´ í•˜ìœ„ ì„¹ì…˜ (number: "1.1", "1.2" ...)
   - "ê°€)"ë¡œ ì‹œì‘í•˜ë©´ í•˜ìœ„ ì„¹ì…˜ (number: "1.1.1", "1.2.1" ...)
   - **ì¤‘ë³µ ì œê±°**: ê°™ì€ ì œëª©ì´ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ë©´ í•˜ë‚˜ë§Œ í¬í•¨

4. **"ì„¹ì…˜ë³„ ë³¸ë¬¸ ë°œì·Œ" í™œìš©:**
   - ì œê³µëœ ê²½ìš°, ê° ì„¹ì…˜ì˜ excerpt í…ìŠ¤íŠ¸ë¥¼ ë°˜ë“œì‹œ ì½ì–´ì„œ description ì‘ì„±
   - excerptì—ì„œ í•˜ìœ„ í•­ëª©(1), 2), ê°€), ë‚˜) ë“±)ì„ í™•ì¸í•˜ì—¬ ì •í™•í•œ ê³„ì¸µ êµ¬ì¡° ìƒì„±

5. **ê° í•­ëª©ì— í¬í•¨í•  ì •ë³´:**
   - number: ê³„ì¸µ êµ¬ì¡°ë¥¼ ë°˜ì˜í•œ ë²ˆí˜¸ ("1", "1.1", "1.1.1" í˜•ì‹)
   - title: ì„¹ì…˜ ì œëª© (ê¸°í˜¸ ì œê±°, ì˜ˆ: "â–¡ ê¸°ì—…í˜„í™©" â†’ "ê¸°ì—…í˜„í™©")
   - description: í•´ë‹¹ ì„¹ì…˜ì—ì„œ ìš”êµ¬í•˜ëŠ” ì‘ì„± ë‚´ìš© ìš”ì•½ (1-2ë¬¸ì¥)

6. **ì¶œë ¥ í˜•ì‹ (JSON):**
{
  "sections": [
    {
      "number": "1",
      "title": "ì—°êµ¬ê°œë°œê³¼ì œì˜ í•„ìš”ì„±",
      "description": "ì—°êµ¬ê°œë°œê³¼ì œì™€ ê´€ë ¨ë˜ëŠ” êµ­ë‚´ì™¸ í˜„í™© ë° ë¬¸ì œì , ì „ë§, í•„ìš”ì„±"
    },
    {
      "number": "2",
      "title": "ì—°êµ¬ê°œë°œê³¼ì œì˜ ëª©í‘œ ë° ë‚´ìš©",
      "description": "ì—°êµ¬ê°œë°œ ëª©í‘œ, ë‚´ìš©, ìˆ˜í–‰ì¼ì • ë° ê²°ê³¼ë¬¼"
    },
    {
      "number": "2.1",
      "title": "ì—°êµ¬ê°œë°œê³¼ì œì˜ ëª©í‘œ",
      "description": "ì—°êµ¬ê°œë°œí•˜ê³ ì í•˜ëŠ” ì§€ì‹, ê¸°ìˆ ì˜ ì •ì„±ì /ì •ëŸ‰ì  ëª©í‘œ"
    }
  ]
}""")

    user_prompt = "\n\n".join(user_prompt_parts)

    return system_prompt, user_prompt


def process_llm_response(
    llm_sections: List[Dict],
    base_sections: List[Dict],
    template: Dict
) -> Dict:
    """
    LLM ì‘ë‹µì„ base_sectionsì™€ ë³‘í•©í•˜ì—¬ ìµœì¢… ëª©ì°¨ ìƒì„±

    ì£¼ìš” ê°œì„ ì‚¬í•­:
    1. í¼ í•„ë“œ í•„í„°ë§ì„ í•­ìƒ ì‹¤í–‰ (base_sections ìœ ë¬´ì™€ ê´€ê³„ì—†ì´)
    2. í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´ ì œì™¸ ("- 10 -" ê°™ì€ íŒ¨í„´)
    3. í‘œ ë‚´ìš© íŒ¨í„´ ì œì™¸ ("TO BE >", "AS IS" ë“±)
    4. ì¤‘ë³µ ì œê±° (ê°™ì€ titleì´ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ë©´ ì²« ë²ˆì§¸ë§Œ ìœ ì§€)
    5. Description ê¸¸ì´ ì œí•œ (ìµœëŒ€ 200ì)
    """
    # ğŸ”§ ê°œì„  1: í¼ í•„ë“œ ë° ì œì™¸ í‚¤ì›Œë“œ ì •ì˜ (í•­ìƒ ì ìš©)
    form_field_keywords = [
        'mail', 'e-mail', 'ì´ë©”ì¼', 'íŒ©ìŠ¤', 'íœ´ëŒ€ì „í™”', 'ì „í™”', 'ì£¼ì†Œ',
        'ìƒë…„ì›”ì¼', 'ì„±ë³„', 'ì§ìœ„', 'ë¶€ì„œ', 'ê³¼ì œëª…', 'ê¸°ê´€ëª…', 'ì‚¬ì—…ë¹„',
        'ëŒ€í‘œì', 'ì‹¤ë¬´ì±…ì„ì', 'ì—°ë½ì²˜', 'ë‹´ë‹¹ì'
    ]

    # í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´
    page_number_pattern = re.compile(r'^-\s*\d+\s*-$')

    # í‘œ ë‚´ìš© íŒ¨í„´
    table_content_keywords = ['TO BE', 'AS IS', 'IS TO', 'BE ê¸°ëŒ€íš¨ê³¼', 'â‡¨']

    # ì˜ˆì‹œ/ìƒ˜í”Œ íŒ¨í„´
    example_keywords = ['í™ê¸¸ë™', 'OOì²œì›', 'ì˜ˆì‹œ', 'ìƒ˜í”Œ', 'ì‘ì„±ì˜ˆ']

    # ì²´í¬ë°•ìŠ¤ ë°˜ë³µ í•­ëª© (ì„±ê³¼ì§€í‘œ ê´€ë ¨)
    checkbox_duplicates = ['íˆ¬ì…', 'ê³¼ì •', 'ì‚°ì¶œ', 'ê²°ê³¼']

    if base_sections:
        # base_sectionsê°€ ìˆìœ¼ë©´ LLM ê²°ê³¼ì™€ ë³‘í•©
        llm_map = {sec.get('number'): sec for sec in llm_sections}
        raw_sections = []

        for base in base_sections:
            llm_candidate = llm_map.get(base['number'], {})
            description = llm_candidate.get('description') or base.get('excerpt', '')

            if not isinstance(description, str):
                description = str(description) if description is not None else ''

            # ğŸ”§ ê°œì„  5: Description ê¸¸ì´ ì œí•œ (ìµœëŒ€ 200ì)
            if len(description) > 200:
                description = description[:197] + '...'

            merged = {
                'number': base['number'],
                'title': base['title'],
                'description': description.strip()
            }
            raw_sections.append(merged)
    else:
        # base_sectionsê°€ ì—†ìœ¼ë©´ LLM ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        raw_sections = llm_sections

    # ğŸ”§ ê°œì„  1-4: ëª¨ë“  ì„¹ì…˜ì— ëŒ€í•´ í•„í„°ë§ ì ìš©
    final_sections = []
    seen_titles = set()  # ì¤‘ë³µ ì²´í¬ìš©
    checkbox_count = {}  # ì²´í¬ë°•ìŠ¤ í•­ëª© ì¹´ìš´íŠ¸

    for sec in raw_sections:
        original_title = sec.get('title', '')
        title_lower = original_title.lower()

        # ğŸ”§ í•„í„° 1: í¼ í•„ë“œ í‚¤ì›Œë“œ ì²´í¬
        if any(keyword in title_lower for keyword in form_field_keywords):
            continue

        # ğŸ”§ í•„í„° 2: í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´ ì²´í¬ ("- 10 -" ê°™ì€ íŒ¨í„´)
        if page_number_pattern.match(original_title.strip()):
            continue

        # ğŸ”§ í•„í„° 3: í‘œ ë‚´ìš© íŒ¨í„´ ì²´í¬
        if any(keyword in original_title for keyword in table_content_keywords):
            continue

        # ğŸ”§ í•„í„° 4: ì˜ˆì‹œ/ìƒ˜í”Œ íŒ¨í„´ ì²´í¬
        if any(keyword in original_title for keyword in example_keywords):
            continue

        # ğŸ”§ í•„í„° 5: ì²´í¬ë°•ìŠ¤ ì¤‘ë³µ í•­ëª© ì œí•œ (ìµœëŒ€ 2ë²ˆê¹Œì§€ë§Œ)
        if original_title in checkbox_duplicates:
            checkbox_count[original_title] = checkbox_count.get(original_title, 0) + 1
            if checkbox_count[original_title] > 2:
                continue

        # ğŸ”§ í•„í„° 6: ì¤‘ë³µ ì œê±° (ê°™ì€ titleì´ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ë©´ ì²« ë²ˆì§¸ë§Œ ìœ ì§€)
        if original_title in seen_titles:
            continue

        seen_titles.add(original_title)

        # Description ê¸¸ì´ ì œí•œ ì ìš© (base_sectionsê°€ ì—†ëŠ” ê²½ìš°ì—ë„)
        description = sec.get('description', '')
        if len(description) > 200:
            description = description[:197] + '...'

        final_sections.append({
            'number': sec.get('number', ''),
            'title': original_title,
            'description': description
        })

    if not final_sections:
        print(f"    âš ï¸  í•„í„°ë§ í›„ ì„¹ì…˜ì´ ì—†ìŒ")
        raise ValueError("ìœ íš¨í•œ ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")

    toc = {
        'source': 'template',
        'source_file': template['file_name'],
        'extraction_method': 'llm_template_chunks',
        'sections': final_sections,
        'total_sections': len(final_sections),
        'has_page_numbers': False,
        'extracted_at': datetime.now().isoformat()
    }

    return toc
