"""
ì²¨ë¶€ ì–‘ì‹ ê°ì§€ ëª¨ë“ˆ
ì œì•ˆì„œ/ê³„íšì„œ ì–‘ì‹ ì—¬ë¶€ë¥¼ RAG + ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨

âœ… í•µì‹¬ ê¸°ëŠ¥: ì²¨ë¶€ì„œë¥˜ ì¤‘ ì–´ë–¤ íŒŒì¼ì´ "ì‘ì„±í•´ì•¼ í•  ì–‘ì‹"ì¸ì§€ ìë™ ê°ì§€
ğŸ“Œ ëª©ì : ì–‘ì‹ ê¸°ë°˜ ëª©ì°¨ ì¶”ì¶œ vs ê³µê³  ê¸°ë°˜ ëª©ì°¨ ìœ ì¶” ë¶„ê¸° ê²°ì •
"""

from datetime import datetime
from typing import List, Dict, Any
import unicodedata
import numpy as np

from ..state_types import BatchState


def detect_proposal_templates(state: BatchState) -> BatchState:
    """
    ì²¨ë¶€ì„œë¥˜ì—ì„œ ì œì•ˆì„œ ì–‘ì‹ ê°ì§€ (RAG + ê·œì¹™ ê¸°ë°˜)

    âœ… í•„ìˆ˜ ë…¸ë“œ: ëª©ì°¨ ì¶”ì¶œ ë°©ì‹ ê²°ì •ì˜ í•µì‹¬

    ğŸ” ê°ì§€ ì‹ í˜¸ (ë‹¤ì¤‘ ì‹ í˜¸ ìœµí•©):
    1. íŒŒì¼ëª… í‚¤ì›Œë“œ ('ê³„íšì„œ', 'ì‹ ì²­ì„œ', 'ì œì•ˆì„œ', 'ì–‘ì‹')
    2. ê³µê³ ë¬¸ì—ì„œ ì²¨ë¶€íŒŒì¼ ì–¸ê¸‰ ('ë¶™ì„1', 'ë³„ì²¨2' ë“±)
    3. RAG ê²€ìƒ‰: ì–‘ì‹ ê´€ë ¨ í‚¤ì›Œë“œ ('ì–‘ì‹', 'ì„œì‹', 'ì‘ì„±ì˜ˆì‹œ')
    4. í‘œ êµ¬ì¡° ì¡´ì¬ (ì…ë ¥ ì¹¸ì´ ìˆëŠ” í‘œ)

    Returns:
        state['attachment_templates']: ì–‘ì‹ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        - has_template: True/False (ì–‘ì‹ ì—¬ë¶€)
        - confidence_score: ì‹ ë¢°ë„ (0.0-1.0)
        - fields: ì¶”ì¶œëœ í•„ë“œ ëª©ë¡
    """
    collection = state['chroma_collection']
    model = state['embedding_model']
    documents = state['documents']
    all_features = state.get('extracted_features', [])

    print(f"\n{'='*60}")
    print(f"ğŸ“‹ ì²¨ë¶€ ì–‘ì‹ ê°ì§€ (RAG ê¸°ë°˜)")
    print(f"{'='*60}")

    attachment_templates = []
    attachment_docs = [d for d in documents if d.get('folder') == 2]

    if not attachment_docs:
        print("\n  âš ï¸  ì²¨ë¶€ ë¬¸ì„œ(folder=2)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        state['attachment_templates'] = []
        return state

    # 1ï¸âƒ£ ê³µê³ ë¬¸ì—ì„œ "ì œì¶œì„œë¥˜" feature ì°¾ê¸°
    submission_features = [
        f for f in all_features
        if f['feature_code'] == 'submission_docs'  # "ì œì¶œì„œë¥˜" feature
    ]

    # 2ï¸âƒ£ ê° ì²¨ë¶€íŒŒì¼ì— ëŒ€í•´ ì–‘ì‹ ì—¬ë¶€ íŒë‹¨
    for att_doc in attachment_docs:
        file_name_raw = att_doc['file_name']
        file_name = unicodedata.normalize('NFC', file_name_raw)
        attachment_num = att_doc.get('attachment_number')

        print(f"\n  ğŸ“„ {file_name}")

        # ì‹ í˜¸ 1: íŒŒì¼ëª… í‚¤ì›Œë“œ ì²´í¬
        keyword_weights = {
            'ê³„íšì„œ': 0.5,
            'ì œì•ˆì„œ': 0.45,
            'ì‹ ì²­ì„œ': 0.5,  # ì‹ ì²­ì„œ ê°€ì¤‘ì¹˜ ìƒí–¥ (0.35 â†’ 0.5)
            'ì–‘ì‹': 0.2,
            'ì„œì‹': 0.2,
            'ì‘ì„±ìš”ë ¹': 0.2
        }
        matched_keywords = [kw for kw in keyword_weights if kw in file_name]
        keyword_score = max((keyword_weights[kw] for kw in matched_keywords), default=0.0)
        confidence_score = keyword_score

        if matched_keywords:
            print(f"    - íŒŒì¼ëª… í‚¤ì›Œë“œ: âœ“ {matched_keywords} (ì‹ ë¢°ë„: +{keyword_score:.2f})")
        else:
            print("    - íŒŒì¼ëª… í‚¤ì›Œë“œ: âœ— (ì‹ ë¢°ë„: +0.0)")

        # ì‹ í˜¸ 2: ê³µê³ ë¬¸ì—ì„œ í•´ë‹¹ ì²¨ë¶€íŒŒì¼ ì–¸ê¸‰ ì²´í¬
        mentioned_in_announcement = False
        mention_context = ""

        for sub_feature in submission_features:
            # ì²¨ë¶€ë²ˆí˜¸ê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ ì²´í¬
            full_content = sub_feature.get('full_content', '')
            if attachment_num:
                if f"ë¶™ì„{attachment_num}" in full_content or f"ë¶™ì„ {attachment_num}" in full_content:
                    mentioned_in_announcement = True
                    mention_context = full_content[:200]
                    confidence_score += 0.3
                    break
                elif f"ë³„ì²¨{attachment_num}" in full_content or f"ë³„ì²¨ {attachment_num}" in full_content:
                    mentioned_in_announcement = True
                    mention_context = full_content[:200]
                    confidence_score += 0.3
                    break

        print(f"    - ê³µê³ ë¬¸ ì–¸ê¸‰: {'âœ“' if mentioned_in_announcement else 'âœ—'} (ì‹ ë¢°ë„: +{0.3 if mentioned_in_announcement else 0.0})")

        # ì‹ í˜¸ 3: RAGë¡œ ì²¨ë¶€íŒŒì¼ ìì²´ì—ì„œ "ì–‘ì‹" ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        try:
            # OpenAI APIë¡œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (processing.pyì˜ extract_features_ragì™€ ë™ì¼í•œ ë°©ì‹)
            from openai import OpenAI
            import os
            from dotenv import load_dotenv
            
            load_dotenv()
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            query_text = "ì–‘ì‹ ì„œì‹ ì‘ì„±ì˜ˆì‹œ ì‘ì„±ë°©ë²• ì…ë ¥ì¹¸"
            query_response = client.embeddings.create(
                model="text-embedding-3-small",
                input=[query_text]
            )
            query_embedding = [query_response.data[0].embedding]

            results = collection.query(
                query_embeddings=query_embedding,
                n_results=3,
                where={'file_name': file_name}  # í•´ë‹¹ íŒŒì¼ë§Œ ê²€ìƒ‰
            )

            if results['ids'][0] and results['distances'][0][0] < 0.8:
                confidence_score += 0.4
                print(f"    - RAG ì–‘ì‹ í‚¤ì›Œë“œ: âœ“ (ê±°ë¦¬: {results['distances'][0][0]:.2f}, ì‹ ë¢°ë„: +0.4)")
            else:
                print(f"    - RAG ì–‘ì‹ í‚¤ì›Œë“œ: âœ—")
        except Exception as e:
            print(f"    - RAG ì–‘ì‹ í‚¤ì›Œë“œ: âœ— (ê²€ìƒ‰ ì‹¤íŒ¨: {e})")

        # ì‹ í˜¸ 4: í‘œ êµ¬ì¡° ë¶„ì„
        tables = att_doc.get('tables', [])
        valid_tables = [t for t in tables if t['rows'] >= 2]
        has_table_structure = len(valid_tables) >= 1

        if has_table_structure:
            confidence_score += 0.2
            print(f"    - í‘œ êµ¬ì¡°: âœ“ ({len(valid_tables)}ê°œ ìœ íš¨ í‘œ, ì‹ ë¢°ë„: +0.2)")
        else:
            print(f"    - í‘œ êµ¬ì¡°: âœ—")

        # ê³„íšì„œ/ì‹ ì²­ì„œ ì²¨ë¶€ ë²ˆí˜¸ ê°€ì¤‘ì¹˜ (ë¶™ì„ 1, 2 ë“±ì— ìš°ì„ ìˆœìœ„ ë¶€ì—¬)
        if attachment_num in (1, 2):
            if 'ê³„íšì„œ' in file_name:
                confidence_score += 0.15
                print(f"    - ì²¨ë¶€ë²ˆí˜¸/ê³„íšì„œ ìš°ì„  ê°€ì¤‘ì¹˜ ì ìš© (+0.15)")
            elif 'ì‹ ì²­ì„œ' in file_name:
                confidence_score += 0.1
                print(f"    - ì²¨ë¶€ë²ˆí˜¸/ì‹ ì²­ì„œ ìš°ì„  ê°€ì¤‘ì¹˜ ì ìš© (+0.1)")
        
        # ì‹ ì²­ì„œ + í‘œ êµ¬ì¡° ì¡°í•© ê°€ì¤‘ì¹˜ (ì‹ ì²­ì„œëŠ” ë³´í†µ í‘œ êµ¬ì¡°ê°€ ìˆìœ¼ë©´ ì–‘ì‹ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
        if 'ì‹ ì²­ì„œ' in file_name and has_table_structure:
            confidence_score += 0.1
            print(f"    - ì‹ ì²­ì„œ+í‘œêµ¬ì¡° ì¡°í•© ê°€ì¤‘ì¹˜ ì ìš© (+0.1)")

        # ìµœì¢… íŒë‹¨ (ì„ê³„ê°’: 0.6)
        is_template = confidence_score >= 0.6

        # í•„ë“œ ì¶”ì¶œ (ì–‘ì‹ì¸ ê²½ìš°ì—ë§Œ)
        fields = []
        if is_template and has_table_structure:
            fields = _extract_fields_from_tables(valid_tables)

        # í…œí”Œë¦¿ ì •ë³´ ì €ì¥
        template_info = {
            'document_id': att_doc['document_id'],
            'file_name': file_name,
            'attachment_number': attachment_num,
            'has_template': is_template,
            'confidence_score': round(confidence_score, 2),
            'detection_signals': {
                'filename_keyword': matched_keywords,
                'announcement_mention': mentioned_in_announcement,
                'table_structure': has_table_structure
            },
            'fields': fields,
            'tables': valid_tables,  # ëª©ì°¨ ì¶”ì¶œì— ì‚¬ìš©
            'mention_context': mention_context if mentioned_in_announcement else None,
            'extracted_at': datetime.now().isoformat()
        }

        attachment_templates.append(template_info)

        print(f"    â†’ ìµœì¢… íŒë‹¨: {'âœ… ì–‘ì‹ ë¬¸ì„œ' if is_template else 'âŒ ì¼ë°˜ ë¬¸ì„œ'} (ì‹ ë¢°ë„: {confidence_score:.2f})")

    state['attachment_templates'] = attachment_templates

    # ìš”ì•½
    templates_with_forms = [t for t in attachment_templates if t['has_template']]
    print(f"\n  âœ… ì–‘ì‹ ê°ì§€ ì™„ë£Œ:")
    print(f"    - ì „ì²´ ì²¨ë¶€: {len(attachment_templates)}ê°œ")
    print(f"    - ì–‘ì‹ ë¬¸ì„œ: {len(templates_with_forms)}ê°œ")

    return state


def _extract_fields_from_tables(valid_tables: List[Dict]) -> List[Dict[str, str]]:
    """
    í‘œì—ì„œ í•„ë“œ ì¶”ì¶œ (í—¤ë” ë¶„ì„)

    Args:
        valid_tables: í‘œ ì •ë³´ ë¦¬ìŠ¤íŠ¸

    Returns:
        í•„ë“œ ë¦¬ìŠ¤íŠ¸ [{'field_name': 'í•­ëª©ëª…', 'field_type': 'text', 'source': 'table_header'}, ...]
    """
    fields = []

    for table_info in valid_tables[:1]:  # ì²« ë²ˆì§¸ í‘œë§Œ ë¶„ì„
        table_data = table_info['data']
        if len(table_data) >= 2 and table_data[0]:
            headers = table_data[0]
            for col_idx, header in enumerate(headers):
                if header and header.strip():
                    field_name = header.strip()

                    # í•„ë“œ íƒ€ì… ì¶”ë¡ 
                    field_type = 'text'
                    if any(kw in field_name for kw in ['ë‚ ì§œ', 'ì¼ì']):
                        field_type = 'date'
                    elif any(kw in field_name for kw in ['ê¸ˆì•¡', 'ìˆ˜ëŸ‰']):
                        field_type = 'number'

                    fields.append({
                        'field_name': field_name,
                        'field_type': field_type,
                        'source': 'table_header'
                    })

    return fields
