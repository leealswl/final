"""
ëª©ì°¨(Table of Contents) ì¶”ì¶œ ëª¨ë“ˆ
ì œì•ˆì„œ ì–‘ì‹ ë˜ëŠ” ê³µê³ ë¬¸/ì²¨ë¶€ì„œë¥˜ì—ì„œ ëª©ì°¨ êµ¬ì¡° ì¶”ì¶œ
"""

import re
import json
import unicodedata
from datetime import datetime
from typing import List, Dict, Any, Optional
from openai import OpenAI
import os
from dotenv import load_dotenv

from ..state_types import BatchState

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def route_toc_extraction(state: BatchState) -> str:
    """
    ëª©ì°¨ ì¶”ì¶œ ë°©ë²• ê²°ì • (ì¡°ê±´ë¶€ ë¼ìš°íŒ…)

    Returns:
        "extract_toc_from_template" - ì–‘ì‹ ê¸°ë°˜ ì¶”ì¶œ
        "extract_toc_from_announcement_and_attachments" - ê³µê³  + ì²¨ë¶€ì„œë¥˜ ê¸°ë°˜ ì¶”ì¶œ
    """
    templates = state.get('attachment_templates', [])
    proposal_template = _find_proposal_template(templates)

    if proposal_template:
        return "extract_toc_from_template"
    else:
        return "extract_toc_from_announcement_and_attachments"


# ë¼ìš°íŒ…í• ë•Œ ì–‘ì‹ ì°¾ê¸°
def _find_proposal_template(templates: List[Dict]) -> Optional[Dict]:
    """
    ì œì•ˆì„œ ì–‘ì‹ ì°¾ê¸° (ìš°ì„ ìˆœìœ„: ì œì•ˆì„œ > ê³„íšì„œ > ì‹ ì²­ì„œ)
    """
    if not templates:
        return None

    # ì–‘ì‹ìœ¼ë¡œ ê°ì§€ëœ ê²ƒë§Œ í•„í„°ë§
    valid_templates = [t for t in templates if t.get('has_template')]

    if not valid_templates:
        return None

    # ìš°ì„ ìˆœìœ„/ê°€ì¤‘ì¹˜ ê³„ì‚°
    def template_priority(template: Dict) -> float:
        file_name = template.get('file_name', '')
        score = template.get('confidence_score', 0.0)

        # íŒŒì¼ëª… í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
        keyword_weights = {
            'ê³„íšì„œ': 1.0,
            'ì œì•ˆì„œ': 0.8,
            'ì‹ ì²­ì„œ': 0.6,
            'ì–‘ì‹': 0.2
        }
        for keyword, weight in keyword_weights.items():
            if keyword in file_name:
                score += weight

        # ì²¨ë¶€ ë²ˆí˜¸ê°€ 2 (ë¶™ì„2)ë©´ ì¶”ê°€ ê°€ì¤‘ì¹˜
        attachment_num = template.get('attachment_number')
        if attachment_num == 2:
            score += 0.3

        return score

    # ê³„íšì„œê°€ í¬í•¨ëœ í…œí”Œë¦¿ì´ ìˆìœ¼ë©´ ìµœìš°ì„  ë°˜í™˜
    for template in valid_templates:
        if 'ê³„íšì„œ' in template.get('file_name', ''):
            return template

    # ê·¸ ì™¸ëŠ” ìµœê³  ì ìˆ˜ í…œí”Œë¦¿ ë°˜í™˜
    return max(valid_templates, key=template_priority)


def extract_toc_from_template(state: BatchState) -> BatchState:
    """
    ì œì•ˆì„œ ì–‘ì‹ì—ì„œ ëª©ì°¨ ì¶”ì¶œ (LangGraph ë…¸ë“œ)

    ë°©ë²•:
    1. í‘œ êµ¬ì¡°ì—ì„œ ëª©ì°¨ ì„¹ì…˜ ì°¾ê¸° (í‚¤ì›Œë“œ: "ëª©ì°¨", "ì‘ì„±í•­ëª©", "êµ¬ì„±")
    2. ê° í–‰ì—ì„œ ì„¹ì…˜ ë²ˆí˜¸, ì œëª©, í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ
    3. ê³„ì¸µ êµ¬ì¡° íŒŒì‹± (1. â†’ 1.1. â†’ 1.1.1.)

    Returns:
        state: table_of_contents ì—…ë°ì´íŠ¸ëœ BatchState
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“‘ ì–‘ì‹ì—ì„œ ëª©ì°¨ ì¶”ì¶œ")
    print(f"{'='*60}")

    # ì–‘ì‹ ì°¾ê¸°
    templates = state.get('attachment_templates', [])
    template = _find_proposal_template(templates)

    if not template:
        print(f"\n  âš ï¸  ì–‘ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        state['table_of_contents'] = _create_default_toc()
        state['status'] = 'toc_extracted'
        return state

    print(f"\n  ğŸ“‹ ì–‘ì‹: {template['file_name']}")

    tables = template.get('tables', [])
    if not tables:
        print(f"  âœ— í‘œ êµ¬ì¡° ì—†ìŒ â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        state['table_of_contents'] = _create_default_toc()
        state['status'] = 'toc_extracted'
        return state

    # ëª©ì°¨ ê´€ë ¨ í‘œ ì°¾ê¸°
    toc_table = _find_toc_table(tables)

    if not toc_table:
        print(f"  âš ï¸  ëª©ì°¨ í‘œ ì°¾ê¸° ì‹¤íŒ¨ â†’ LLM ê¸°ë°˜ ì¶”ì¶œ ì‹œë„")
        # LLMìœ¼ë¡œ ì–‘ì‹ í…ìŠ¤íŠ¸ ì „ì²´ ë¶„ì„
        return _extract_toc_from_template_with_llm(state, template)

    # í‘œì—ì„œ ì„¹ì…˜ ì¶”ì¶œ
    sections = _parse_toc_table(toc_table['data'])

    if not sections:
        print(f"  âš ï¸  ì„¹ì…˜ íŒŒì‹± ì‹¤íŒ¨ â†’ LLM ê¸°ë°˜ ì¶”ì¶œ ì‹œë„")
        # LLMìœ¼ë¡œ ì–‘ì‹ í…ìŠ¤íŠ¸ ì „ì²´ ë¶„ì„
        return _extract_toc_from_template_with_llm(state, template)

    toc = {
        'source': 'template',
        'source_file': template['file_name'],
        'extraction_method': 'table_parsing',
        'sections': sections,
        'total_sections': len(sections),
        'has_page_numbers': any(s.get('page') for s in sections),
        'extracted_at': datetime.now().isoformat()
    }

    state['table_of_contents'] = toc
    state['status'] = 'toc_extracted'

    print(f"\n  âœ… ì–‘ì‹ì—ì„œ {len(sections)}ê°œ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ")
    for sec in sections[:5]:
        print(f"    â€¢ {sec.get('number', '')} {sec.get('title', '')}")
    if len(sections) > 5:
        print(f"    ... ì™¸ {len(sections) - 5}ê°œ")

    return state


def _find_toc_table(tables: List[Dict]) -> Optional[Dict]:
    """
    ëª©ì°¨ ê´€ë ¨ í‘œ ì°¾ê¸°

    ì¡°ê±´:
    - ì²« ë²ˆì§¸ í–‰ì— "ëª©ì°¨", "ì‘ì„±í•­ëª©", "êµ¬ì„±", "í•­ëª©" ë“± í‚¤ì›Œë“œ í¬í•¨
    - ë˜ëŠ” ë²ˆí˜¸(1., 2., ê°€., ë‚˜.) íŒ¨í„´ì´ ë§ì´ í¬í•¨ëœ í‘œ
    """
    TOC_KEYWORDS = ['ëª©ì°¨', 'ì‘ì„±í•­ëª©', 'êµ¬ì„±', 'í•­ëª©', 'ë‚´ìš©', 'ì œì¶œì„œë¥˜']

    for table in tables:
        data = table['data']
        if not data or len(data) < 2:
            continue

        # ì²« ë²ˆì§¸ í–‰ ê²€ì‚¬
        first_row = ' '.join([str(cell) for cell in data[0] if cell])

        if any(kw in first_row for kw in TOC_KEYWORDS):
            return table

        # ì „ì²´ ë°ì´í„°ì—ì„œ ë²ˆí˜¸ íŒ¨í„´ ë¹„ìœ¨ ì²´í¬
        all_text = '\n'.join([' '.join([str(cell) for cell in row if cell]) for row in data])
        number_pattern_count = len(re.findall(r'\d+\.|ê°€\.|ë‚˜\.|ë‹¤\.|â‘ |â‘¡|â‘¢', all_text))

        if number_pattern_count >= len(data) * 0.3:  # í–‰ì˜ 30% ì´ìƒì´ ë²ˆí˜¸ íŒ¨í„´
            return table

    return None


def _parse_toc_table(table_data: List[List[str]]) -> List[Dict]:
    """
    ëª©ì°¨ í‘œì—ì„œ ì„¹ì…˜ ì •ë³´ ì¶”ì¶œ

    Args:
        table_data: 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ [[cell, cell, ...], ...]

    Returns:
        ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸ [{'number': '1', 'title': 'ì—°êµ¬ëª©ì ', 'page': 3}, ...]
    """
    sections = []

    # í—¤ë” ìŠ¤í‚µ (ì²« ë²ˆì§¸ í–‰)
    for row_idx, row in enumerate(table_data[1:], start=1):
        if not row or not any(row):  # ë¹ˆ í–‰ ìŠ¤í‚µ
            continue

        row_text = ' '.join([str(cell).strip() for cell in row if cell])

        # ì„¹ì…˜ ë²ˆí˜¸ ì¶”ì¶œ (íŒ¨í„´: 1., 1.1., ê°€., â‘ , I., ë“±)
        number_match = re.search(
            r'^(\d+\.?\d*\.?|[ê°€-í£]\.?|[â‘ -â‘³]|[IVX]+\.?)',
            row_text
        )

        if not number_match:
            continue

        section_number = number_match.group(1).strip('.')
        remaining_text = row_text[number_match.end():].strip()

        # ì œëª©ê³¼ í˜ì´ì§€ ë²ˆí˜¸ ë¶„ë¦¬
        # íŒ¨í„´: "ì œëª© ... í˜ì´ì§€ë²ˆí˜¸" ë˜ëŠ” "ì œëª©"
        page_match = re.search(r'(\d+)\s*$', remaining_text)

        if page_match:
            page_number = int(page_match.group(1))
            title = remaining_text[:page_match.start()].strip()
        else:
            page_number = None
            title = remaining_text

        # ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì œëª© í•„í„°ë§
        if len(title) < 2 or title in ['í•©ê³„', 'ê³„', 'ë¹„ê³ ', '']:
            continue

        sections.append({
            'number': section_number,
            'title': title,
            'page': page_number,
            'row_index': row_idx
        })

    return sections


def extract_toc_from_announcement_and_attachments(state: BatchState) -> BatchState:
    """
    ê³µê³ ë¬¸ + ëª¨ë“  ì²¨ë¶€ì„œë¥˜ì—ì„œ ëª©ì°¨ ìœ ì¶” (RAG + LLM) - LangGraph ë…¸ë“œ

    âš ï¸ ì–‘ì‹ì´ ì—†ëŠ” ê²½ìš°, ê³µê³ ë¬¸ê³¼ ëª¨ë“  ì²¨ë¶€ì„œë¥˜(RFP, ê°€ì´ë“œ ë“±)ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ëª©ì°¨ ìƒì„±

    ë°©ë²•:
    1. ê³µê³ ë¬¸ì—ì„œ "ì œì¶œì„œë¥˜" feature ì°¾ê¸°
    2. RAGë¡œ ëª¨ë“  ë¬¸ì„œ(ê³µê³ +ì²¨ë¶€)ì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
    3. LLMìœ¼ë¡œ ëª©ì°¨ êµ¬ì¡° ìƒì„±

    Returns:
        state: table_of_contents ì—…ë°ì´íŠ¸ëœ BatchState
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“‘ ê³µê³ ë¬¸ + ì²¨ë¶€ì„œë¥˜ ê¸°ë°˜ ëª©ì°¨ ìœ ì¶”")
    print(f"{'='*60}")

    all_features = state.get('extracted_features', [])
    collection = state['chroma_collection']

    # 1ï¸âƒ£ ì œì¶œì„œë¥˜ feature ì°¾ê¸°
    submission_features = [
        f for f in all_features
        if f['feature_code'] == 'submission_docs'
    ]

    if not submission_features:
        print(f"\n  âš ï¸  'ì œì¶œì„œë¥˜' feature ì—†ìŒ â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        state['table_of_contents'] = _create_default_toc()
        state['status'] = 'toc_extracted'
        return state

    submission_content = '\n\n'.join([
        f.get('full_content', '') for f in submission_features
    ])

    # 2ï¸âƒ£ RAGë¡œ ëª¨ë“  ë¬¸ì„œ(ê³µê³ +ì²¨ë¶€) ê²€ìƒ‰ (ë³¼ë¥¨ ì¦ê°€ë¥¼ ìœ„í•´ ê²€ìƒ‰ ê²°ê³¼ í™•ëŒ€)
    try:
        # OpenAI APIë¡œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (processing.pyì˜ extract_features_ragì™€ ë™ì¼í•œ ë°©ì‹)
        query_text = "ì œì¶œì„œë¥˜ ì‘ì„±í•­ëª© êµ¬ì„± ëª©ì°¨ ì œì•ˆì„œ ê³„íšì„œ ì‚¬ì—…ê³„íšì„œ ìš´ì˜ê³„íš"
        query_response = client.embeddings.create(
            model="text-embedding-3-small",
            input=[query_text]
        )
        query_embedding = [query_response.data[0].embedding]

        # âœ… ëª¨ë“  ë¬¸ì„œì—ì„œ ê²€ìƒ‰ (ATTACHMENT í•„í„° ì œê±°)
        results = collection.query(
            query_embeddings=query_embedding,
            n_results=25  # 15 â†’ 25ë¡œ ì¦ê°€: ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ í™•ë³´
            # where ì¡°ê±´ ì œê±° â†’ ê³µê³ ë¬¸ + ëª¨ë“  ì²¨ë¶€ì„œë¥˜ ê²€ìƒ‰
        )

        all_chunks = []
        if results['ids'][0]:
            for i in range(len(results['ids'][0])):
                all_chunks.append({
                    'text': results['documents'][0][i],
                    'file': results['metadatas'][0][i]['file_name'],
                    'section': results['metadatas'][0][i]['section'],
                    'doc_type': results['metadatas'][0][i].get('document_type', 'UNKNOWN')
                })
            print(f"    âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(all_chunks)}ê°œ ì²­í¬ (ê³µê³  + ì²¨ë¶€ì„œë¥˜)")
    except Exception as e:
        print(f"    âœ— RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        all_chunks = []

    # 3ï¸âƒ£ LLMìœ¼ë¡œ ëª©ì°¨ ìƒì„±
    print(f"    ğŸ¤– LLMìœ¼ë¡œ ëª©ì°¨ êµ¬ì¡° ìƒì„± ì¤‘...")

    # ë¬¸ì„œ íƒ€ì…ë³„ë¡œ ì •ë¦¬ (ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ í™œìš©)
    document_context = '\n\n'.join([
        f"[{c['doc_type']} - {c['file']} - {c['section']}]\n{c['text']}"
        for c in all_chunks[:20]  # 10 â†’ 20ìœ¼ë¡œ ì¦ê°€: ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
    ])

    system_prompt = """ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… ê³µê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ê³µê³ ë¬¸ê³¼ ì²¨ë¶€ì„œë¥˜ë¥¼ ë¶„ì„í•˜ì—¬ **ì‹ ì²­ ì‹œ ì œì¶œí•´ì•¼ í•˜ëŠ” ê³„íšì„œì˜ ì‘ì„± í•­ëª©(ëª©ì°¨)**ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ê³µê³ ì˜ ì„±ê²©ì„ ë¨¼ì € íŒŒì•…í•˜ì„¸ìš”:
- ì—°êµ¬ê°œë°œ(R&D) ê³¼ì œ ê³µê³  â†’ ì—°êµ¬ê³„íšì„œ ëª©ì°¨
- ì°½ì—…ì§€ì› ì‚¬ì—… ê³µê³  â†’ ì‚¬ì—…ê³„íšì„œ ëª©ì°¨
- ì£¼ê´€ê¸°ê´€ ì„ ì • ê³µê³  â†’ ì£¼ê´€ê¸°ê´€ ì‚¬ì—…ê³„íšì„œ ëª©ì°¨
- ê¸°íƒ€ ì§€ì›ì‚¬ì—… ê³µê³  â†’ í•´ë‹¹ ì‚¬ì—…ì˜ ê³„íšì„œ ëª©ì°¨

âš ï¸ ë‹¤ìŒì„ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤:
- âŒ ì œì¶œ ì„œë¥˜ëª… (ì˜ˆ: "ì—°êµ¬ê³„íšì„œ", "ì‹ ì²­ì„œ", "ë™ì˜ì„œ") â†’ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- âœ… ì‘ì„± í•­ëª©/ëª©ì°¨ (ì˜ˆ: "ì‚¬ì—… ì¶”ì§„ê³„íš", "ìš´ì˜ ì „ëµ", "ì˜ˆì‚° í¸ì„±") â†’ ì´ê²ƒë§Œ í¬í•¨í•˜ì„¸ìš”

ğŸ“‹ ëª©ì°¨ ìƒì„± ìš”êµ¬ì‚¬í•­:
1. **ìµœì†Œ 10-15ê°œ ì´ìƒì˜ ì„¹ì…˜ì„ ìƒì„±**í•˜ì„¸ìš” (ë„ˆë¬´ ì ìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤)
2. **ê³„ì¸µ êµ¬ì¡°ë¥¼ í¬í•¨**í•˜ì„¸ìš” (1, 1.1, 1.2, 2, 2.1, 2.2 ë“±)
3. ê³µê³ ì˜ ì„±ê²©ì— ë§ëŠ” **í‘œì¤€ ëª©ì°¨ êµ¬ì¡°**ë¥¼ ì°¸ê³ í•˜ë˜, ì‹¤ì œ ê³µê³  ë‚´ìš©ì„ ë°˜ì˜í•˜ì„¸ìš”

ğŸ“š ê³µê³  ìœ í˜•ë³„ í‘œì¤€ ëª©ì°¨ êµ¬ì¡° ì°¸ê³ :

ã€ì—°êµ¬ê°œë°œ(R&D) ê³¼ì œã€‘
1. ì—°êµ¬ê°œë°œê³¼ì œì˜ ê°œìš” (í•„ìˆ˜)
   1.1. ê³¼ì œì˜ í•„ìš”ì„±
   1.2. ê³¼ì œì˜ ëª©í‘œ
2. ì—°êµ¬ê°œë°œ ëª©í‘œ ë° ë‚´ìš© (í•„ìˆ˜)
   2.1. ì—°êµ¬ê°œë°œ ëª©í‘œ
   2.2. ì—°êµ¬ê°œë°œ ë‚´ìš©
   2.3. ê¸°ìˆ ì  í•´ê²°ê³¼ì œ
3. ì—°êµ¬ê°œë°œ ì¶”ì§„ì²´ê³„ ë° ì¼ì • (í•„ìˆ˜)
   3.1. ì¶”ì§„ì²´ê³„
   3.2. ì—°êµ¬ì¼ì •
   3.3. ì¸ë ¥ìš´ìš©ê³„íš
4. ì—°êµ¬ê°œë°œ ì„±ê³¼ í™œìš©ë°©ì•ˆ (í•„ìˆ˜)
   4.1. ê¸°ëŒ€íš¨ê³¼
   4.2. í™œìš©ë°©ì•ˆ
5. ì†Œìš”ì˜ˆì‚° ë° ìê¸ˆê³„íš (í•„ìˆ˜)
   5.1. ì˜ˆì‚°ê³„íš
   5.2. ìê¸ˆì¡°ë‹¬ê³„íš

ã€ì°½ì—…ì§€ì›/ì‚¬ì—…ê³„íšì„œã€‘
1. ì‚¬ì—… ê°œìš” (í•„ìˆ˜)
   1.1. ì‚¬ì—… ë°°ê²½ ë° í•„ìš”ì„±
   1.2. ì‚¬ì—… ëª©í‘œ
2. ì‚¬ì—… ëª¨ë¸ (í•„ìˆ˜)
   2.1. ì‚¬ì—… ì•„ì´í…œ
   2.2. ì‚¬ì—… ì „ëµ
3. ì¶”ì§„ ê³„íš (í•„ìˆ˜)
   3.1. ìš´ì˜ ê³„íš
   3.2. ë§ˆì¼€íŒ… ê³„íš
4. ì¡°ì§ ë° ì¸ë ¥ (í•„ìˆ˜)
   4.1. ì¡°ì§ êµ¬ì„±
   4.2. ì¸ë ¥ ìš´ì˜
5. ì¬ë¬´ ê³„íš (í•„ìˆ˜)
   5.1. ë§¤ì¶œ ê³„íš
   5.2. ìê¸ˆ ê³„íš

ã€ì£¼ê´€ê¸°ê´€/ìš´ì˜ê¸°ê´€ ì„ ì •ã€‘
1. ê¸°ê´€ ê°œìš” (í•„ìˆ˜)
   1.1. ê¸°ê´€ í˜„í™©
   1.2. ì¡°ì§ êµ¬ì„±
2. ìš´ì˜ ê³„íš (í•„ìˆ˜)
   2.1. í”„ë¡œê·¸ë¨ ê¸°íš
   2.2. ìš´ì˜ ì „ëµ
3. ì¶”ì§„ ì²´ê³„ (í•„ìˆ˜)
   3.1. ì¡°ì§ ì²´ê³„
   3.2. ì¸ë ¥ ìš´ìš©
4. ì˜ˆì‚° ë° ìê¸ˆ ê³„íš (í•„ìˆ˜)
   4.1. ì˜ˆì‚° í¸ì„±
   4.2. ìê¸ˆ ê´€ë¦¬

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ë°˜í™˜:
{
  "sections": [
    {
      "number": "1",
      "title": "ì‚¬ì—… ì¶”ì§„ ê°œìš”",
      "required": true,
      "description": "ì‚¬ì—…ì˜ ëª©ì ê³¼ í•„ìš”ì„±"
    },
    {
      "number": "1.1",
      "title": "ì‚¬ì—… ë°°ê²½ ë° í•„ìš”ì„±",
      "required": true,
      "description": "ì‚¬ì—…ì„ ì¶”ì§„í•˜ëŠ” ë°°ê²½ê³¼ í•„ìš”ì„±"
    },
    {
      "number": "2",
      "title": "ìš´ì˜ ê³„íš ë° ì „ëµ",
      "required": true,
      "description": "êµ¬ì²´ì ì¸ ìš´ì˜ ë°©ì•ˆê³¼ ì¶”ì§„ ì „ëµ"
    }
  ]
}

âš ï¸ ì¤‘ìš” ì£¼ì˜ì‚¬í•­:
- ì œì¶œ ì„œë¥˜ì˜ "ì´ë¦„"ì´ ì•„ë‹Œ, ì„œë¥˜ "ë‚´ë¶€ì˜ ì‘ì„± í•­ëª©"ì„ ì¶”ì¶œí•˜ì„¸ìš”
- ê³µê³ ì˜ ì‹¤ì œ ë‚´ìš©(ì—°êµ¬ê°œë°œ/ì°½ì—…ì§€ì›/ì£¼ê´€ê¸°ê´€ì„ ì • ë“±)ì„ ë°˜ì˜í•œ ëª©ì°¨ë¥¼ ìƒì„±í•˜ì„¸ìš”
- ì„¹ì…˜ ë²ˆí˜¸ëŠ” "1", "1.1", "1.2", "2", "ê°€" ë“± ê³„ì¸µ êµ¬ì¡° í˜•ì‹ ìœ ì§€
- requiredëŠ” í•„ìˆ˜ ì‘ì„± í•­ëª© ì—¬ë¶€
- **ë°˜ë“œì‹œ 10ê°œ ì´ìƒì˜ ì„¹ì…˜ì„ ìƒì„±**í•˜ë˜, ê³µê³  ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”"""

    # ê³µê³ ë¬¸ ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ì²¨ë¶€íŒŒì¼ì´ ì—†ì„ ë•Œ ëŒ€ë¹„) - ì»¨í…ìŠ¤íŠ¸ í™•ëŒ€
    announcement_docs = [d for d in state['documents'] if d.get('document_type') == 'ANNOUNCEMENT']
    announcement_text = ''
    if announcement_docs:
        announcement_text = announcement_docs[0].get('text', '')[:5000]  # 3000 â†’ 5000ìœ¼ë¡œ ì¦ê°€

    submission_text_limit = submission_content[:3000]  # 2000 â†’ 3000ìœ¼ë¡œ ì¦ê°€
    document_context_limit = document_context[:4000] if document_context else '(ì²¨ë¶€ì„œë¥˜ ì—†ìŒ)'  # 2000 â†’ 4000ìœ¼ë¡œ ì¦ê°€

    user_prompt = f"""## ê³µê³ ë¬¸ ë‚´ìš©

{announcement_text}

## ì œì¶œì„œë¥˜ ìš”êµ¬ì‚¬í•­

{submission_text_limit}

## ì²¨ë¶€ì„œë¥˜ ê´€ë ¨ ë‚´ìš© (ì–‘ì‹/ê³„íšì„œì˜ ì‘ì„± í•­ëª©)

{document_context_limit}

---

## ğŸ“‹ ë¶„ì„ ë° ëª©ì°¨ ìƒì„± ì§€ì¹¨

### 1ë‹¨ê³„: ê³µê³  ì„±ê²© íŒŒì•…
ë‹¤ìŒ ì¤‘ í•´ë‹¹í•˜ëŠ” í•­ëª©ì„ íŒŒì•…í•˜ì„¸ìš”:
- [ ] ì—°êµ¬ê°œë°œ(R&D) ê³¼ì œ ê³µê³ 
- [ ] ì°½ì—…ì§€ì›/ë²¤ì²˜ ì§€ì› ì‚¬ì—… ê³µê³ 
- [ ] ì£¼ê´€ê¸°ê´€/ìš´ì˜ê¸°ê´€ ì„ ì • ê³µê³ 
- [ ] ê¸°íƒ€ ì§€ì›ì‚¬ì—… ê³µê³ 

### 2ë‹¨ê³„: ëª©ì°¨ êµ¬ì¡° ìƒì„±
ìœ„ì—ì„œ íŒŒì•…í•œ ê³µê³  ì„±ê²©ì— ë§ëŠ” í‘œì¤€ ëª©ì°¨ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ë˜, **ê³µê³ ë¬¸ê³¼ ì²¨ë¶€ì„œë¥˜ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ì‘ì„± í•­ëª©**ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”.

**âš ï¸ ë°˜ë“œì‹œ ì¤€ìˆ˜í•  ì‚¬í•­:**
1. **ìµœì†Œ 10-15ê°œ ì´ìƒì˜ ì„¹ì…˜ ìƒì„±** (ê³„ì¸µ êµ¬ì¡° í¬í•¨ ì‹œ 15-20ê°œ ì´ìƒ)
2. **ê³„ì¸µ êµ¬ì¡° í•„ìˆ˜ í¬í•¨**:
   - 1ì°¨ ì„¹ì…˜: "1", "2", "3" ë“±
   - 2ì°¨ ì„¹ì…˜: "1.1", "1.2", "2.1", "2.2" ë“±
   - 3ì°¨ ì„¹ì…˜ (í•„ìš”ì‹œ): "1.1.1", "1.1.2" ë“±
3. **ê³µê³  ë‚´ìš© ê¸°ë°˜ ìƒì„±**: í‘œì¤€ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ë˜, ê³µê³ ë¬¸ê³¼ ì²¨ë¶€ì„œë¥˜ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰ëœ í•­ëª©ì„ ìš°ì„  ë°˜ì˜
4. **"ì„œë¥˜ëª…"ì´ ì•„ë‹Œ "ì‘ì„± í•­ëª©"ë§Œ ì¶”ì¶œ**:
   - âŒ ì˜ëª»ëœ ëª©ì°¨: ["ì‚¬ì—…ê³„íšì„œ", "ì‹ ì²­ì„œ", "ë™ì˜ì„œ", "ì²¨ë¶€ìë£Œ"]
   - âœ… ì˜¬ë°”ë¥¸ ëª©ì°¨: ["ì‚¬ì—… ì¶”ì§„ ê°œìš”", "ìš´ì˜ ê³„íš", "ì˜ˆì‚° í¸ì„±", "ì¶”ì§„ ì²´ê³„"]

### 3ë‹¨ê³„: êµ¬ì²´ì ì¸ ì˜ˆì‹œ

**ì—°êµ¬ê°œë°œ ê³¼ì œ ì˜ˆì‹œ:**
```
1. ì—°êµ¬ê°œë°œê³¼ì œì˜ ê°œìš”
   1.1. ê³¼ì œì˜ í•„ìš”ì„± ë° ë°°ê²½
   1.2. ê³¼ì œì˜ ëª©í‘œ
   1.3. ê¸°ëŒ€íš¨ê³¼
2. ì—°êµ¬ê°œë°œ ëª©í‘œ ë° ë‚´ìš©
   2.1. ì—°êµ¬ê°œë°œ ëª©í‘œ
   2.2. ì—°êµ¬ê°œë°œ ë‚´ìš©
   2.3. ê¸°ìˆ ì  í•´ê²°ê³¼ì œ
   2.4. í•µì‹¬ê¸°ìˆ  ìš”ì†Œ
3. ì—°êµ¬ê°œë°œ ì¶”ì§„ì²´ê³„ ë° ì¼ì •
   3.1. ì¶”ì§„ì²´ê³„
   3.2. ì—°êµ¬ì¼ì • (Gantt ì°¨íŠ¸ í¬í•¨)
   3.3. ì¸ë ¥ìš´ìš©ê³„íš
   3.4. ì—­í•  ë¶„ë‹´
4. ì—°êµ¬ê°œë°œ ì„±ê³¼ í™œìš©ë°©ì•ˆ
   4.1. ê¸°ëŒ€íš¨ê³¼
   4.2. í™œìš©ë°©ì•ˆ
   4.3. ì‚¬ì—…í™” ê³„íš
5. ì†Œìš”ì˜ˆì‚° ë° ìê¸ˆê³„íš
   5.1. ì˜ˆì‚°ê³„íš (ì—°ë„ë³„)
   5.2. ìê¸ˆì¡°ë‹¬ê³„íš
   5.3. ì˜ˆì‚° ì§‘í–‰ ê³„íš
```

**âš ï¸ ì£¼ì˜: ìœ„ ì˜ˆì‹œëŠ” ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ê³µê³ ë¬¸ê³¼ ì²¨ë¶€ì„œë¥˜ì˜ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”.**

ìœ„ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì‹ ì²­ìê°€ ì‘ì„±í•´ì•¼ í•  ê³„íšì„œì˜ **ìƒì„¸í•œ ëª©ì°¨(ìµœì†Œ 10-15ê°œ ì„¹ì…˜, ê³„ì¸µ êµ¬ì¡° í¬í•¨)**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0
        )

        result = json.loads(response.choices[0].message.content)

        if result.get('sections'):
            toc = {
                'source': 'announcement',
                'extraction_method': 'rag_llm',
                'inference_confidence': 0.7,  # RAG + LLM ê¸°ë°˜ì´ë¯€ë¡œ ì¤‘ê°„ ì‹ ë¢°ë„
                'sections': result['sections'],
                'total_sections': len(result['sections']),
                'extracted_at': datetime.now().isoformat()
            }

            state['table_of_contents'] = toc
            state['status'] = 'toc_extracted'

            print(f"\n  âœ… LLMìœ¼ë¡œ {len(result['sections'])}ê°œ ì„¹ì…˜ ìƒì„± ì™„ë£Œ")
            for sec in result['sections'][:5]:
                print(f"    â€¢ {sec.get('number', '')} {sec.get('title', '')}")
            if len(result['sections']) > 5:
                print(f"    ... ì™¸ {len(result['sections']) - 5}ê°œ")

            return state
        else:
            print(f"\n  âœ— LLM ê²°ê³¼ì— ì„¹ì…˜ ì—†ìŒ â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
            state['table_of_contents'] = _create_default_toc()
            state['status'] = 'toc_extracted'
            return state

    except Exception as e:
        print(f"\n  âœ— LLM í˜¸ì¶œ ì‹¤íŒ¨: {e} â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        state['table_of_contents'] = _create_default_toc()
        state['status'] = 'toc_extracted'
        return state


def _create_default_toc() -> Dict:
    """
    ê¸°ë³¸ ëª©ì°¨ ìƒì„± (ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ)

    ì¼ë°˜ì ì¸ R&D ì œì•ˆì„œ í‘œì¤€ ëª©ì°¨ ì œê³µ
    """
    return {
        'source': 'default',
        'extraction_method': 'fallback',
        'inference_confidence': 0.3,
        'sections': [
            {'number': '1', 'title': 'ì—°êµ¬ê°œë°œ ê³¼ì œì˜ ê°œìš”', 'required': True},
            {'number': '2', 'title': 'ì—°êµ¬ê°œë°œ ëª©í‘œ ë° ë‚´ìš©', 'required': True},
            {'number': '3', 'title': 'ì—°êµ¬ê°œë°œ ì¶”ì§„ì²´ê³„ ë° ì¼ì •', 'required': True},
            {'number': '4', 'title': 'ì—°êµ¬ê°œë°œ ì„±ê³¼ í™œìš©ë°©ì•ˆ', 'required': True},
            {'number': '5', 'title': 'ì†Œìš”ì˜ˆì‚°', 'required': True},
        ],
        'total_sections': 5,
        'extracted_at': datetime.now().isoformat(),
        'note': 'ëª©ì°¨ ì¶”ì¶œ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©'
    }


def _extract_toc_from_template_with_llm(state: BatchState, template: Dict) -> BatchState:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì–‘ì‹ í…ìŠ¤íŠ¸ì—ì„œ ëª©ì°¨ ì¶”ì¶œ (í‘œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ)

    Args:
        state: BatchState
        template: ì–‘ì‹ ë¬¸ì„œ ì •ë³´

    Returns:
        state: table_of_contents ì—…ë°ì´íŠ¸ëœ BatchState
    """
    print(f"  ğŸ¤– LLMìœ¼ë¡œ ì–‘ì‹ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")

    # ì–‘ì‹ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    documents = state.get('documents', [])
    template_doc = None

    template_file_name = unicodedata.normalize('NFC', template['file_name'])

    for doc in documents:
        doc_file_name = unicodedata.normalize('NFC', doc.get('file_name', ''))
        if doc_file_name == template_file_name:
            template_doc = doc
            break

    if not template_doc or not template_doc.get('full_text'):
        print(f"  âœ— ì–‘ì‹ í…ìŠ¤íŠ¸ ì—†ìŒ â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        state['table_of_contents'] = _create_default_toc()
        state['status'] = 'toc_extracted'
        return state

    # ëª©ì°¨ ì„¹ì…˜ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ
    full_text = template_doc['full_text']

    # 1ë‹¨ê³„: ëª©ì°¨ ì‹œì‘ í‚¤ì›Œë“œ ì°¾ê¸°
    toc_start_keywords = [
        '< ë³¸ë¬¸', '<ë³¸ë¬¸', 'ë³¸ë¬¸>',
        'ì‘ì„± ëª©ì°¨', 'ì œì¶œì„œë¥˜ ëª©ì°¨', 'ê³„íšì„œ ëª©ì°¨',
        'ì‘ì„±í•­ëª©', 'ì œì¶œí•­ëª©', 'ê¸°ì¬ì‚¬í•­'
    ]

    toc_section_start = -1
    for keyword in toc_start_keywords:
        idx = full_text.find(keyword)
        if idx != -1:
            toc_section_start = idx
            print(f"    ğŸ“ ëª©ì°¨ ì‹œì‘ í‚¤ì›Œë“œ ë°œê²¬: '{keyword}' (ìœ„ì¹˜: {idx})")
            break

    # 2ë‹¨ê³„: ëª©ì°¨ ë ì§€ì  ì°¾ê¸°
    if toc_section_start != -1:
        # ëª©ì°¨ ì‹œì‘ ì´í›„ í…ìŠ¤íŠ¸
        text_after_start = full_text[toc_section_start:]

        # ë ì§€ì  í›„ë³´ í‚¤ì›Œë“œ
        end_keywords = [
            '< ë³¸ë¬¸ 2', '<ë³¸ë¬¸ 2', 'ë³¸ë¬¸ 2>',
            'ì‘ì„±ìš”ë ¹', 'ì‘ì„± ìš”ë ¹', 'ì£¼ì˜ì‚¬í•­', 'ìœ ì˜ì‚¬í•­',
            'ì°¸ê³ ì‚¬í•­', 'ê¸°ì¬ìš”ë ¹', 'ì²¨ë¶€ì„œë¥˜',
            'â€» ì°¸ê³ ', 'ã€ì°¸ê³ ', '[ì°¸ê³ '
        ]

        toc_end = len(text_after_start)  # ê¸°ë³¸ê°’: ëê¹Œì§€
        for end_kw in end_keywords:
            end_idx = text_after_start.find(end_kw)
            if end_idx != -1 and end_idx < toc_end:
                toc_end = end_idx
                print(f"    ğŸ“ ëª©ì°¨ ë í‚¤ì›Œë“œ ë°œê²¬: '{end_kw}' (ìƒëŒ€ ìœ„ì¹˜: {end_idx})")
                break

        # ëª©ì°¨ ì„¹ì…˜ ì¶”ì¶œ (ìµœëŒ€ 5000ìë¡œ ì œí•œ)
        template_text = text_after_start[:min(toc_end, 5000)]
        print(f"    âœ… ëª©ì°¨ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(template_text)}ì)")
    else:
        # 3ë‹¨ê³„: í‚¤ì›Œë“œ ì—†ìœ¼ë©´ ë²ˆí˜¸ íŒ¨í„´ìœ¼ë¡œ ëª©ì°¨ êµ¬ê°„ ì°¾ê¸°
        print(f"    âš ï¸  ëª©ì°¨ í‚¤ì›Œë“œ ë¯¸ë°œê²¬ â†’ ë²ˆí˜¸ íŒ¨í„´ ê¸°ë°˜ íƒì§€ ì‹œë„")

        # "1. ", "2. ", "3. " íŒ¨í„´ì´ ì—°ì†ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” êµ¬ê°„ ì°¾ê¸°
        import re
        pattern = r'^[1-9]\.\s+[ê°€-í£]{2,}'
        lines = full_text.split('\n')

        toc_line_start = -1
        consecutive_numbered = 0

        for i, line in enumerate(lines):
            if re.search(pattern, line.strip()):
                if toc_line_start == -1:
                    toc_line_start = i
                consecutive_numbered += 1

                # 3ê°œ ì´ìƒ ì—°ì† ë²ˆí˜¸ íŒ¨í„´ì´ë©´ ëª©ì°¨ë¡œ íŒë‹¨
                if consecutive_numbered >= 3:
                    # ëª©ì°¨ ì‹œì‘ë¶€í„° ìµœëŒ€ 100ì¤„ ë˜ëŠ” 5000ì
                    toc_lines = lines[toc_line_start:toc_line_start + 100]
                    template_text = '\n'.join(toc_lines)[:5000]
                    print(f"    âœ… ë²ˆí˜¸ íŒ¨í„´ ê¸°ë°˜ ëª©ì°¨ ë°œê²¬ (ë¼ì¸: {toc_line_start}, ê¸¸ì´: {len(template_text)}ì)")
                    break
            else:
                consecutive_numbered = 0
        else:
            # ë²ˆí˜¸ íŒ¨í„´ë„ ëª» ì°¾ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
            template_text = full_text[:15000]  # 15000ìë¡œ í™•ëŒ€
            print(f"    âš ï¸  ëª©ì°¨ íŒ¨í„´ ë¯¸ë°œê²¬ â†’ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš© (15000ì)")

    system_prompt = """ë‹¹ì‹ ì€ ì •ë¶€ R&D ì œì•ˆì„œ ì–‘ì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì œì•ˆì„œ ì‘ì„± ì–‘ì‹ì˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ **ì‹¤ì œ ì‘ì„±í•´ì•¼ í•  ëª©ì°¨(ì„¹ì…˜)**ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ë°˜í™˜:
{
  "sections": [
    {
      "number": "1",
      "title": "ì—°êµ¬ê°œë°œê³¼ì œì˜ í•„ìš”ì„±",
      "required": true,
      "description": "ê³¼ì œì˜ í•„ìš”ì„± ì„¤ëª…"
    }
  ]
}

âš ï¸ ì¤‘ìš” êµ¬ë¶„:
- âœ… ì¶”ì¶œí•  ê²ƒ: "1. ì—°êµ¬ê°œë°œê³¼ì œì˜ í•„ìš”ì„±", "2. ì—°êµ¬ê°œë°œê³¼ì œì˜ ëª©í‘œ ë° ë‚´ìš©" ê°™ì€ **ë³¸ë¬¸ ì‘ì„± ëª©ì°¨**
- âŒ ì œì™¸í•  ê²ƒ: "ì‚¬ì—…ëª…", "ì—°êµ¬ì±…ì„ì", "ì—°êµ¬ê°œë°œê¸°ê°„" ê°™ì€ **í¼ ì…ë ¥ í•„ë“œ**

ì£¼ì˜ì‚¬í•­:
- ë²ˆí˜¸ê°€ ìˆëŠ” ì‘ì„± í•­ëª©(1., 2., 3. ë˜ëŠ” ê°€., ë‚˜., ë‹¤.)ì„ ì„¹ì…˜ìœ¼ë¡œ ì¶”ì¶œ
- ì„¹ì…˜ ë²ˆí˜¸ëŠ” "1", "1.1", "ê°€" ë“± ì›ë¬¸ í˜•ì‹ ìœ ì§€
- ê³„ì¸µ êµ¬ì¡°ë„ í¬í•¨ (1) â†’ 2) â†’ 3) ë“±)
- requiredëŠ” í•„ìˆ˜ ì‘ì„± í•­ëª© ì—¬ë¶€"""

    user_prompt = f"""## ì œì•ˆì„œ ì–‘ì‹ í…ìŠ¤íŠ¸

{template_text}

ìœ„ ì–‘ì‹ì„ ë¶„ì„í•˜ì—¬ **ì œì•ˆì„œ ë³¸ë¬¸ ì‘ì„± ëª©ì°¨**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ë‹¨ìˆœ í¼ í•„ë“œê°€ ì•„ë‹Œ, ì‹¤ì œë¡œ ì„œìˆ í•´ì•¼ í•  ì„¹ì…˜ë“¤ì„ ì¶”ì¶œí•˜ì„¸ìš”."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0
        )

        result = json.loads(response.choices[0].message.content)

        if result.get('sections') and len(result['sections']) > 0:
            toc = {
                'source': 'template',
                'source_file': template['file_name'],
                'extraction_method': 'llm_text_analysis',
                'inference_confidence': 0.75,  # LLM ê¸°ë°˜ì´ë¯€ë¡œ ì¤‘ìƒ ì‹ ë¢°ë„
                'sections': result['sections'],
                'total_sections': len(result['sections']),
                'extracted_at': datetime.now().isoformat()
            }

            state['table_of_contents'] = toc
            state['status'] = 'toc_extracted'

            print(f"  âœ… LLMìœ¼ë¡œ {len(result['sections'])}ê°œ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ")
            for sec in result['sections'][:5]:
                print(f"    â€¢ {sec.get('number', '')} {sec.get('title', '')}")
            if len(result['sections']) > 5:
                print(f"    ... ì™¸ {len(result['sections']) - 5}ê°œ")

            return state
        else:
            print(f"  âœ— LLM ê²°ê³¼ì— ì„¹ì…˜ ì—†ìŒ â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
            state['table_of_contents'] = _create_default_toc()
            state['status'] = 'toc_extracted'
            return state

    except Exception as e:
        print(f"  âœ— LLM í˜¸ì¶œ ì‹¤íŒ¨: {e} â†’ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        state['table_of_contents'] = _create_default_toc()
        state['status'] = 'toc_extracted'
        return state
