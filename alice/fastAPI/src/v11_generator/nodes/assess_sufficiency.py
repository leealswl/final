from typing import Dict, Any, List
from langchain_openai import ChatOpenAI 
from langchain_core.prompts import PromptTemplate 
from ..state_types import ProposalGenerationState
import re 

def assess_info(state: ProposalGenerationState) -> Dict[str, Any]:
    """
    [íŒì‚¬ ë…¸ë“œ] (ìµœì¢… ë²„ì „)
    ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ 80ì  ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ê³  íë¦„ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    print("--- ë…¸ë“œ ì‹¤í–‰: assess_sufficiency (Section Scoring) ---")

    # 1. 'anal_guide' ë³€ìˆ˜ ì¤€ë¹„
    fetched_context = state.get("fetched_context", {})
    # ğŸ’¡ draft_strategyì—ì„œ ì „ëµì„ ê°€ì ¸ì˜´ (ìƒíƒœì˜ ë‹¤ë¥¸ í•„ë“œë¥¼ ì°¸ì¡°í•  ê²½ìš° ìˆ˜ì • í•„ìš”)
    anal_guide = str(state.get("draft_strategy", "íŠ¹ë³„í•œ ê³µê³ ë¬¸ ë¶„ì„ ì „ëµ ì—†ìŒ.")) 
    
    # 1. --- LLM ë° í‰ê°€ í”„ë¡¬í”„íŠ¸ ì •ì˜ ---
    GRADING_PROMPT = """
        ë‹¹ì‹ ì€ **ìµœì¢… ê¸°íšì„œ ì´ˆì•ˆ ìƒì„± ì „ë¬¸ ê²€í† ê´€**ì…ë‹ˆë‹¤. 

        ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì§€ì •ëœ ëª©ì°¨ í•­ëª©ì— ëŒ€í•´ **'ì´ˆì•ˆ ìƒì„±ì— ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€'**ì¸ì§€ í‰ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        [ëª©í‘œ ëª©ì°¨]
        ë²ˆí˜¸: {chapter_number}
        ì œëª©: {chapter_title}
        ìš”êµ¬ ì‚¬í•­: {chapter_description}

        [ìˆ˜ì§‘ëœ ì •ë³´]
        {collected_data}

        [ê³µê³ ë¬¸ í•µì‹¬ ì „ëµ ë° í‰ê°€ ê¸°ì¤€]
        â­ {anal_guide} â­ ê³µê³ ë¬¸ì˜ í•µì‹¬ ì „ëµì´ ìˆ˜ì§‘ëœ ì •ë³´ì— ì¶©ë¶„íˆ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
        
        [í‰ê°€ ê¸°ì¤€: 'ìƒì„± ì í•©ì„±']
        1. **ì •ëŸ‰ì  ë°ì´í„° í¬í•¨ ì—¬ë¶€:** (ì˜ˆ: ì—° ë§¤ì¶œ ëª©í‘œ, ì‹œì¥ ê·œëª¨, % ì„±ì¥ë¥  ë“±) êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€? (ê¸°íšì„œì˜ ì„¤ë“ë ¥ì„ ë†’ì´ëŠ” í•µì‹¬ ìš”ì†Œ)
        2. **ë…¼ë¦¬ì  ì—°ê²°ì„±:** ìˆ˜ì§‘ëœ ì •ë³´ê°€ ëª©í‘œ ëª©ì°¨ì˜ ìš”êµ¬ ì‚¬í•­ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë’·ë°›ì¹¨í•˜ë©° ìµœì¢… ê¸°íšì„œì— ê·¸ëŒ€ë¡œ í™œìš©ë  ìˆ˜ ìˆëŠ”ê°€?
        3. **ì™„ë£Œ ê¸°ì¤€:** 80ì  ì´ìƒì´ë©´ 'ì´ˆì•ˆ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ê°€ í™•ë³´ë¨'ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤. 80ì  ë¯¸ë§Œì´ë©´ ì¶”ê°€ì ì¸, ë”ìš± êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        
        [ì¶œë ¥ í˜•ì‹]
        - ì ìˆ˜ëŠ” ë°˜ë“œì‹œ <score> íƒœê·¸ ì•ˆì— ìˆ«ì(ì •ìˆ˜)ë§Œ ë„£ì–´ì£¼ì„¸ìš”.
        - ì ìˆ˜ë¥¼ ë§¤ê¸´ ì´ìœ ì™€ ë¶€ì¡±í•œ ë¶€ë¶„ì„ <reason> íƒœê·¸ ì•ˆì— êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
          (ë¶€ì¡±í•œ ë¶€ë¶„ì€ 'ì •ëŸ‰ì  ëª©í‘œ ìˆ˜ì¹˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤', 'ê²½ìŸ ìš°ìœ„ ìš”ì†Œê°€ ë¶ˆëª…í™•í•©ë‹ˆë‹¤'ì™€ ê°™ì´ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ)
        
        <score>ì ìˆ˜</score>
        <reason>í‰ê°€ ì´ìœ  ë° ë¶€ì¡±í•œ ì  ì„¤ëª…</reason>
        """
    
    llm = None
    try:
        llm = ChatOpenAI(temperature=0, model="gpt-4o")
    except Exception as e:
        print(f"âš ï¸ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    prompt = PromptTemplate.from_template(GRADING_PROMPT)
    # ---------------------------------------------

    # 2. í˜„ì¬ ëª©í‘œ ì„¹ì…˜ ì •ë³´ ì„¤ì • (history_checkerì˜ ê²°ì • ë°˜ì˜ ë¡œì§)
    collected_data = state.get("collected_data", "")
    print(f"--- ğŸ“Š ASSESS_INFO ìˆ˜ì‹  ë°ì´í„° ê¸¸ì´: {len(collected_data)}ì ---")
    
    toc_structure = state.get("draft_toc_structure", [])
    target_title = state.get("target_chapter", "")
    current_idx = state.get("current_chapter_index", 0) 
    
    # ğŸ”‘ history_checkerì˜ ê²°ì •ì„ ë°˜ì˜í•˜ì—¬ current_idxë¥¼ ë®ì–´ì”ë‹ˆë‹¤.
    found_idx = -1
    for i, item in enumerate(toc_structure):
        item_title = item.get("title", "")
        if item_title == target_title or target_title in item_title:
            found_idx = i
            break
            
    if found_idx != -1:
        current_idx = found_idx
    
    # ëª©ì°¨ ëì— ë„ë‹¬í–ˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤ì¸ ê²½ìš° ì™„ë£Œ ì²˜ë¦¬
    if not toc_structure or current_idx >= len(toc_structure):
        return {"sufficiency": True, "completeness_score": 100, "grading_reason": "ëª¨ë“  ëª©ì°¨ í•­ëª© ì™„ë£Œ", "next_step": "FINISH"}

    current_section_item = toc_structure[current_idx]
    current_number = current_section_item.get("number", "0")
    current_title = current_section_item.get("title", "ì œëª© ì—†ìŒ")
    current_description = current_section_item.get("description", "ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")



    # 3. --- í‰ê°€ LLM í˜¸ì¶œ ë° ê²°ê³¼ íŒŒì‹± ---
    if not collected_data.strip():
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0ì ìœ¼ë¡œ ì²˜ë¦¬ (LLM í˜¸ì¶œ ìƒëµ)
        final_score = 0
        grading_reason = "ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ì–´ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        # ë°ì´í„°ê°€ ìˆìœ¼ë©´ LLMì„ í˜¸ì¶œí•˜ì—¬ ì •êµí•˜ê²Œ í‰ê°€í•©ë‹ˆë‹¤.
        final_score = 0
        grading_reason = "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ í‰ê°€ ë¶ˆê°€ (LLM í˜¸ì¶œ ì‹¤íŒ¨)"
        
        if llm is None:
            print("âŒ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 0ì  ì²˜ë¦¬.")
        else:
            print(f"--- ğŸ§  LLM í˜¸ì¶œ: [{current_number} {current_title}] ì •êµí•œ í‰ê°€ ì‹œì‘ ---")
            chain = prompt | llm
            
            try:
                response_text = chain.invoke({
                    "chapter_number": current_number,
                    "chapter_title": current_title,
                    "chapter_description": current_description,
                    "collected_data": collected_data,
                    "anal_guide": anal_guide 
                }).content.strip()
                
                # ğŸ”‘ íŒŒì‹± ë¡œì§
                score_match = re.search(r"<score>\s*(\d+)\s*</score>", response_text, re.IGNORECASE)
                reason_match = re.search(r"<reason>\s*(.*?)\s*</reason>", response_text, re.IGNORECASE | re.DOTALL)
                
                final_score = int(score_match.group(1)) if score_match else 0
                grading_reason = reason_match.group(1).strip() if reason_match else "í‰ê°€ ì´ìœ  íŒŒì‹± ì˜¤ë¥˜"
                
                print(f"ğŸ“Š LLM í‰ê°€ ê²°ê³¼: {final_score}ì  - {grading_reason[:50]}...")
            except Exception as e:
                print(f"âŒ LLM í˜¸ì¶œ/íŒŒì‹± ì˜¤ë¥˜: {e}")
                
    # 4. --- ê²°ê³¼ ë°˜í™˜ (80ì  ê¸°ì¤€ ë¶„ê¸° ë¡œì§ êµ¬í˜„ ë° ì ìˆ˜ ì˜ì†í™”) ---
    is_sufficient = final_score >= 80 
    
    # ğŸ”‘ ì ìˆ˜ ì˜ì†í™”: section_scoresì— í˜„ì¬ ì„¹ì…˜ ì ìˆ˜ ì €ì¥
    section_scores = state.get("section_scores", {})
    section_scores[f"{current_number}"] = final_score
    
    print(f"âœ… í‰ê°€ ì™„ë£Œ: [{current_number} {current_title}] í•„ìš”ì •ë³´: {final_score}%")
    if is_sufficient:
        print(f"ğŸ¯ ì¶©ë¶„ì„± íŒë‹¨: 80ì  ì´ìƒ â†’ MANAGE_PROGRESSIONìœ¼ë¡œ ë¶„ê¸°")
    else:
        print(f"âš ï¸ ì¶©ë¶„ì„± íŒë‹¨: 80ì  ë¯¸ë§Œ â†’ GENERATE_QUERYë¡œ ë¶„ê¸°")
    
    return {
        "sufficiency": is_sufficient,
        "completeness_score": final_score,  # ğŸ”‘ ì ìˆ˜ ì˜ì†í™”ë¥¼ ìœ„í•´ ìƒíƒœì— ì €ì¥
        "grading_reason": grading_reason,
        "missing_subsections": [],
        "current_chapter_index": current_idx, 
        "target_chapter": current_title,      
        "section_scores": section_scores,  # ğŸ”‘ ì—…ë°ì´íŠ¸ëœ ì ìˆ˜ ì €ì¥
        # ğŸ”‘ 80ì  ì´ìƒì´ë©´ MANAGE_PROGRESSION, ì•„ë‹ˆë©´ GENERATE_QUERY
        "next_step": "MANAGE_PROGRESSION" if is_sufficient else "GENERATE_QUERY"
    }
