# íŒŒì¼: generate_query.py (ì „ì²´ êµì²´)

from typing import Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from ..state_types import ProposalGenerationState
from dotenv import load_dotenv

load_dotenv()


PROMPT_TEMPLATE_CONSULTANT = """
ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… ê¸°íšì„œ ì‘ì„±ì„ ë•ëŠ” AI ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶€ì¡±í•œ í•­ëª©ì„ íŒŒì•…í•˜ê³ , êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

======================================================================
ğŸ“Œ <ì…ë ¥ ì •ë³´>
1. ì‘ì„± ëŒ€ìƒ ëª©ì°¨: "{target_chapter_info}"
2. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´: {collected_data}
3. ì‚¬ìš©ì ë©”ì‹œì§€: "{user_prompt}"
4. ëŒ€í™” íˆìŠ¤í† ë¦¬: {recent_history}
5. ë¶€ì¡±í•œ ì  ë¶„ì„: {grading_reason}
======================================================================

ğŸ¯ <ì—­í•  ë° ì˜ì‚¬ê²°ì • ì›ì¹™>
1. {grading_reason}ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶€ì¡±í•œ ìš”ì†Œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
2. ìˆ˜ì§‘ëœ ì •ë³´({collected_data})ì—ì„œ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²ƒ vs ë¶€ì¡±í•œ ìš”ì†Œë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
3. ë¶€ì¡±í•œ ìš”ì†Œë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•œ **í•µì‹¬ í•­ëª©**ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´í•©ë‹ˆë‹¤.
4. ì´ë¯¸ íˆìŠ¤í† ë¦¬ì—ì„œ ì§ˆë¬¸í–ˆê±°ë‚˜ ë‹µë³€ë˜ì—ˆë˜ ë‚´ìš©ì€ ì ˆëŒ€ ë‹¤ì‹œ ë¬»ì§€ ì•ŠìŠµë‹ˆë‹¤.
5. ì‚¬ìš©ìê°€ ë°”ë¡œ ì´í•´í•˜ê³  ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

======================================================================
ğŸ“ <ì¶œë ¥ í˜•ì‹>
ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤. í˜•ì‹ ë³€ê²½ ê¸ˆì§€.

[ì¶”ê°€ ì •ë³´ ìš”ì²­]

ì•„ë˜ í•­ëª©ì´ ë” í•„ìš”í•´ìš”!

- (ë¶€ì¡±í•œ í•­ëª© 1: êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ, ì˜ˆ: "í•´ì™¸ íˆ¬ì ìœ ì¹˜ ëª©í‘œ ê¸ˆì•¡")
- (ë¶€ì¡±í•œ í•­ëª© 2: êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ, ì˜ˆ: "í˜„ì§€ë²•ì¸ ì„¤ë¦½ ì‹œì  ë° ì˜ˆìƒ ë¹„ìš©")
- (ë¶€ì¡±í•œ í•­ëª© 3: í•„ìš”ì‹œ ë” ì¶”ê°€, ìµœëŒ€ 3-5ê°œ)

ğŸ“Œ ì˜ˆì‹œ
(êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ 2-3ì¤„ë¡œ ì‘ì„±. ê° í•­ëª©ì— ëŒ€í•œ ì‹¤ì œ ë‹µë³€ ì˜ˆì‹œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”. ì˜ˆ: "2024ë…„ê¹Œì§€ í•´ì™¸ íˆ¬ì 50ì–µ ì› ìœ ì¹˜\n2025ë…„ ë¯¸êµ­ ë²•ì¸ ì„¤ë¦½(ì˜ˆìƒ ë¹„ìš©: 10ì–µ ì›)\në§¤ì¶œ 30% ì¦ê°€, ê¸€ë¡œë²Œ ê³ ê°ì‚¬ 20ê³³ í™•ë³´")

ğŸ™Œ ìœ„ì²˜ëŸ¼ ì•Œë ¤ì£¼ì‹œë©´ ë°”ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í• ê²Œìš”!

âš ï¸ ì¤‘ìš”:
- ë¶€ì¡±í•œ í•­ëª©ì€ {grading_reason}ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš” (ìµœëŒ€ 3-5ê°œ)
- ì˜ˆì‹œëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ë‹µë³€ í˜•ì‹ìœ¼ë¡œ 2-3ì¤„ ì‘ì„±í•˜ì„¸ìš”
- ì‹¬ì‚¬ ê¸°ì¤€, ì ìˆ˜, í‰ê°€ ë‚´ìš© ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” (ë‚´ë¶€ ì°¸ê³ ìš©)
- ì‚¬ìš©ìê°€ ë°”ë¡œ ì´í•´í•˜ê³  ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”

======================================================================
â›” ì ˆëŒ€ ê¸ˆì§€
- íˆìŠ¤í† ë¦¬ ì¤‘ë³µ ì§ˆë¬¸ ë°˜ë³µ
- ê³µê°ì„ ê°€ì¥í•œ ì¡ë‹´, ì˜ë¡€ì  ì¸ì‚¬
- "ë” ì„¤ëª…í•´ì£¼ì„¸ìš”" / "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œë°" ê°™ì€ í¬ê´„ì  í‘œí˜„
- ì‹¬ì‚¬ ê¸°ì¤€, ì ìˆ˜, í‰ê°€ ë‚´ìš© ë“± ë‚´ë¶€ ì •ë³´ ë…¸ì¶œ
- ë¶€ì¡±í•œ í•­ëª©ì„ ë„ˆë¬´ ë§ê²Œ ë‚˜ì—´ (3-5ê°œ ì´ë‚´)
- ê¸´ ì„¤ëª…ì´ë‚˜ ë¶ˆí•„ìš”í•œ ë°°ê²½ ì„¤ëª…


"""

def generate_query(state: ProposalGenerationState) -> ProposalGenerationState:
    print("--- ë…¸ë“œ ì‹¤í–‰: generate_query (Score Display / Fix Error) ---")
    
    # ğŸŒŸ [ì˜¤ë¥˜ í•´ê²°] generated_response ë³€ìˆ˜ë¥¼ ë¯¸ë¦¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    generated_response = ""
    
    try:
        llm = ChatOpenAI(temperature=0.1, model="gpt-4o-mini")
    except Exception:
        return {"current_query": "LLM ì´ˆê¸°í™” ì˜¤ë¥˜ ë°œìƒ"}

    # 1. ìƒíƒœ ë³€ìˆ˜ ì¶”ì¶œ ë° ì´ˆê¸°ê°’ ì„¤ì •
    user_prompt = state.get("user_prompt", "")
    collected_data = state.get("collected_data", "")
    if not collected_data:
        collected_data = "(ì—†ìŒ)"
    
    current_avg_score = state.get("completeness_score", 0) 
    grading_reason = state.get("grading_reason", "")
    # missing_list = state.get("missing_subsections", [])
    section_scores = state.get("section_scores", {}) 
    # missing_points = ", ".join(missing_list) if missing_list else "(ì—†ìŒ)"
    
    fetched_context = state.get("fetched_context", {})
    anal_guide_summary = str(fetched_context.get("anal_guide", "ì „ëµ ì •ë³´ ì—†ìŒ"))

    toc_structure = state.get("draft_toc_structure", [])
    current_idx = state.get("current_chapter_index", 0)
    
    # 2. [í•µì‹¬] ì§„í–‰ë¥  í‘œì‹œ ë³€ìˆ˜ ì´ˆê¸°í™” ë° ê³„ì‚°
    major_chapter_title = "ì±•í„° ì œëª© ì—†ìŒ"
    focused_subchapter_display = "ì´ˆê¸° ì§ˆë¬¸"
    focused_subchapter_score = current_avg_score #í˜„ì¬ ASSESS_INFOì˜ ê²°ê³¼ ì ìˆ˜
    all_sub_section_numbers = []
    # avg_score_description = "(ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ë˜ëŠ” ì´ˆê¸° ì§„ì…)"
    target_info_full = "ì •ë³´ ìˆ˜ì§‘"
    chapter_display = "ì „ì²´ ê°œìš”"

    if toc_structure and current_idx < len(toc_structure):
        major_chapter_item = toc_structure[current_idx]
        major_chapter_number = major_chapter_item.get("number", "0") 
        major_chapter_title = major_chapter_item.get("title", "ì œëª© ì—†ìŒ") 

        # 2-1. LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  ì£¼ ì±•í„° ì •ë³´ êµ¬ì„±
        chapter_display = f"{major_chapter_item.get('number')} {major_chapter_item.get('title')}"
        target_info_full = f"[{chapter_display}]\nì„¤ëª…: {major_chapter_item.get('description')}" 

        print('target_info_full: ', target_info_full)
        
        # 2-2. í•˜ìœ„ í•­ëª© ë°ì´í„° ì¶”ì¶œ
        for item in toc_structure:
            num = item.get("number", "")
            if num.startswith(major_chapter_number + '.') and '.' in num:
                all_sub_section_numbers.append(num)
        
        # 2-3. í¬ì»¤ìŠ¤ ëŒ€ìƒ (1.1 í•­ëª©) ë° ì ìˆ˜ ì„¤ì •
        if all_sub_section_numbers:
            first_subchapter_num = all_sub_section_numbers[0]
            first_subchapter_item = next((item for item in toc_structure if item.get("number") == first_subchapter_num), None)
            
            if first_subchapter_item:
                focused_subchapter_display = f"{first_subchapter_item.get('number')} {first_subchapter_item.get('title')}"
                # ê°œë³„ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸° 
                focused_subchapter_score = section_scores.get(first_subchapter_num, 0)
        
        # 2-4. ì „ì²´ ì§„í–‰ë¥  ì„¤ëª… ë¬¸ìì—´ ìƒì„±
        subchapter_list_str = ", ".join(all_sub_section_numbers)
        if all_sub_section_numbers:
            avg_score_description = f"({subchapter_list_str} í‰ê· , {major_chapter_title} ë‚´ {len(all_sub_section_numbers)}ê°œ í•­ëª©)"
        else:
            avg_score_description = f"({major_chapter_title} ìì²´ ì§„í–‰ë¥ )"

    # 3. ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
    msgs = state.get("messages", [])
    recent_history = ""
    if msgs:
        for msg in msgs:
            role = "ğŸ‘¤" if msg.get("role") == "user" else "ğŸ¤–"
            content = msg.get("content", "")
            recent_history += f"{role}: {content}\n"

    # 4. LLM í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE_CONSULTANT)
    chain = prompt | llm
    
    try:
        generated_response = chain.invoke({
            "target_chapter_info": target_info_full,
            "user_prompt": user_prompt,
            "collected_data": collected_data,
            "recent_history": recent_history,
            "grading_reason": grading_reason,
        }).content.strip()
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì˜¤ë¥˜: {e}")
        generated_response = "ì§ˆë¬¸ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
    
    # 5. ìµœì¢… ì¶œë ¥ (ì‹¬ì‚¬ ê¸°ì¤€ ì½”ë©˜íŠ¸ëŠ” ì œê±°, ì‚¬ìš©ìì—ê²ŒëŠ” ì§ˆë¬¸ë§Œ í‘œì‹œ)
    final_response = generated_response

    history = state.get("messages", [])
    history.append({"role": "assistant", "content": final_response})

    # ğŸ“Œ [ë””ë²„ê·¸] â€” scoreê°€ ì •ìƒì ìœ¼ë¡œ ë„˜ì–´ì˜¤ëŠ”ì§€ í™•ì¸
    # print("DEBUG >>> generate_query received state keys:", state.keys())
    # print("DEBUG >>> generate_query completeness_score:", state.get("completeness_score"))
    # print("DEBUG >>> generate_query section_scores:", section_scores)
    # print("DEBUG >>> generate_query focused score:", focused_subchapter_score)

    return {
        "current_query": final_response,
        "messages": history,
    }