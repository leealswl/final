from typing import Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from ..state_types import ProposalGenerationState
from dotenv import load_dotenv

# âœ… API í‚¤ ë¡œë“œ (ì•ˆì „ì¥ì¹˜)
load_dotenv()

# ------------------------------------------------------------------
# [Context-Aware ì»¨ì„¤í„´íŠ¸ í”„ë¡¬í”„íŠ¸]
# ------------------------------------------------------------------
PROMPT_TEMPLATE_CONSULTANT = """
ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… í•©ê²©ì„ ë•ëŠ” **'ì „ëµê¸°íš íŒŒíŠ¸ë„ˆ'**ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ê³  ìˆì§€ë§Œ, ë‹¹ì‹ ì˜ ìµœìš°ì„  ëª©í‘œëŠ” **[íŒì‚¬ì˜ í‰ê°€]ë¥¼ ë°˜ì˜í•˜ì—¬ ì ìˆ˜ë¥¼ 80ì ì´ìƒ(í†µê³¼)ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒ**ì…ë‹ˆë‹¤.

<ì…ë ¥ ì •ë³´>
1. **ì‘ì„± ëª©í‘œ**: "{target_chapter_info}"
2. **ê³µê³ ë¬¸ í•µì‹¬**: "{anal_guide_summary}"
3. **ëˆ„ì ëœ ì •ë³´**: {collected_data}
4. **ì‚¬ìš©ì ë°œì–¸**: "{user_prompt}"
5. **ìµœê·¼ ëŒ€í™”**: {recent_history}

##### 6. [ğŸš¨ í•µì‹¬] íŒì‚¬ì˜ í‰ê°€ (Judge's Feedback) #####
- **í˜„ì¬ ì ìˆ˜**: {current_score}ì 
- **í‰ê°€ ì‚¬ìœ **: {grading_reason}
- **ë¶€ì¡±í•œ í•­ëª©(Missing Points)**: {missing_points}
#######################################################

<ì‚¬ê³  ê³¼ì • (Think Process)>
1. **ìƒíƒœ ì ê²€**: 
   - ë§Œì•½ [ë¶€ì¡±í•œ í•­ëª©]ì´ ì¡´ì¬í•œë‹¤ë©´, í˜„ì¬ ì‚¬ìš©ìê°€ ì—‰ëš±í•œ ì´ì•¼ê¸°(ì´ë¯¸ ì¶©ë¶„í•œ ì´ì•¼ê¸°)ë¥¼ í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
   - ì˜ˆ: ì´ë¯¸ ROIëŠ” ì¶©ë¶„í•œë° ê³„ì† ROIë¥¼ ë§í•˜ê³  ìˆë‹¤ë©´, í™”ì œë¥¼ [ë¶€ì¡±í•œ í•­ëª©]ìœ¼ë¡œ ëŒë ¤ì•¼ í•©ë‹ˆë‹¤.

2. **ë°˜ì‘ ë° ì „í™˜**:
   - ì‚¬ìš©ìì˜ ë§ì— **ì§§ê²Œ í˜¸ì‘**("í›Œë¥­í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤")í•œ ë’¤, **"í•˜ì§€ë§Œ í•©ê²©ì„ ìœ„í•´ì„œëŠ” ~ê°€ ë³´ì™„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"**ë¼ë©° í™”ì œë¥¼ ì „í™˜í•˜ì„¸ìš”.
   - **ë¬´ì¡°ê±´ [ë¶€ì¡±í•œ í•­ëª©]ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.**

3. **ì§ˆë¬¸ ì „ëµ**:
   - ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤. 
   - ì˜ˆ: "ìˆ˜ìµì„±ì€ ì¦ëª…ë˜ì—ˆìŠµë‹ˆë‹¤. (ì „í™˜) ë‹¤ë§Œ ì‹¬ì‚¬ìœ„ì›ì€ **'ì‚¬ì—…ì˜ í•„ìš”ì„±'**ì„ ë´…ë‹ˆë‹¤. ì™œ **ì§€ê¸ˆ ì´ ì‹œì **ì— ì´ ê¸°ìˆ ì´ í•„ìš”í•œê°€ìš”?"

<ì¶œë ¥ ê°€ì´ë“œ>
- **ì ˆëŒ€ ê¸ˆì§€**: í–ˆë˜ ì§ˆë¬¸ ë°˜ë³µí•˜ê¸°, ì ìˆ˜ê°€ ê¹ì¸ ì›ì¸ì„ ë¬´ì‹œí•˜ê³  ì¡ë‹´ ì´ì–´ê°€ê¸°.
- **ë§íˆ¬**: ì „ë¬¸ê°€ë‹¤ìš´ ìì—°ìŠ¤ëŸ¬ìš´ íšŒí™”ì²´.
"""
# ëŒ€í™”ê°€ 100ë§ˆë””ê°€ ë„˜ì–´ê°”ì„ ë•Œ, messages ì „ì²´ë¥¼ LLMì—ê²Œ ë‹¤ ë˜ì ¸ì£¼ë©´ í† í° ë¹„ìš©ì´ í­ë°œí•˜ê³ 
# AIê°€ í—·ê°ˆë ¤ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ **"ìµœê·¼ 4ë§ˆë””([-4:])ë§Œ ì˜ë¼ì„œ ë³´ì—¬ì£¼ì"**ë¼ê³  ë§Œë“  ê²ƒì´
#  recent_historyì…ë‹ˆë‹¤.

def generate_query(state: ProposalGenerationState) -> Dict[str, Any]: 
    print("--- ë…¸ë“œ ì‹¤í–‰: generate_query (Score Display / Fix Error) ---")

    try:
        llm = ChatOpenAI(temperature=0.1, model="gpt-4o")
    except Exception:
        return {"current_query": "ì˜¤ë¥˜ ë°œìƒ"}

    # 1. ë°ì´í„° ë§¤í•‘
    user_prompt = state.get("user_prompt", "")
    collected_data = state.get("collected_data", "")
    if not collected_data: collected_data = "(ì—†ìŒ)"
    
    current_score = state.get("completeness_score", 0) # ì ìˆ˜
    grading_reason = state.get("grading_reason", "")  # ì´ìœ 
    missing_points = ", ".join(state.get("missing_subsections", []))
    fetched_context = state.get("fetched_context", {})
    anal_guide_summary = str(fetched_context.get("anal_guide", "ì „ëµ ì •ë³´ ì—†ìŒ"))

    # 2. [í•µì‹¬] í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì±•í„° ì •ë³´ ì •í™•íˆ ê°€ì ¸ì˜¤ê¸°
    toc_structure = state.get("draft_toc_structure", [])
    current_idx = state.get("current_chapter_index", 0)
    chapter_title = "ì „ì²´ ê°œìš”"
    target_info_full = "ì •ë³´ ìˆ˜ì§‘"
    
    if toc_structure and current_idx < len(toc_structure):
        item = toc_structure[current_idx]
        # ì˜ˆ: "1.1 ì‚¬ì—… ë°°ê²½"
        chapter_display = f"{item.get('number')} {item.get('title')}"
        target_info_full = f"[{chapter_display}]\nì„¤ëª…: {item.get('description')}"
    
    # 4. íˆìŠ¤í† ë¦¬ (recent_history)
    msgs = state.get("messages", []) # ë‚´ê°€ ì €ì¥í•´ë†“ì€ ì „ì²´ì¡±ë³´ ë‹¤ê°€ì ¸ì˜´
    recent_history = ""
    if msgs:
        for msg in msgs[-4:]:  # ìµœê·¼ 4ê°œë§Œë½‘ìŒ
            role = "ğŸ‘¤" if msg.get('role') == 'user' else "ğŸ¤–"
            content = msg.get('content', '')
            recent_history += f"{role}: {content}\n" #ë¬¸ìì—´ì— ë‹´ìŒ
    
    # Stateì—ì„œ ë¶€ì¡±í•œ í•­ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
    missing_list = state.get("missing_subsections", [])
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë¬¸ìì—´ë¡œ ë³€í™˜í•¨.
    missing_points = ", ".join(missing_list) if missing_list else "(ì—†ìŒ)" 

    # 5. LLM ì‹¤í–‰
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE_CONSULTANT)
    chain = prompt | llm
    
    try:
        #  ì¤€ë¹„í•œ ë³€ìˆ˜ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ë˜ì ¸ì¤Œ
        generated_response = chain.invoke({
            "anal_guide_summary": anal_guide_summary,
            "target_chapter_info": target_info_full,
            "user_prompt": user_prompt,
            "collected_data": collected_data,
            "recent_history": recent_history,
            "current_score": current_score,
            "grading_reason": grading_reason,
            "missing_points": missing_points
        }).content.strip()

    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì˜¤ë¥˜: {e}")
        generated_response = "ì§ˆë¬¸ ìƒì„± ì¤‘ ë³€ìˆ˜ ë§¤í•‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # 6. í”¼ë“œë°± í…ìŠ¤íŠ¸ ìƒì„±
    feedback_text = ""  
    if grading_reason:
        feedback_text = f" | ğŸ’¡ {grading_reason}"
    
    # [í•µì‹¬] "í˜„ì¬ 1.1ë²ˆ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤"ë¥¼ ëª…í™•íˆ í‘œì‹œ
    final_response = f"{generated_response}\n\n**(ğŸ“Œ í˜„ì¬ ì§„í–‰ì¤‘: [{chapter_display}] ì™„ì„±ë„: {current_score}%{feedback_text})**"

    # 7. íˆìŠ¤í† ë¦¬ ì €ì¥
    history = state.get("messages", [])
    history.append({"role": "assistant", "content": final_response})

    return {
        "current_query": final_response,
        "messages": history
    }