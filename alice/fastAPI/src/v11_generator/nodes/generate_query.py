# íŒŒì¼: generate_query.py (ì „ì²´ êµì²´)

from typing import Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from ..state_types import ProposalGenerationState
from dotenv import load_dotenv

load_dotenv()


PROMPT_TEMPLATE_CONSULTANT = """
ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… í•©ê²©ì„ ë•ëŠ” ìµœê³  ìˆ˜ì¤€ì˜ â€œì „ëµê¸°íš íŒŒíŠ¸ë„ˆ AI ì»¨ì„¤í„´íŠ¸â€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ìµœì¢… ëª©í‘œëŠ” ì‚¬ì—…ê³„íšì„œì˜ ì™„ì„±ë„ë¥¼ ë†’ì—¬ **ì‹¬ì‚¬ìœ„ì› ì ìˆ˜ 70ì  ì´ìƒ(í•©ê²© ê¸°ì¤€)**ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°ì •ì  ë§Œì¡±ë³´ë‹¤, â€œì‹¬ì‚¬ ê¸°ì¤€ ì¶©ì¡±â€ê³¼ â€œì ìˆ˜ ê°œì„ â€ì´ ì ˆëŒ€ì  ìš°ì„ ìˆœìœ„ì…ë‹ˆë‹¤.

======================================================================
ğŸ“Œ <ì…ë ¥ ì •ë³´>
1. ì‘ì„± ëŒ€ìƒ ëª©ì°¨(Target Section): "{target_chapter_info}"
2. ê³µê³ ë¬¸ í•µì‹¬ ë¶„ì„ ìš”ì•½(Key Guidelines Summary): "{anal_guide_summary}"
3. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì‚¬ìš©ì ì •ë³´(Collected Data): {collected_data}
4. ì‚¬ìš©ìì˜ ìµœê·¼ ë°œì–¸(User Message): "{user_prompt}"
5. ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬(Recent Chat History): {recent_history}

6. íŒì‚¬ì˜ í‰ê°€(Judgeâ€™s Feedback)
- í˜„ì¬ ì ìˆ˜(Current Score): {current_score}ì 
- ê°ì  ì‚¬ìœ (Reason of Deduction): {grading_reason}
======================================================================

ğŸ¯ <ì—­í•  ë° ì˜ì‚¬ê²°ì • ì›ì¹™>
1. ë¨¼ì € ì…ë ¥ëœ ì •ë³´ë§Œìœ¼ë¡œ ì‹¬ì‚¬ìœ„ì› ì‹œê°ì—ì„œ â€œí˜„ ìƒíƒœì˜ ë¬¸ì œâ€ë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤.
2. ë¶€ì¡±í•œ ìš”ì†Œë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•œ **í•µì‹¬ ì§ˆë¬¸**ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
3. ì§ˆë¬¸ì€ ë°˜ë“œì‹œ **êµ¬ì²´ì  / ì¸¡ì • ê°€ëŠ¥ / ì‘ì„± ëª©ì°¨ ê°œì„ ì— ì§ì ‘ ë„ì›€ì´ ë˜ëŠ” êµ¬ì¡°**ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
4. ì´ë¯¸ íˆìŠ¤í† ë¦¬ì—ì„œ ì§ˆë¬¸í–ˆê±°ë‚˜ ë‹µë³€ë˜ì—ˆë˜ ë‚´ìš©ì€ ì ˆëŒ€ ë‹¤ì‹œ ë¬»ì§€ ì•ŠìŠµë‹ˆë‹¤.
5. ì •ë³´ê°€ ì´ë¯¸ ì¶©ë¶„í•˜ë‹¤ë©´, ì§ˆë¬¸ ëŒ€ì‹  **ì‘ì„± ë°©í–¥ ì œì•ˆ(ì „ëµ ì½”ì¹­)**ì„ ì œê³µí•©ë‹ˆë‹¤.

======================================================================
ğŸ§  <ì‚¬ê³  ê³¼ì • (Chain-of-Thought ìš”ì•½)>
- Step 1. í˜„ì¬ ì ìˆ˜ ì›ì¸({grading_reason})ê³¼ ë¶€ì¡±í•œ ìš”ì†Œ ë¶„ì„
- Step 2. ìˆ˜ì§‘ëœ ì •ë³´({collected_data})ì—ì„œ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²ƒ vs ë¶€ì¡±í•œ ìš”ì†Œ ë¶„ë¦¬
- Step 3. â€œí•©ê²©ì„ ìœ„í•œ ë‹¤ìŒ í–‰ë™(ì§ˆë¬¸ ë˜ëŠ” ì‘ì„± ì§€ì‹œ)â€ì„ ê²°ì •
- Step 4. ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì œ (ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ ê¸ˆì§€)

======================================================================
ğŸ“ <ì¶œë ¥ í˜•ì‹>
ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤. í˜•ì‹ ë³€ê²½ ê¸ˆì§€.

[ì „ë¬¸ê°€ ì½”ë©˜íŠ¸]
(ì‚¬ìš©ì ë°œì–¸ì— ê³µê° 1ë¬¸ì¥ + ì ìˆ˜ ê°œì„  í•„ìš”ì„± ê°•ì¡° 1ë¬¸ì¥)

[ì‹¬ì‚¬ ê¸°ì¤€ ê´€ì  ë¬¸ì œ ìš”ì•½]
- (í˜„ì¬ ë¶€ì¡±í•œ ì ì„ ëª…í™•íˆ 1~2ì¤„ë¡œ ìš”ì•½)

[ë‹¤ìŒ í•µì‹¬ ì§ˆë¬¸]
(ë¶€ì¡±í•œ ìš”ì†Œë¥¼ ì±„ìš°ê¸° ìœ„í•œ ì§ˆë¬¸. ë°˜ë“œì‹œ êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•´ì•¼ í•¨.)

======================================================================
â›” ì ˆëŒ€ ê¸ˆì§€
- íˆìŠ¤í† ë¦¬ ì¤‘ë³µ ì§ˆë¬¸ ë°˜ë³µ
- ê³µê°ì„ ê°€ì¥í•œ ì¡ë‹´, ì˜ë¡€ì  ì¸ì‚¬
- "ë” ì„¤ëª…í•´ì£¼ì„¸ìš”" / "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œë°" ê°™ì€ í¬ê´„ì  ì§ˆë¬¸
- ë‹¤ì¤‘ ì§ˆë¬¸ (í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ)

======================================================================
ğŸ’¡ ì§ˆë¬¸ ìƒì„± ì˜ˆì‹œ
- "í˜„ì¬ ì†”ë£¨ì…˜ì˜ í•„ìš”ì„±ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì´ ì§€ê¸ˆ ì‹œì¥ì—ì„œ ë°˜ë“œì‹œ í•„ìš”í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
- "ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì˜ êµ¬ì²´ì  íŠ¹ì„±ê³¼ êµ¬ë§¤ ì˜ì‚¬ ê²°ì • ìš”ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "ì˜ˆìƒ ë§¤ì¶œì„ ì¦ëª…í•  ìˆ˜ ìˆëŠ” ê·¼ê±°ë‚˜ ë°ì´í„°ê°€ ìˆë‚˜ìš”?"

======================================================================


"""

def generate_query(state: ProposalGenerationState) -> ProposalGenerationState:
    print("--- ë…¸ë“œ ì‹¤í–‰: generate_query (Score Display / Fix Error) ---")
    
    # ğŸŒŸ [ì˜¤ë¥˜ í•´ê²°] generated_response ë³€ìˆ˜ë¥¼ ë¯¸ë¦¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    generated_response = ""
    
    try:
        llm = ChatOpenAI(temperature=0.1, model="gpt-4o")
    except Exception:
        return {"current_query": "LLM ì´ˆê¸°í™” ì˜¤ë¥˜ ë°œìƒ"}

    # 1. ìƒíƒœ ë³€ìˆ˜ ì¶”ì¶œ ë° ì´ˆê¸°ê°’ ì„¤ì •
    user_prompt = state.get("user_prompt", "")
    collected_data = state.get("collected_data", "")
    if not collected_data:
        collected_data = "(ì—†ìŒ)"
    
    current_avg_score = state.get("completeness_score", 0) 
    grading_reason = state.get("grading_reason", "")
    # missing_list = state.get("missing_subsections", [])
    section_scores = state.get("section_scores", {}) 
    # missing_points = ", ".join(missing_list) if missing_list else "(ì—†ìŒ)"
    
    fetched_context = state.get("fetched_context", {})
    anal_guide_summary = str(fetched_context.get("anal_guide", "ì „ëµ ì •ë³´ ì—†ìŒ"))

    toc_structure = state.get("draft_toc_structure", [])
    current_idx = state.get("current_chapter_index", 0)
    
    # 2. [í•µì‹¬] ì§„í–‰ë¥  í‘œì‹œ ë³€ìˆ˜ ì´ˆê¸°í™” ë° ê³„ì‚°
    major_chapter_title = "ì±•í„° ì œëª© ì—†ìŒ"
    focused_subchapter_display = "ì´ˆê¸° ì§ˆë¬¸"
    focused_subchapter_score = current_avg_score #í˜„ì¬ ASSESS_INFOì˜ ê²°ê³¼ ì ìˆ˜
    all_sub_section_numbers = []
    # avg_score_description = "(ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ë˜ëŠ” ì´ˆê¸° ì§„ì…)"
    target_info_full = "ì •ë³´ ìˆ˜ì§‘"
    chapter_display = "ì „ì²´ ê°œìš”"

    if toc_structure and current_idx < len(toc_structure):
        major_chapter_item = toc_structure[current_idx]
        major_chapter_number = major_chapter_item.get("number", "0") 
        major_chapter_title = major_chapter_item.get("title", "ì œëª© ì—†ìŒ") 

        # 2-1. LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  ì£¼ ì±•í„° ì •ë³´ êµ¬ì„±
        chapter_display = f"{major_chapter_item.get('number')} {major_chapter_item.get('title')}"
        target_info_full = f"[{chapter_display}]\nì„¤ëª…: {major_chapter_item.get('description')}" 

        print('target_info_full: ', target_info_full)
        
        # 2-2. í•˜ìœ„ í•­ëª© ë°ì´í„° ì¶”ì¶œ
        for item in toc_structure:
            num = item.get("number", "")
            if num.startswith(major_chapter_number + '.') and '.' in num:
                all_sub_section_numbers.append(num)
        
        # 2-3. í¬ì»¤ìŠ¤ ëŒ€ìƒ (1.1 í•­ëª©) ë° ì ìˆ˜ ì„¤ì •
        if all_sub_section_numbers:
            first_subchapter_num = all_sub_section_numbers[0]
            first_subchapter_item = next((item for item in toc_structure if item.get("number") == first_subchapter_num), None)
            
            if first_subchapter_item:
                focused_subchapter_display = f"{first_subchapter_item.get('number')} {first_subchapter_item.get('title')}"
                # ê°œë³„ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸° 
                focused_subchapter_score = section_scores.get(first_subchapter_num, 0)
        
        # 2-4. ì „ì²´ ì§„í–‰ë¥  ì„¤ëª… ë¬¸ìì—´ ìƒì„±
        subchapter_list_str = ", ".join(all_sub_section_numbers)
        if all_sub_section_numbers:
            avg_score_description = f"({subchapter_list_str} í‰ê· , {major_chapter_title} ë‚´ {len(all_sub_section_numbers)}ê°œ í•­ëª©)"
        else:
            avg_score_description = f"({major_chapter_title} ìì²´ ì§„í–‰ë¥ )"

    # 3. ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
    msgs = state.get("messages", [])
    recent_history = ""
    if msgs:
        for msg in msgs:
            role = "ğŸ‘¤" if msg.get("role") == "user" else "ğŸ¤–"
            content = msg.get("content", "")
            recent_history += f"{role}: {content}\n"

    # 4. LLM í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE_CONSULTANT)
    chain = prompt | llm
    
    try:
        generated_response = chain.invoke({
            "anal_guide_summary": anal_guide_summary,
            "target_chapter_info": target_info_full,
            "user_prompt": user_prompt,
            "collected_data": collected_data,
            "recent_history": recent_history,
            "current_score": current_avg_score,
            "grading_reason": grading_reason,
            # "missing_points": missing_points
        }).content.strip()
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì˜¤ë¥˜: {e}")
        generated_response = "ì§ˆë¬¸ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
    
    # 5. ìµœì¢… ì¶œë ¥ í¬ë§· êµ¬ì„± (ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜)
    feedback_text = f"ğŸ’¡ {grading_reason}" if grading_reason else ""
    
    final_response = (
        f"{generated_response}\n\n"
        f"{feedback_text}"
    )

    history = state.get("messages", [])
    history.append({"role": "assistant", "content": final_response})

    # ğŸ“Œ [ë””ë²„ê·¸] â€” scoreê°€ ì •ìƒì ìœ¼ë¡œ ë„˜ì–´ì˜¤ëŠ”ì§€ í™•ì¸
    # print("DEBUG >>> generate_query received state keys:", state.keys())
    # print("DEBUG >>> generate_query completeness_score:", state.get("completeness_score"))
    # print("DEBUG >>> generate_query section_scores:", section_scores)
    # print("DEBUG >>> generate_query focused score:", focused_subchapter_score)

    return {
        "current_query": final_response,
        "messages": history,
    }