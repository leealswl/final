"""
ì§ˆë¬¸ ìƒì„± ë…¸ë“œ
ë¶€ì¡±í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê±°ë‚˜, 80ì  ì´ìƒì¼ ë•Œ ì™„ë£Œ ì¶”ì²œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI 
from langchain_core.prompts import PromptTemplate 
from ..state_types import ProposalGenerationState
from dotenv import load_dotenv

load_dotenv()


PROMPT_TEMPLATE_CONSULTANT = """
ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… í•©ê²©ì„ ë•ëŠ” ìµœê³  ìˆ˜ì¤€ì˜ â€œì „ëžµê¸°íš íŒŒíŠ¸ë„ˆ AI ì»¨ì„¤í„´íŠ¸â€ìž…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ìµœì¢… ëª©í‘œëŠ” ì‚¬ì—…ê³„íšì„œì˜ ì™„ì„±ë„ë¥¼ ë†’ì—¬ **ì‹¬ì‚¬ìœ„ì› ì ìˆ˜ 70ì  ì´ìƒ(í•©ê²© ê¸°ì¤€)**ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.
ì‚¬ìš©ìžì˜ ê°ì •ì  ë§Œì¡±ë³´ë‹¤, â€œì‹¬ì‚¬ ê¸°ì¤€ ì¶©ì¡±â€ê³¼ â€œì ìˆ˜ ê°œì„ â€ì´ ì ˆëŒ€ì  ìš°ì„ ìˆœìœ„ìž…ë‹ˆë‹¤.

    
    # ðŸ”‘ 1. ì™„ë£Œëœ ëª©ì°¨ ì–¸ê¸‰ í”Œëž˜ê·¸ í™•ì¸ (HISTORY_CHECKERì—ì„œ ì„¤ì •ë¨)
    target_completed = state.get("target_already_completed")
    
    # ðŸ”‘ [í•µì‹¬ ìˆ˜ì •] ì™„ë£Œëœ ëª©ì°¨ ì–¸ê¸‰ ì‹œ ë¶„ê¸° (ë‹¨ìˆœ ì‘ë‹µ)
    if target_completed:
        # í˜„ìž¬ ì§„í–‰í•´ì•¼ í•  ëª©í‘œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (history_checkerê°€ ê²°ì •í•œ ë‹¤ìŒ ì±•í„°)
        current_target = state.get('target_chapter', 'ë‹¤ìŒ ìž‘ì—… ëª©í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        
        # ì‚¬ìš©ìž ìš”ì²­ì— ë”°ë¥¸ ë‹¨ìˆœ ì™„ë£Œ ë©”ì‹œì§€
        completion_message = (
            f"âœ… **[ìž‘ì„± ì™„ë£Œ]**\n"
            f"ì‚¬ìš©ìžë‹˜ê»˜ì„œ ì–¸ê¸‰í•˜ì‹  ëª©ì°¨ **'{target_completed}'**ëŠ” **ì´ë¯¸ ì •ë³´ ìˆ˜ì§‘ì´ ì™„ë£Œ**ë˜ì–´ ì´ˆì•ˆ ë°ì´í„°ì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
            f"í˜„ìž¬ ì €í¬ê°€ ì§‘ì¤‘í•´ì•¼ í•  ë‹¤ìŒ ëª©í‘œëŠ” **'{current_target}'** ìž…ë‹ˆë‹¤. ì´ ëª©í‘œì— ëŒ€í•œ ì •ë³´ë¥¼ ê³„ì† ìž…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤."
        )
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ë°˜í™˜
        history = state.get("messages", [])
        history.append({"role": "assistant", "content": completion_message})
        
        print(f"âœ… ì™„ë£Œëœ ëª©ì°¨ ì–¸ê¸‰ ê°ì§€: '{target_completed}' - ì™„ë£Œ ë©”ì‹œì§€ ë°˜í™˜")
        
        return {
            "current_query": completion_message,
            "messages": history,
            "target_already_completed": None # â¬…ï¸ í”Œëž˜ê·¸ ì´ˆê¸°í™”
        }
    
    current_avg_score = state.get("completeness_score", 0) 
    grading_reason = state.get("grading_reason", "")
    # missing_list = state.get("missing_subsections", [])
    section_scores = state.get("section_scores", {}) 
    # missing_points = ", ".join(missing_list) if missing_list else "(ì—†ìŒ)"
    
    # ðŸ”‘ [í•µì‹¬ ë³€ìˆ˜] attempt_count ê°€ì ¸ì˜¤ê¸°
    attempt_count = state.get("attempt_count", 0)
    
    # 2. [í•µì‹¬] ì§„í–‰ë¥  í‘œì‹œ ë³€ìˆ˜ ì´ˆê¸°í™” ë° ê³„ì‚°
    major_chapter_title = "ì±•í„° ì œëª© ì—†ìŒ"
    focused_subchapter_display = "ì´ˆê¸° ì§ˆë¬¸"
    focused_subchapter_score = current_avg_score #í˜„ìž¬ ASSESS_INFOì˜ ê²°ê³¼ ì ìˆ˜
    all_sub_section_numbers = []
    # avg_score_description = "(ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ë˜ëŠ” ì´ˆê¸° ì§„ìž…)"
    target_info_full = "ì •ë³´ ìˆ˜ì§‘"
    chapter_display = "ì „ì²´ ê°œìš”"

    # ðŸ”‘ 2. ë‹¤ìŒ ëª©í‘œ ì±•í„° ì œëª© ì°¾ê¸° (Manage Progressionì´ ì—…ë°ì´íŠ¸í•œ ì¸ë±ìŠ¤ ê¸°ë°˜)
    next_idx = state.get("current_chapter_index", 0)
    toc = state.get("draft_toc_structure", [])

        # 2-1. LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  ì£¼ ì±•í„° ì •ë³´ êµ¬ì„±
        chapter_display = f"{major_chapter_item.get('number')} {major_chapter_item.get('title')}"
        target_info_full = f"[{chapter_display}]\nì„¤ëª…: {major_chapter_item.get('description')}" 

        print('target_info_full: ', target_info_full)
        
        # 2-2. í•˜ìœ„ í•­ëª© ë°ì´í„° ì¶”ì¶œ
        for item in toc_structure:
            num = item.get("number", "")
            if num.startswith(major_chapter_number + '.') and '.' in num:
                all_sub_section_numbers.append(num)
        
        # 2-3. í¬ì»¤ìŠ¤ ëŒ€ìƒ (1.1 í•­ëª©) ë° ì ìˆ˜ ì„¤ì •
        if all_sub_section_numbers:
            first_subchapter_num = all_sub_section_numbers[0]
            first_subchapter_item = next((item for item in toc_structure if item.get("number") == first_subchapter_num), None)
            
            if first_subchapter_item:
                focused_subchapter_display = f"{first_subchapter_item.get('number')} {first_subchapter_item.get('title')}"
                # ê°œë³„ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸° 
                focused_subchapter_score = section_scores.get(first_subchapter_num, 0)
        
        # 2-4. ì „ì²´ ì§„í–‰ë¥  ì„¤ëª… ë¬¸ìžì—´ ìƒì„±
        subchapter_list_str = ", ".join(all_sub_section_numbers)
        if all_sub_section_numbers:
            avg_score_description = f"({subchapter_list_str} í‰ê· , {major_chapter_title} ë‚´ {len(all_sub_section_numbers)}ê°œ í•­ëª©)"
        else:
            avg_score_description = f"({major_chapter_title} ìžì²´ ì§„í–‰ë¥ )"

    # 3. ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
    msgs = state.get("messages", [])
    recent_history = ""
    if msgs:
        for msg in msgs:
            role = "ðŸ‘¤" if msg.get("role") == "user" else "ðŸ¤–"
            content = msg.get("content", "")
            recent_history += f"{role}: {content}\n"

    # 4. --- LLM í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„± ---
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
    chain = prompt | llm

    try:
        final_message_content = chain.invoke({
            "completeness_score": completeness_score,
            "grading_reason": grading_reason,
            # "missing_points": missing_points
        }).content.strip()
    except Exception as e:
        final_message_content = f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({e})"

    # 5. --- ìµœì¢… ì‘ë‹µ êµ¬ì„± (ìƒˆë¡œìš´ ë¡œì§) ---
    final_response_prefix = ""
    
    # 5. ìµœì¢… ì¶œë ¥ í¬ë§· êµ¬ì„± (ì‚¬ìš©ìž ìš”ì²­ ë°˜ì˜)
    feedback_text = f"ðŸ’¡ {grading_reason}" if grading_reason else ""
    
    final_response = (
        f"{generated_response}\n\n"
        f"{feedback_text}"
    )

    history = state.get("messages", [])
    history.append({"role": "assistant", "content": final_response})

    # ðŸ“Œ [ë””ë²„ê·¸] â€” scoreê°€ ì •ìƒì ìœ¼ë¡œ ë„˜ì–´ì˜¤ëŠ”ì§€ í™•ì¸
    # print("DEBUG >>> generate_query received state keys:", state.keys())
    # print("DEBUG >>> generate_query completeness_score:", state.get("completeness_score"))
    # print("DEBUG >>> generate_query section_scores:", section_scores)
    # print("DEBUG >>> generate_query focused score:", focused_subchapter_score)

    return {
        "current_query": final_response,
        "messages": history,
    }
