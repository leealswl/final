# ëª©ì°¨(ë‹¨ë½)ì„ ê´€ë¦¬ í•´ì£¼ëŠ” ë§¤ë‹ˆì € í•¨ìˆ˜ 
# í•œë½ì´ ì™„ì„±ì´ ë˜ë©´ ê·¸ ì™„ì„±ëë‹¤ëŠ” ì •ë³´ë¥¼ íŒì‚¬í•¨ìˆ˜ì™€ ì‘ì„±í•¨ìˆ˜ì—ê²Œì „ë‹¬

from typing import Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from ..state_types import ProposalGenerationState
from dotenv import load_dotenv

load_dotenv()

def manage_progression(state: ProposalGenerationState) -> Dict[str, Any]:
    """
    [ì§„í–‰ ê´€ë¦¬ì ë…¸ë“œ]
    í•©ê²© ì‹œ: ëŒ€í™” ë‚´ìš© ìš”ì•½ -> ì €ì¥ -> ë‹¤ìŒ ì±•í„°ë¡œ ì¸ë±ìŠ¤ ì´ë™ -> ìƒíƒœ ë¦¬ì…‹
    """
    print("--- ë…¸ë“œ ì‹¤í–‰: manage_progression (Manager) ---")
    
    is_sufficient = state.get("sufficiency", False)
    current_idx = state.get("current_chapter_index", 0)
    toc = state.get("draft_toc_structure", [])
    
    # 1. í•©ê²© ì•ˆ í–ˆìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•¨
    if not is_sufficient:
        return {}

    # -------------------------------------------------------
    # [ê¸°ëŠ¥ 1] ëŒ€í™” ë‚´ìš© ìš”ì•½ (Summarize)
    # -------------------------------------------------------
    current_data = state.get("collected_data", "")
    summary_text = current_data # ê¸°ë³¸ê°’

    if current_data.strip():
        try:
            llm = ChatOpenAI(temperature=0, model="gpt-4o")
            SUMMARY_PROMPT = """
            ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ê¸°íšì„œ ì‘ì„±ìš©ìœ¼ë¡œ ê°„ëµíˆ ìš”ì•½í•˜ì„¸ìš”.
            (ì‚¬ì‹¤, ìˆ˜ì¹˜, ê²°ì •ëœ ì „ëµ ìœ„ì£¼ë¡œ)
            
            ëŒ€í™”: {text}
            """
            chain = PromptTemplate.from_template(SUMMARY_PROMPT) | llm
            summary_text = chain.invoke({"text": current_data}).content.strip()
            print(f"âš¡ ë°ì´í„° ìš”ì•½ ì™„ë£Œ: {len(current_data)}ì -> {len(summary_text)}ì")
        except Exception as e:
            print(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨(ì›ë³¸ ì €ì¥): {e}")

    # -------------------------------------------------------
    # [ê¸°ëŠ¥ 2] ì°½ê³ ì— ì €ì¥ (Archive)
    # -------------------------------------------------------
    accumulated = state.get("accumulated_data", "")
    
    # í˜„ì¬ ì±•í„° ì œëª© ì°¾ê¸°
    chapter_title = "ì±•í„°"
    if current_idx < len(toc):
        chapter_title = toc[current_idx].get("title", "ì œëª©ì—†ìŒ")
        
    # ì˜ˆì˜ê²Œ í¬ì¥í•´ì„œ ëˆ„ì 
    new_accumulated = f"{accumulated}\n\n### [{current_idx + 1}. {chapter_title} ìš”ì•½]\n{summary_text}\n--------------------\n"
    
    # -------------------------------------------------------
    # [ê¸°ëŠ¥ 3] ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (Next Chapter)
    # -------------------------------------------------------
    next_idx = current_idx + 1
    
    if next_idx < len(toc):
        next_chapter = toc[next_idx]
        print(f"â© ì±•í„° ì „í™˜! [{chapter_title}] -> [{next_chapter.get('title')}]")
        
        return {
            "current_chapter_index": next_idx,   # í˜ì´ì§€ ë„˜ê¹€
            "accumulated_data": new_accumulated, # ì°½ê³  ì €ì¥
            "collected_data": "",                # ìˆ˜ì²© ë¹„ìš°ê¸° (ì¤‘ìš”!)
            "completeness_score": 0,             # ì ìˆ˜ ë¦¬ì…‹
            "grading_reason": "",                # ì´ìœ  ë¦¬ì…‹
            "sufficiency": False                 # ë‹¤ì‹œ ë¶ˆí•©ê²© ìƒíƒœë¡œ
        }
    else:
        print("ğŸ‰ ëª¨ë“  ì±•í„° ì™„ë£Œ!")
        return {
            "accumulated_data": new_accumulated,
            "next_step": "FINISH"
        }