# ëª©ì°¨(ë‹¨ë½)ì„ ê´€ë¦¬ í•´ì£¼ëŠ” í•¨ìˆ˜ 
# í•œë½ì´ ì™„ì„±ì´ ë˜ë©´ ê·¸ ì™„ì„±ëë‹¤ëŠ” ì •ë³´ë¥¼ íŒì‚¬í•¨ìˆ˜ì™€ ì‘ì„±í•¨ìˆ˜ì—ê²Œì „ë‹¬

from typing import Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from ..state_types import ProposalGenerationState
from dotenv import load_dotenv

load_dotenv()

def manage_progression(state: ProposalGenerationState) -> Dict[str, Any]:
    print("--- ë…¸ë“œ ì‹¤í–‰: manage_progression (Section Progression) ---")
    
    is_sufficient = state.get("sufficiency", False)
    current_idx = state.get("current_chapter_index", 0)
    toc = state.get("draft_toc_structure", [])
    
    if not is_sufficient or current_idx >= len(toc):
        # ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜ ëª©ì°¨ ëì´ë©´ ì§„í–‰ ê´€ë¦¬ ë…¸ë“œê°€ í˜¸ì¶œë  ì¼ ì—†ìŒ (ë°©ì–´ì  ì½”ë“œ)
        return {} 

    # 1. ì´ì „ ì„¹ì…˜ ë°ì´í„° ìš”ì•½ ë° ëˆ„ì 
    
    # í˜„ì¬ ì™„ë£Œëœ ì„¹ì…˜ ì •ë³´
    current_item = toc[current_idx]
    current_number = current_item.get("number", "0")
    current_title = current_item.get("title", "ì œëª© ì—†ìŒ")
    current_data = state.get("collected_data", "")
    
    llm = None
    try:
        llm = ChatOpenAI(temperature=0, model="gpt-4o")
    except Exception as e:
        print(f"âš ï¸ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

    summary_text = current_data
    if llm and current_data.strip():
        SUMMARY_PROMPT = f"""
        ë‹¹ì‹ ì€ ê¸°íšì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ [ëŒ€í™” ë‚´ìš©]ì—ì„œ **[{current_title}]** ì‘ì„±ì— í•„ìš”í•œ **í•µì‹¬ ì •ë³´(ì‚¬ì‹¤, ìˆ˜ì¹˜, ì „ëµ)**ë§Œ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.
        ì¡ë‹´ì´ë‚˜ ë¶ˆí•„ìš”í•œ ë¬¸ì¥ì€ ëª¨ë‘ ì œê±°í•˜ì„¸ìš”. ê°œì¡°ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        
        ì‘ì„±ì´ ì™„ë£Œëœ ëª©ì°¨ëŠ” 
        <ëŒ€í™” ë‚´ìš©>
        {{current_data}}
        """
        try:
            prompt = PromptTemplate.from_template(SUMMARY_PROMPT)
            chain = prompt | llm
            summary_result = chain.invoke({"current_data": current_data}).content.strip()
            summary_text = summary_result
            print(f"âš¡ ë°ì´í„° ì••ì¶• ì™„ë£Œ: {current_number} - {len(current_data)}ì -> {len(summary_text)}ì")
        except Exception as e:
            print(f"âš ï¸ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ëˆ„ì  ë°ì´í„°ì— ë¶ˆëŸ¬ì˜¤ê¸°
    accumulated_data = state.get("accumulated_data", "")
    
    new_accumulated = f"{accumulated_data}\n\n### [{current_number} {current_title} ìš”ì•½]\n{summary_text}\n----------------------------------------\n"
    
    # 2. [í•µì‹¬] ë‹¤ìŒ ì„¹ì…˜ ì¸ë±ìŠ¤ ì°¾ê¸°
# 4. ë‹¤ìŒ ì±•í„° ê³„ì‚°
    
    # ------------------------------------------------------------------
    # ğŸ”‘ [í•µì‹¬ ìˆ˜ì •] í˜„ì¬ ì¸ë±ìŠ¤ ì´í›„ì˜ ì²« ë²ˆì§¸ 'í•˜ìœ„ ì„¹ì…˜' (ì˜ˆ: 1.2, 2.1)ì„ ì°¾ìŠµë‹ˆë‹¤.
    #    í•˜ìœ„ ì„¹ì…˜ì€ ë²ˆí˜¸ì— '.'ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    # ------------------------------------------------------------------
    next_idx = -1
    
    # í˜„ì¬ ì¸ë±ìŠ¤ ë‹¤ìŒë¶€í„° ëª©ì°¨ ëê¹Œì§€ ìˆœíšŒí•©ë‹ˆë‹¤.
    for i in range(current_idx + 1, len(toc)):
        item = toc[i]
        num = item.get("number", "")
        
        # ì†Œìˆ˜ì ('.')ì´ í¬í•¨ëœ 'í•˜ìœ„ ì„¹ì…˜'ì„ ì°¾ìŠµë‹ˆë‹¤. (ì˜ˆ: 1.1, 1.2, 2.1)
        if '.' in num: 
            next_idx = i
            break
            
    # ------------------------------------------------------------------

    if next_idx != -1:
        next_chapter = toc[next_idx]
        print(f"â© ì„¹ì…˜ ì „í™˜: [{current_title}] -> [{next_chapter.get('title')}]")
        
        return {
            "current_chapter_index": next_idx,
            "target_chapter": next_chapter.get("title", "ëª©í‘œ ì—†ìŒ"),
            "accumulated_data": new_accumulated,
            "collected_data": "", # ë‹¤ìŒ ì±•í„°ë¥¼ ìœ„í•´ ë°ì´í„° ì´ˆê¸°í™”
            "completeness_score": 0, # ë‹¤ìŒ ì±•í„° ì ìˆ˜ ì´ˆê¸°í™”
            "next_step": "GENERATE_QUERY"
        }
    else:
        # ë” ì´ìƒ í•˜ìœ„ ì„¹ì…˜ì´ ì—†ë‹¤ë©´ ëª¨ë“  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œë¡œ ê°„ì£¼
        print("ğŸ‰ ëª¨ë“  ì„¹ì…˜ ì™„ë£Œ: ìµœì¢… ì´ˆì•ˆ ìƒì„± ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        return {
            "next_step": "FINISH_DRAFT", # (ì¶”í›„ generate_draft ë…¸ë“œë¡œ ì—°ê²°)
            "accumulated_data": new_accumulated,
            "collected_data": "", 
            "current_draft": f"ìµœì¢… ì´ˆì•ˆì„ ìƒì„±í•˜ê¸° ìœ„í•œ ì •ë³´ê°€ ëª¨ë‘ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì´ ì •ë³´ ê¸¸ì´: {len(new_accumulated)}ì",
            "completeness_score": 100
        }