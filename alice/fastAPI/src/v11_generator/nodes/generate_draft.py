from ..state_types import ProposalGenerationState
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import logging
from typing import Dict, Any, Optional
import re
import json
from pathlib import Path
import os

def get_json_file_path() -> Path:
    """
    JSON íŒŒì¼ ì €ì¥ ê²½ë¡œë¥¼ ë°˜í™˜
    Returns:
        Path: backend/uploads/admin/1/1/234.json ê²½ë¡œ (Spring Bootê°€ ì„œë¹™í•˜ëŠ” ê²½ë¡œ)
    """
    current_file = Path(__file__).resolve()
    # alice/fastAPI/src/v11_generator/nodes/generate_draft.py
    # â†’ alice/fastAPI/src/ â†’ alice/fastAPI/ â†’ í”„ë¡œì íŠ¸ ë£¨íŠ¸
    project_root = current_file.parent.parent.parent.parent.parent
    # Spring Bootê°€ ì„œë¹™í•˜ëŠ” backend/uploads/ ê²½ë¡œì— ì €ì¥
    save_dir = project_root / "backend" / "uploads" / "admin" / "1" / "1"
    save_dir.mkdir(parents=True, exist_ok=True)
    return save_dir / "234.json"


def load_existing_json() -> Optional[Dict[str, Any]]:
    """
    ê¸°ì¡´ JSON íŒŒì¼ì„ ì½ì–´ì„œ ë°˜í™˜
    Phase 1: íŒŒì¼ ì½ê¸° ê¸°ëŠ¥
    
    Returns:
        Optional[Dict[str, Any]]: ProseMirror JSON êµ¬ì¡°, íŒŒì¼ì´ ì—†ìœ¼ë©´ None
    """
    file_path = get_json_file_path()
    
    try:
        if not file_path.exists():
            print(f"ğŸ“„ [Phase 1] íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
            return None
        
        print(f"ğŸ“– [Phase 1] íŒŒì¼ ì½ê¸° ì‹œì‘: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = json.load(f)
        
        # JSON êµ¬ì¡° ê²€ì¦
        if not isinstance(content, dict):
            print(f"âš ï¸ [Phase 1] JSONì´ dict í˜•ì‹ì´ ì•„ë‹˜: {type(content)}")
            return None
        
        if content.get("type") != "doc":
            print(f"âš ï¸ [Phase 1] ProseMirror JSON í˜•ì‹ì´ ì•„ë‹˜: type={content.get('type')}")
            return None
        
        paragraph_count = len(content.get("content", []))
        print(f"âœ… [Phase 1] íŒŒì¼ ì½ê¸° ì™„ë£Œ: {paragraph_count}ê°œ paragraph")
        
        return content
        
    except json.JSONDecodeError as e:
        print(f"âŒ [Phase 1] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ [Phase 1] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ğŸ” [Phase 1] ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None


def text_to_prosemirror_json(text: str) -> Dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ProseMirror JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    í•œê¸€ ë¬¸ì„œ/DOCX ìŠ¤íƒ€ì¼: ê° ì¤„ì„ ë³„ë„ paragraphë¡œ, ë¹ˆ ì¤„ë„ ë¹ˆ paragraphë¡œ ì²˜ë¦¬
    """
    if not text or not text.strip():
        return {
            "type": "doc",
            "content": []
        }
    
    # í”„ë¡¬í”„íŠ¸ì—ì„œ ë°˜í™˜ëœ í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ë³¸ë¬¸ë§Œ ì¶”ì¶œ
    # "----------------------------------------------------------------------" êµ¬ë¶„ì ì œê±°
    lines = text.split('\n')
    content_lines = []
    in_content = False
    
    for line in lines:
        line_stripped = line.strip()
        # êµ¬ë¶„ì ë¼ì¸ ë¬´ì‹œ
        if line_stripped.startswith('---') or line_stripped.startswith('==='):
            continue
        # <ì‘ì„±ëœ ì œì•ˆì„œ ë³¸ë¬¸> ê°™ì€ íƒœê·¸ ì œê±°
        if '<ì‘ì„±ëœ ì œì•ˆì„œ ë³¸ë¬¸>' in line_stripped or '</ì‘ì„±ëœ ì œì•ˆì„œ ë³¸ë¬¸>' in line_stripped:
            in_content = True
            continue
        # ëª¨ë“  ì¤„ì„ í¬í•¨ (ë¹ˆ ì¤„ë„ í¬í•¨)
        content_lines.append(line_stripped)
    
    # ê° ì¤„ì„ ë³„ë„ paragraphë¡œ ì²˜ë¦¬ (í•œê¸€ ë¬¸ì„œ ìŠ¤íƒ€ì¼)
    paragraphs = []
    
    for line in content_lines:
        # ë¹ˆ ì¤„ë„ ë¹ˆ paragraphë¡œ ì²˜ë¦¬
        if not line:
            paragraphs.append({
                "type": "paragraph",
                "attrs": {"textAlign": "left"},
                "content": [{"type": "text", "text": "â€‹"}]  # ë¹ˆ í…ìŠ¤íŠ¸ (zero-width space)
            })
        else:
            # ê° ì¤„ì„ ë³„ë„ paragraphë¡œ
            paragraphs.append({
                "type": "paragraph",
                "attrs": {"textAlign": "left"},
                "content": [{"type": "text", "text": line}]
            })
    
    # ë¹ˆ ê²½ìš° ê¸°ë³¸ paragraph ì¶”ê°€
    if not paragraphs:
        paragraphs.append({
            "type": "paragraph",
            "attrs": {"textAlign": None},
            "content": [{"type": "text", "text": ""}]
        })
    
    return {
        "type": "doc",
        "content": paragraphs
    }

def generate_proposal_draft(state: ProposalGenerationState) -> ProposalGenerationState:
    """
    [ì‘ê°€ ë…¸ë“œ - ë¹„í™œì„±í™” ìƒíƒœ]
    í˜„ì¬ëŠ” ì´ˆì•ˆ ìƒì„± ë¡œì§ì„ ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ë§‰ì•„ë‘ì—ˆìŠµë‹ˆë‹¤.
    í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë”ë¯¸(Dummy) ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print("ğŸ” [ë””ë²„ê¹…] --- ë…¸ë“œ ì‹¤í–‰: generate_proposal_draft ---")
    print(f"ğŸ” [ë””ë²„ê¹…] state.keys(): {list(state.keys())}")
    print(f"ğŸ” [ë””ë²„ê¹…] collected_data ê¸¸ì´: {len(state.get('collected_data', ''))}")
    logging.info(f"ğŸ“ generate_draft ë…¸ë“œ ì‹¤í–‰")

    DRAFT_PROMPT = """
        ë‹¹ì‹ ì€ í•œêµ­ ì •ë¶€ RFP(ì œì•ˆìš”ì²­ì„œ)Â·ì…ì°°Â·ì§€ì›ì‚¬ì—… ì œì•ˆì„œ ì‘ì„± ì „ë¬¸ê°€ì´ë©°,
        ì‹¤ì œ í‰ê°€ ì‹¬ì‚¬ìœ„ì›ì´ ì½ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ê³µì‹ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë¬¸ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

        ======================================================================
        ğŸ“Œ <ì…ë ¥ ì •ë³´>
        1. ì‘ì„± ëŒ€ìƒ ëª©ì°¨ (Target Section)
        - "{target_chapter_info}"

        2. ê³µê³ ë¬¸ í•µì‹¬ ë¶„ì„ ìš”ì•½ (Key Guidelines Summary)
        - "{anal_guide_summary}"

        3. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì‚¬ìš©ì ì •ë³´ (Collected Data)
        - {collected_data}

        4. ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ (Recent Chat History)
        - {recent_history}
        ======================================================================

        âœï¸ <ì‘ì„± ì§€ì¹¨>
        - ìœ„ ë„¤ ê°€ì§€ ì…ë ¥ ì •ë³´ë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ **ì •ë¶€ ì œì•ˆì„œ ê³µì‹ ë¬¸ì²´ë¡œ í•´ë‹¹ ëª©ì°¨ì˜ ì™„ì„±ëœ ë‹¨ë½**ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        - ë¬¸ë‹¨ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ê°œì¡°ì‹ ë‚˜ì—´ì´ í•„ìš”í•œ ê²½ìš° ì ì ˆíˆ í˜¼í•©í•˜ì‹­ì‹œì˜¤.
        - ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•œ ì˜ì—­ì´ ìˆì–´ë„ ì¶”ë¡  ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì™„í•˜ì‹­ì‹œì˜¤.
        - ë‹¨ìˆœ ìš”ì•½ì´ë‚˜ ë‚˜ì—´ì´ ì•„ë‹Œ **ë…¼ë¦¬ì  êµ¬ì¡°(ë°°ê²½ â†’ í•„ìš”ì„± â†’ ëª©ì  â†’ ê·¼ê±° â†’ ê¸°ëŒ€íš¨ê³¼ ë“±)**ë¡œ ì„¤ë“ë ¥ ìˆê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        - ê³µê³ ë¬¸ ìš”êµ¬ì‚¬í•­ê³¼ì˜ ì í•©ì„±ì„ ëª…í™•í•˜ê²Œ ë“œëŸ¬ë‚´ì‹­ì‹œì˜¤.
        - í‰ê°€ìœ„ì›ì´ ì½ì„ ë•Œ **ì‚¬ì—…ì˜ íƒ€ë‹¹ì„±, ì‹¤í˜„ ê°€ëŠ¥ì„±, ê³µê³µì„±, í˜ì‹ ì„±, ê¸°ëŒ€ ì„±ê³¼**ê°€ ê°•ì¡°ë˜ë„ë¡ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        - 'ìš°ë¦¬ëŠ”', 'ì €í¬ëŠ”' ê°™ì€ í‘œí˜„ ëŒ€ì‹  **ê¸°ì—…ëª… ë˜ëŠ” ì‚¬ì—… ì£¼ì²´ë¥¼ 3ì¸ì¹­ìœ¼ë¡œ ê¸°ìˆ **í•˜ì‹­ì‹œì˜¤.

        ğŸ“Œ <ì¶œë ¥ í˜•ì‹>
        ì•„ë˜ ProseMirror JSON í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

        {{
          "type": "doc",
          "content": [
            {{
              "type": "paragraph",
              "attrs": {{
                "textAlign": "left",
                "paragraphIndex": 0
              }},
              "content": [
                {{
                  "type": "text",
                  "text": "ì²« ë²ˆì§¸ ë¬¸ë‹¨ ë‚´ìš©"
                }}
              ]
            }},
            {{
              "type": "paragraph",
              "attrs": {{
                "textAlign": "left",
                "paragraphIndex": 1
              }},
              "content": [
                {{
                  "type": "text",
                  "text": "â€‹"
                }}
              ]
            }},
            {{
              "type": "paragraph",
              "attrs": {{
                "textAlign": "left",
                "paragraphIndex": 2
              }},
              "content": [
                {{
                  "type": "text",
                  "text": "ë‘ ë²ˆì§¸ ë¬¸ë‹¨ ë‚´ìš©"
                }}
              ]
            }}
          ]
        }}

        âš ï¸ ì¤‘ìš”:
        - ê° paragraphëŠ” paragraphIndexë¥¼ 0ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ë¶€ì—¬í•˜ì„¸ìš”
        - ë¹ˆ ì¤„ì€ text: "â€‹" (zero-width space)ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”
        - ì½”ë“œ ë¸”ë¡ ë§ˆì»¤(```)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
        - ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”
        - ê° ë¬¸ë‹¨ì€ ë³„ë„ì˜ paragraphë¡œ êµ¬ë¶„í•˜ì„¸ìš”
        """
    
    # 2. í˜„ì¬ ëª©í‘œ ì„¹ì…˜ ì •ë³´ ì„¤ì • (history_checkerì˜ ê²°ì • ë°˜ì˜ ë¡œì§)
    collected_data = state.get("collected_data", "")
    # print('collected_data: ', collected_data)
    # print(f"--- ğŸ“Š ASSESS_INFO ìˆ˜ì‹  ë°ì´í„° ê¸¸ì´: {len(collected_data)}ì ---")
    
    toc_structure = state.get("draft_toc_structure", [])
    target_title = state.get("target_chapter", "")
    current_idx = state.get("current_chapter_index", 0) 

    fetched_context = state.get("fetched_context", {})
    anal_guide_summary = str(fetched_context.get("anal_guide", "ì „ëµ ì •ë³´ ì—†ìŒ"))

    if toc_structure and current_idx < len(toc_structure):
        major_chapter_item = toc_structure[current_idx]
        major_chapter_number = major_chapter_item.get("number", "0") 
        major_chapter_title = major_chapter_item.get("title", "ì œëª© ì—†ìŒ") 

        # 2-1. LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  ì£¼ ì±•í„° ì •ë³´ êµ¬ì„±
        chapter_display = f"{major_chapter_item.get('number')} {major_chapter_item.get('title')}"
        target_info_full = f"[{chapter_display}]\nì„¤ëª…: {major_chapter_item.get('description')}" 

        print('target_info_full: ', target_info_full)

    msgs = state.get("messages", [])
    recent_history = ""
    if msgs:
        for msg in msgs:
            role = "ğŸ‘¤" if msg.get("role") == "user" else "ğŸ¤–"
            content = msg.get("content", "")
            recent_history += f"{role}: {content}\n"


    prompt = PromptTemplate.from_template(DRAFT_PROMPT)

    llm = None
    try:
        llm = ChatOpenAI(temperature=0, model="gpt-4o")
    except Exception as e:
        print(f"âš ï¸ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

    chain = prompt | llm | StrOutputParser()

    result = chain.invoke({
        'target_chapter_info': target_info_full,
        'anal_guide_summary': anal_guide_summary,
        'collected_data': collected_data,
        'recent_history': recent_history
        })
    
    # ë§Œì•½ accumulated_dataê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    accumulated_data = state.get('accumulated_data', [])
    if isinstance(accumulated_data, str):
        accumulated_data = [accumulated_data]

    accumulated_data.append(target_title)

    print('accumulated_data: ', accumulated_data)
    
    history = state.get("messages", [])
    history.append({"role": "assistant", "content": result})
    
    # LLMì´ ìƒì„±í•œ JSON íŒŒì‹± ë° íŒŒì¼ ì €ì¥
    completed_content = None
    try:
        print(f"ğŸ” [ë””ë²„ê¹…] JSON íŒŒì‹± ì‹œì‘, result ê¸¸ì´: {len(result) if result else 0}")
        
        # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±° (```json ... ``` í˜•ì‹ì¼ ê²½ìš°)
        json_text = result.strip()
        if json_text.startswith('```'):
            lines = json_text.split('\n')
            # ì²« ì¤„ê³¼ ë§ˆì§€ë§‰ ì¤„ ì œê±° (```json, ```)
            json_text = '\n'.join(lines[1:-1]) if len(lines) > 2 and lines[-1].strip() == '```' else '\n'.join(lines[1:])
        
        # JSON íŒŒì‹±
        completed_content = json.loads(json_text)
        print(f"âœ… JSON íŒŒì‹± ì™„ë£Œ: {len(completed_content.get('content', []))}ê°œ ë¬¸ë‹¨")
        
        # íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì • (get_json_file_path í•¨ìˆ˜ ì¬ì‚¬ìš©)
        save_path = get_json_file_path()
        
        # ì ˆëŒ€ ê²½ë¡œ ëª…í™•íˆ ì¶œë ¥
        absolute_path = save_path.resolve()
        print(f"ğŸ’¾ [ì €ì¥ ì „] íŒŒì¼ ê²½ë¡œ (ìƒëŒ€): {save_path}")
        print(f"ğŸ’¾ [ì €ì¥ ì „] íŒŒì¼ ê²½ë¡œ (ì ˆëŒ€): {absolute_path}")
        print(f"ğŸ’¾ [ì €ì¥ ì „] íŒŒì¼ ì¡´ì¬: {save_path.exists()}")
        if save_path.exists():
            with open(save_path, 'r', encoding='utf-8') as f:
                old_content = json.load(f)
            old_para_count = len(old_content.get('content', []))
            print(f"ğŸ’¾ [ì €ì¥ ì „] ê¸°ì¡´ paragraph ê°œìˆ˜: {old_para_count} (ë®ì–´ì“°ê¸° ì˜ˆì •)")
        else:
            print(f"ğŸ’¾ [ì €ì¥ ì „] íŒŒì¼ ì—†ìŒ (ìƒˆë¡œ ìƒì„±)")
        
        # ìƒˆ paragraphë“¤ì˜ paragraphIndexê°€ 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ë³´ì¥
        for i, para in enumerate(completed_content.get('content', [])):
            if 'attrs' not in para:
                para['attrs'] = {}
            if 'paragraphIndex' not in para['attrs']:
                para['attrs']['paragraphIndex'] = i
            if 'textAlign' not in para['attrs']:
                para['attrs']['textAlign'] = 'left'
        
        # JSON íŒŒì¼ ì €ì¥ (ë®ì–´ì“°ê¸°)
        print(f"ğŸ’¾ [ì €ì¥ ì‹œë„] paragraph ê°œìˆ˜: {len(completed_content.get('content', []))}")
        if completed_content.get('content'):
            first_para_text = completed_content['content'][0].get('content', [{}])[0].get('text', '')[:50] if completed_content['content'][0].get('content') else ''
            print(f"ğŸ’¾ [ì €ì¥ ì‹œë„] ì²« ë²ˆì§¸ paragraph í…ìŠ¤íŠ¸: {first_para_text}...")
        
        try:
            # íŒŒì¼ ë®ì–´ì“°ê¸° ëª¨ë“œë¡œ ì €ì¥ ('w' ëª¨ë“œëŠ” ìë™ìœ¼ë¡œ ë®ì–´ì“°ê¸°)
            print(f"ğŸ’¾ [ì €ì¥ ì‹œì‘] ê²½ë¡œ: {absolute_path}")
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(completed_content, f, ensure_ascii=False, indent=2)
                # íŒŒì¼ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
                f.flush()
                import os
                if hasattr(f, 'fileno'):
                    try:
                        os.fsync(f.fileno())
                    except:
                        pass
            print(f"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {absolute_path}")
        except Exception as save_error:
            print(f"âŒ [ì €ì¥ ì‹¤íŒ¨] ì˜¤ë¥˜: {save_error}")
            print(f"âŒ [ì €ì¥ ì‹¤íŒ¨] ê²½ë¡œ: {absolute_path}")
            import traceback
            print(f"ğŸ” [ì €ì¥ ì‹¤íŒ¨ ìƒì„¸] {traceback.format_exc()}")
            raise
        
        # ì €ì¥ í›„ íŒŒì¼ ë‚´ìš© ê²€ì¦
        import time
        time.sleep(0.1)  # íŒŒì¼ ì‹œìŠ¤í…œ ë™ê¸°í™” ëŒ€ê¸°
        
        if save_path.exists():
            with open(save_path, 'r', encoding='utf-8') as f:
                saved_content = json.load(f)
            saved_para_count = len(saved_content.get('content', []))
            saved_first_text = ''
            if saved_content.get('content') and saved_content['content'][0].get('content'):
                saved_first_text = saved_content['content'][0]['content'][0].get('text', '')[:50]
            
            print(f"âœ… [ì €ì¥ í›„ ê²€ì¦] íŒŒì¼ ê²½ë¡œ: {absolute_path}")
            print(f"âœ… [ì €ì¥ í›„ ê²€ì¦] íŒŒì¼ paragraph ê°œìˆ˜: {saved_para_count}")
            print(f"âœ… [ì €ì¥ í›„ ê²€ì¦] ì²« ë²ˆì§¸ paragraph í…ìŠ¤íŠ¸: {saved_first_text}...")
            print(f"âœ… [ì €ì¥ í›„ ê²€ì¦] íŒŒì¼ í¬ê¸°: {save_path.stat().st_size} bytes")
            
            # ë‚´ìš© ì¼ì¹˜ í™•ì¸ (ë®ì–´ì“°ê¸°ëœ ë‚´ìš© ê¸°ì¤€)
            expected_count = len(completed_content.get('content', []))
            if saved_para_count == expected_count:
                print(f"âœ… [ì €ì¥ í›„ ê²€ì¦] paragraph ê°œìˆ˜ ì¼ì¹˜! (ì˜ˆìƒ: {expected_count}ê°œ, ì‹¤ì œ: {saved_para_count}ê°œ)")
                print(f"âœ… [ì €ì¥ í›„ ê²€ì¦] âœ…âœ…âœ… íŒŒì¼ ë®ì–´ì“°ê¸° ì„±ê³µ! âœ…âœ…âœ…")
            else:
                print(f"âš ï¸ [ì €ì¥ í›„ ê²€ì¦] paragraph ê°œìˆ˜ ë¶ˆì¼ì¹˜: ì €ì¥ë¨={saved_para_count}, ì˜ˆìƒ={expected_count}")
        else:
            print(f"âŒ [ì €ì¥ í›„ ê²€ì¦] íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ! ì €ì¥ ì‹¤íŒ¨!")
            print(f"âŒ [ì €ì¥ í›„ ê²€ì¦] ì˜ˆìƒ ê²½ë¡œ: {absolute_path}")
        
        print(f"ğŸ” [ë””ë²„ê¹…] completedContent êµ¬ì¡°: {json.dumps(completed_content, ensure_ascii=False, indent=2)[:500]}...")
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ğŸ” [ë””ë²„ê¹…] íŒŒì‹± ì‹¤íŒ¨í•œ í…ìŠ¤íŠ¸: {result[:500]}...")
        import traceback
        print(f"ğŸ” [ë””ë²„ê¹…] íŒŒì‹± ì‹¤íŒ¨ ìƒì„¸: {traceback.format_exc()}")
        completed_content = None
    except Exception as e:
        print(f"âš ï¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ğŸ” [ë””ë²„ê¹…] ì €ì¥ ì‹¤íŒ¨ ìƒì„¸: {traceback.format_exc()}")
        # íŒŒì‹±ì€ ì„±ê³µí–ˆì§€ë§Œ ì €ì¥ ì‹¤íŒ¨í•œ ê²½ìš° completed_contentëŠ” ìœ ì§€
    
    # 4. ìƒíƒœ ë°˜í™˜
    return_value = {
        "current_query": result,
        "completedContent": completed_content,
        "messages": history,
        "target_chapter": ""
    }
    print(f"ğŸ” [ë””ë²„ê¹…] generate_draft ë°˜í™˜ê°’ - current_query ì¡´ì¬: {return_value.get('current_query') is not None}")
    print(f"ğŸ” [ë””ë²„ê¹…] generate_draft ë°˜í™˜ê°’ - completedContent ì¡´ì¬: {return_value.get('completedContent') is not None}")
    print(f"ğŸ” [ë””ë²„ê¹…] generate_draft ë°˜í™˜ê°’ - keys: {list(return_value.keys())}")
    
    return return_value