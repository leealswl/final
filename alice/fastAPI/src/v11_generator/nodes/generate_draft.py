from ..state_types import ProposalGenerationState
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import logging
import json
import os
from pathlib import Path


def _extract_relevant_guide(guide_data: dict, chapter_number: str, chapter_title: str) -> str:
    """
    guide_claude.jsonì—ì„œ ëª©ì°¨ ë²ˆí˜¸/ì œëª©ì— ë§ëŠ” ê°€ì´ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        guide_data: ë¡œë“œëœ guide JSON ë°ì´í„°
        chapter_number: ëª©ì°¨ ë²ˆí˜¸ (ì˜ˆ: "1", "2", "2.1")
        chapter_title: ëª©ì°¨ ì œëª©

    Returns:
        í•´ë‹¹ ëª©ì°¨ì— ëŒ€í•œ ê°€ì´ë“œ í…ìŠ¤íŠ¸
    """
    try:
        # integrated_business_proposal_guideì—ì„œ ì„¹ì…˜ ì°¾ê¸°
        guide_root = guide_data.get("integrated_business_proposal_guide", {})

        # ëª©ì°¨ ë²ˆí˜¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¹ì…˜ í‚¤ ë§¤í•‘
        section_mapping = {
            "1": "section_01_basic_info",
            "2": "section_02_current_status",
            "3": "section_03_preparation_plan",
            "4": "section_04_goals_and_requirements",
            "5": "section_05_business_feasibility",
            "6": "section_06_budget",
            "7": "section_07_evaluation_criteria"
        }

        # ì£¼ìš” ì„¹ì…˜ ë²ˆí˜¸ ì¶”ì¶œ (2.1 -> 2)
        main_section_num = chapter_number.split('.')[0] if '.' in chapter_number else chapter_number
        section_key = section_mapping.get(main_section_num)

        if section_key and section_key in guide_root:
            section_data = guide_root[section_key]

            # ê°€ì´ë“œ í…ìŠ¤íŠ¸ êµ¬ì„±
            guide_text = f"## {section_data.get('section_name', '')}\n\n"

            # R&D ê³„íšì„œ ì°¸ì¡°
            if 'rd_plan_reference' in section_data:
                guide_text += f"**R&D ì°¸ì¡°**: {section_data['rd_plan_reference']}\n"

            # SW RFP ì°¸ì¡°
            if 'sw_rfp_reference' in section_data:
                guide_text += f"**SW RFP ì°¸ì¡°**: {section_data['sw_rfp_reference']}\n\n"

            # ì£¼ìš” í‚¤ì›Œë“œ
            if 'common_keywords' in section_data:
                guide_text += f"**í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join(section_data['common_keywords'])}\n\n"

            # ë‚˜ë¨¸ì§€ ì„¹ì…˜ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì¶”ê°€
            guide_text += "### ìƒì„¸ ê°€ì´ë“œ\n"
            guide_text += json.dumps(section_data, ensure_ascii=False, indent=2)

            return guide_text
        else:
            # ë§¤ì¹­ë˜ëŠ” ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì‘ì„± íŒ ë°˜í™˜
            tips = guide_root.get("writing_tips_and_warnings", {}).get("common_tips", [])
            if tips:
                return f"ì¼ë°˜ ì‘ì„± ì§€ì¹¨:\n" + "\n".join(f"- {item}" for item in tips)
            else:
                return "í•´ë‹¹ ëª©ì°¨ì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        print(f"âš ï¸ ê°€ì´ë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return "ê°€ì´ë“œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


def generate_proposal_draft(state: ProposalGenerationState) -> ProposalGenerationState:
    """
    [ì‘ê°€ ë…¸ë“œ - ë¹„í™œì„±í™” ìƒíƒœ]
    í˜„ì¬ëŠ” ì´ˆì•ˆ ìƒì„± ë¡œì§ì„ ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ë§‰ì•„ë‘ì—ˆìŠµë‹ˆë‹¤.
    í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë”ë¯¸(Dummy) ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print("--- ë…¸ë“œ ì‹¤í–‰: generate_proposal_draft (í˜„ì¬ ë¹„í™œì„±í™”ë¨) ---")
    logging.info(f"ğŸ“ generate_draft ë…¸ë“œ ì‹¤í–‰ (Skipped)")

    DRAFT_PROMPT = """
        ë‹¹ì‹ ì€ í•œêµ­ ì •ë¶€ RFP(ì œì•ˆìš”ì²­ì„œ)Â·ì…ì°°Â·ì§€ì›ì‚¬ì—… ì œì•ˆì„œ ì‘ì„± ì „ë¬¸ê°€ì´ë©°,
        ì‹¤ì œ í‰ê°€ ì‹¬ì‚¬ìœ„ì›ì´ ì½ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ê³µì‹ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë¬¸ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

        ======================================================================
        ğŸ“Œ <ì…ë ¥ ì •ë³´>
        1. ì‘ì„± ëŒ€ìƒ ëª©ì°¨ (Target Section)
        - "{target_chapter_info}"

        2. ê³µê³ ë¬¸ í•µì‹¬ ë¶„ì„ ìš”ì•½ (Key Guidelines Summary)
        - "{anal_guide_summary}"

        3. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì‚¬ìš©ì ì •ë³´ (Collected Data)
        - {collected_data}

        4. ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ (Recent Chat History)
        - {recent_history}

        5. ì œì•ˆì„œ ì‘ì„± ê°€ì´ë“œ (Writing Guide Reference)
        - {guide_reference}
        ======================================================================

        âœï¸ <ì‘ì„± ì§€ì¹¨>
        - ìœ„ ë‹¤ì„¯ ê°€ì§€ ì…ë ¥ ì •ë³´ë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ **ì •ë¶€ ì œì•ˆì„œ ê³µì‹ ë¬¸ì²´ë¡œ í•´ë‹¹ ëª©ì°¨ì˜ ì™„ì„±ëœ ë‹¨ë½**ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        - **ì œì•ˆì„œ ì‘ì„± ê°€ì´ë“œ**ì— ëª…ì‹œëœ í•´ë‹¹ ëª©ì°¨ì˜ ì‘ì„± ìš”ë ¹, í•µì‹¬ í¬ì¸íŠ¸, í•„ìˆ˜ í¬í•¨ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.
        - ê°€ì´ë“œì— ì œì‹œëœ í‘œ í˜•ì‹, ì¸¡ì • ë°©ë²•, ì •ëŸ‰ì  ì§€í‘œ, ì˜ˆì‹œ ë“±ì˜ ìš”êµ¬ì‚¬í•­ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì‹­ì‹œì˜¤.
        - ë¬¸ë‹¨ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ê°œì¡°ì‹ ë‚˜ì—´ì´ í•„ìš”í•œ ê²½ìš° ì ì ˆíˆ í˜¼í•©í•˜ì‹­ì‹œì˜¤.
        - ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•œ ì˜ì—­ì´ ìˆì–´ë„ ì¶”ë¡  ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì™„í•˜ì‹­ì‹œì˜¤.
        - ë‹¨ìˆœ ìš”ì•½ì´ë‚˜ ë‚˜ì—´ì´ ì•„ë‹Œ **ë…¼ë¦¬ì  êµ¬ì¡°(ë°°ê²½ â†’ í•„ìš”ì„± â†’ ëª©ì  â†’ ê·¼ê±° â†’ ê¸°ëŒ€íš¨ê³¼ ë“±)**ë¡œ ì„¤ë“ë ¥ ìˆê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        - ê³µê³ ë¬¸ ìš”êµ¬ì‚¬í•­ê³¼ì˜ ì í•©ì„±ì„ ëª…í™•í•˜ê²Œ ë“œëŸ¬ë‚´ì‹­ì‹œì˜¤.
        - í‰ê°€ìœ„ì›ì´ ì½ì„ ë•Œ **ì‚¬ì—…ì˜ íƒ€ë‹¹ì„±, ì‹¤í˜„ ê°€ëŠ¥ì„±, ê³µê³µì„±, í˜ì‹ ì„±, ê¸°ëŒ€ ì„±ê³¼**ê°€ ê°•ì¡°ë˜ë„ë¡ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        - 'ìš°ë¦¬ëŠ”', 'ì €í¬ëŠ”' ê°™ì€ í‘œí˜„ ëŒ€ì‹  **ê¸°ì—…ëª… ë˜ëŠ” ì‚¬ì—… ì£¼ì²´ë¥¼ 3ì¸ì¹­ìœ¼ë¡œ ê¸°ìˆ **í•˜ì‹­ì‹œì˜¤.

        ğŸ“Œ <ì¶œë ¥ í˜•ì‹>
        ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ì¶œë ¥í•˜ì‹­ì‹œì˜¤:
        ----------------------------------------------------------------------
        <ì‘ì„±ëœ ì œì•ˆì„œ ë³¸ë¬¸>\n
        (ì—¬ê¸°ì— ìµœì¢… ì‘ì„± ë¬¸ë‹¨ì„ ë„£ìœ¼ì‹­ì‹œì˜¤)
        \n----------------------------------------------------------------------
        """
    
    # 1. guide_claude.json ë¡œë“œ
    guide_data = {}
    guide_reference = "ê°€ì´ë“œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    try:
        # í˜„ì¬ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ guide í´ë” ê²½ë¡œ ì°¾ê¸°
        current_dir = Path(__file__).parent
        guide_path = current_dir.parent / "guide" / "guide_claude.json"

        if guide_path.exists():
            with open(guide_path, 'r', encoding='utf-8') as f:
                guide_data = json.load(f)
                print(f"âœ… guide_claude.json ë¡œë“œ ì„±ê³µ: {guide_path}")
        else:
            print(f"âš ï¸ guide_claude.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {guide_path}")
    except Exception as e:
        print(f"âš ï¸ guide_claude.json ë¡œë“œ ì˜¤ë¥˜: {e}")

    # 2. í˜„ì¬ ëª©í‘œ ì„¹ì…˜ ì •ë³´ ì„¤ì • (history_checkerì˜ ê²°ì • ë°˜ì˜ ë¡œì§)
    collected_data = state.get("collected_data", "")
    # print('collected_data: ', collected_data)
    # print(f"--- ğŸ“Š ASSESS_INFO ìˆ˜ì‹  ë°ì´í„° ê¸¸ì´: {len(collected_data)}ì ---")

    toc_structure = state.get("draft_toc_structure", [])
    target_title = state.get("target_chapter", "")
    current_idx = state.get("current_chapter_index", 0)

    fetched_context = state.get("fetched_context", {})
    anal_guide_summary = str(fetched_context.get("anal_guide", "ì „ëµ ì •ë³´ ì—†ìŒ"))

    if toc_structure and current_idx < len(toc_structure):
        major_chapter_item = toc_structure[current_idx]
        major_chapter_number = major_chapter_item.get("number", "0")
        major_chapter_title = major_chapter_item.get("title", "ì œëª© ì—†ìŒ")

        # 2-1. LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  ì£¼ ì±•í„° ì •ë³´ êµ¬ì„±
        chapter_display = f"{major_chapter_item.get('number')} {major_chapter_item.get('title')}"
        target_info_full = f"[{chapter_display}]\nì„¤ëª…: {major_chapter_item.get('description')}"

        print('target_info_full: ', target_info_full)

        # 2-2. ê°€ì´ë“œì—ì„œ í•´ë‹¹ ëª©ì°¨ì— ë§ëŠ” ì„¹ì…˜ ì°¾ê¸°
        if guide_data:
            guide_reference = _extract_relevant_guide(guide_data, major_chapter_number, major_chapter_title)
            print(f"ğŸ“š ì¶”ì¶œëœ ê°€ì´ë“œ ê¸¸ì´: {len(guide_reference)}ì")

    msgs = state.get("messages", [])
    recent_history = ""
    if msgs:
        for msg in msgs:
            role = "ğŸ‘¤" if msg.get("role") == "user" else "ğŸ¤–"
            content = msg.get("content", "")
            recent_history += f"{role}: {content}\n"


    prompt = PromptTemplate.from_template(DRAFT_PROMPT)

    llm = None
    try:
        llm = ChatOpenAI(temperature=0, model="gpt-4o")
    except Exception as e:
        print(f"âš ï¸ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

    chain = prompt | llm | StrOutputParser()

    result = chain.invoke({
        'target_chapter_info': target_info_full,
        'anal_guide_summary': anal_guide_summary,
        'collected_data': collected_data,
        'recent_history': recent_history,
        'guide_reference': guide_reference
        })
    
    # ë§Œì•½ accumulated_dataê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    accumulated_data = state.get('accumulated_data', [])
    if isinstance(accumulated_data, str):
        accumulated_data = [accumulated_data]

    accumulated_data.append(target_title)

    print('accumulated_data: ', accumulated_data)
    
    history = state.get("messages", [])
    history.append({"role": "assistant", "content": result})
    # 4. ìƒíƒœ ë°˜í™˜
    return {
        "current_query": result,
        "messages": history,
        "target_chapter": ""
    }