from .state_types2 import ProposalGenerationState
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from typing import List
import re
from langgraph.graph import StateGraph, END, START

llm = ChatOpenAI(model='gpt-4o-mini')


# ì§ˆë¬¸ ëª©ë¡ ì¶”ì¶œ í•¨ìˆ˜
def parse_questions(result_text: str) -> List[str]:
    """
    LLM ì¶œë ¥(result_text)ì—ì„œ [ì§ˆë¬¸ ëª©ë¡] ë¸”ë¡ë§Œ ì¶”ì¶œí•˜ì—¬
    bullet í˜•íƒœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸(List[str])ë¡œ ë³€í™˜
    """
    pattern = r"\[ì§ˆë¬¸ ëª©ë¡\](.*?)(?=\n\[|$)"
    match = re.search(pattern, result_text, re.DOTALL)

    if not match:
        return []

    question_block = match.group(1).strip()

    questions = []
    for line in question_block.split("\n"):
        line = line.strip()
        if line.startswith("- "):
            questions.append(line[2:].strip())
    
    return questions


def load_data(state: ProposalGenerationState) -> ProposalGenerationState:
    print("ë…¸ë“œ ì‹¤í–‰: load_data")

    # Checkpointerê°€ ë³µì›í•œ ê¸°ì¡´ íˆìŠ¤í† ë¦¬
    history = state.get("messages", [])
    
    # ìƒˆ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    if state.get("user_prompt"):
        user_msg = {"role": "user", "content": state["user_prompt"]}
        history.append(user_msg)

    context_data = state.get("fetched_context", {})

    # ëª©ì°¨ êµ¬ì¡° ì¶”ì¶œ ë° ì •ë¦¬
    result_toc = context_data.get('result_toc', {})
    toc_structure = result_toc.get("sections", [])

    anal_guide = context_data.get('anal_guide', [])
    generation_strategy = [
        item.get("writing_strategy")
        for item in anal_guide
        if "writing_strategy" in item
    ]

    print('generation_strategy: ', generation_strategy)

    # ê¸°ì¡´ ìƒíƒœ ìœ ì§€í•˜ë©´ì„œ í•„ìš”í•œ ê²ƒë§Œ ì—…ë°ì´íŠ¸
    update = {
        'messages': history
    }
    
    # draft_toc_structureê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ ì„¤ì • (ìµœì´ˆ 1íšŒ)
    if not state.get("draft_toc_structure"):
        update["draft_toc_structure"] = toc_structure
    
    # guideê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ ì„¤ì • (ìµœì´ˆ 1íšŒ)
    if not state.get("guide"):
        update["guide"] = generation_strategy

    return update


def select_chapter(state: ProposalGenerationState) -> ProposalGenerationState:
    print("ë…¸ë“œ ì‹¤í–‰: select_chapter")
    
    current_target = state.get("target_chapter", "")
    completed_chapters = state.get("completed_chapters", [])
    
    print(f"í˜„ì¬ ì„ íƒëœ ëª©ì°¨: {current_target}")
    print(f"ì™„ë£Œëœ ëª©ì°¨ë“¤: {completed_chapters}")
    
    # ğŸ’¡ í•µì‹¬ ìˆ˜ì •: í˜„ì¬ ëª©ì°¨ê°€ ìˆê³ , ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì ˆëŒ€ ë°”ê¾¸ì§€ ì•ŠìŒ
    if current_target and current_target not in completed_chapters and "NONE" not in current_target:
        print(f"ğŸ”’ ëª©ì°¨ '{current_target}' ì‘ì—… ì§„í–‰ ì¤‘ - ë³€ê²½ ì•ˆí•¨")
        return {}  # ìƒíƒœ ë³€ê²½ ì—†ìŒ
    
    # ğŸ’¡ ìƒˆë¡œìš´ ëª©ì°¨ ì„ íƒì´ í•„ìš”í•œ ê²½ìš° (write ì™„ë£Œ í›„ì—ë§Œ ì‹¤í–‰ë¨)
    print("ğŸ”„ ìƒˆë¡œìš´ ëª©ì°¨ ì„ íƒ ì‹œì‘")
    
    select_chapter_template = '''
    ë‹¹ì‹ ì€ ì‚¬ì—…ê³„íšì„œ ì‘ì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

    ë‹¤ìŒì€ ì „ì²´ ëª©ì°¨ ëª©ë¡ì…ë‹ˆë‹¤:
    {chapter_data}

    ë‹¤ìŒì€ ì´ë¯¸ ì™„ë£Œëœ ëª©ì°¨ ëª©ë¡ì…ë‹ˆë‹¤:
    {completed_chapters}

    ë‹¤ìŒì€ ì‚¬ìš©ìì™€ì˜ ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬ì…ë‹ˆë‹¤:
    {history}

    í˜„ì¬ê¹Œì§€ ì‘ì„±ëœ ë‚´ìš© ë˜ëŠ” ì‚¬ìš©ìì™€ì˜ ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•˜ì—¬,
    "ë‹¤ìŒì— ì‘ì„±í•´ì•¼ í•  ì •í™•í•œ ëª©ì°¨ í•œ ê°œ"ë¥¼ ì„ íƒí•˜ì‹­ì‹œì˜¤.

    ì„ íƒ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    1. **ì™„ë£Œëœ ëª©ì°¨ëŠ” ì ˆëŒ€ ì„ íƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
    2. ìƒìœ„ â†’ í•˜ìœ„ ìˆœì„œì— ë”°ë¼ ì‘ì„± ë‹¨ê³„ê°€ ì§„í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    3. ì•„ì§ ì‘ì„±ë˜ì§€ ì•Šì€ ëª©ì°¨ ì¤‘ ê°€ì¥ ë¨¼ì € ë“±ì¥í•˜ëŠ” í•­ëª©ì„ ì„ íƒí•©ë‹ˆë‹¤.

    ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:

    [ì„ íƒëœ ëª©ì°¨]
    <ëª©ì°¨ ì´ë¦„>

    [ì„ íƒ ì´ìœ ]
    <ê°„ë‹¨í•œ ì´ìœ >

    ë§Œì•½ ëª¨ë“  ëª©ì°¨ ì‘ì„±ì´ ì™„ë£Œë˜ì—ˆë‹¤ê³  íŒë‹¨ë˜ë©´:

    [ì„ íƒëœ ëª©ì°¨]
    NONE

    [ì„ íƒ ì´ìœ ]
    ëª¨ë“  ëª©ì°¨ê°€ ì‘ì„± ì™„ë£Œë¨
    '''

    select_chapter_prompt = ChatPromptTemplate.from_template(select_chapter_template)
    select_chapter_chain = select_chapter_prompt | llm | StrOutputParser()
    result = select_chapter_chain.invoke({
        'chapter_data': state['draft_toc_structure'],
        'completed_chapters': completed_chapters,
        'history': state['messages']
    })

    print(f"ğŸ†• ìƒˆë¡œ ì„ íƒëœ ëª©ì°¨: {result}")

    return {'target_chapter': result}


def check_need_question(state: ProposalGenerationState) -> ProposalGenerationState:
    print("ë…¸ë“œ ì‹¤í–‰: check_need_question")
    
    current_target = state.get("target_chapter", "")
    pending = state.get("pending_questions", [])
    answered = state.get("answered_questions", [])
    
    # ğŸ’¡ ë‚¨ì€ ì§ˆë¬¸ ê³„ì‚°
    remaining_questions = [q for q in pending if q not in answered]
    
    print(f"ğŸ“Š ì§ˆë¬¸ í˜„í™©:")
    print(f"  - ì „ì²´ ì§ˆë¬¸: {len(pending)}ê°œ")
    print(f"  - ë‹µë³€ ì™„ë£Œ: {len(answered)}ê°œ")
    print(f"  - ë‚¨ì€ ì§ˆë¬¸: {len(remaining_questions)}ê°œ")
    
    # ğŸ’¡ ì¼€ì´ìŠ¤ 1: ì§ˆë¬¸ ëª©ë¡ì´ ì´ë¯¸ ìˆê³ , ë‚¨ì€ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ê³„ì† ì§ˆë¬¸
    if pending and remaining_questions:
        print(f"âœ… ê¸°ì¡´ ì§ˆë¬¸ ëª©ë¡ ì‚¬ìš© (ë‚¨ì€ ì§ˆë¬¸: {len(remaining_questions)}ê°œ)")
        return {'sufficiency': False}
    
    # ğŸ’¡ ì¼€ì´ìŠ¤ 2: ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€ ì™„ë£Œ â†’ writeë¡œ ì´ë™
    if pending and not remaining_questions:
        print(f"âœ… ëª¨ë“  ì§ˆë¬¸ ë‹µë³€ ì™„ë£Œ â†’ write ë…¸ë“œë¡œ ì´ë™")
        return {'sufficiency': True}
    
    # ğŸ’¡ ì¼€ì´ìŠ¤ 3: ì§ˆë¬¸ ëª©ë¡ì´ ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±
    print("ğŸ”„ ìƒˆë¡œìš´ ì§ˆë¬¸ ëª©ë¡ ìƒì„± ì‹œì‘")
    
    check_template = '''
    ë‹¹ì‹ ì€ ì‚¬ì—…ê³„íšì„œ ì‘ì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

    [ì„ íƒëœ ëª©ì°¨]
    {chapter}

    [ì‚¬ìš©ìì™€ì˜ ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬]
    {history}

    [ë„ë©”ì¸ ì§€ì‹]
    {domain}

    ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìœ„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,
    ì„ íƒëœ ëª©ì°¨ì— ëŒ€í•œ ë³¸ë¬¸ì„ ì‘ì„±í•˜ê¸° ì „ì— 
    "ì¶”ê°€ ì§ˆì˜ê°€ í•„ìš”í•œì§€ ì—¬ë¶€"ë¥¼ ì •í™•íˆ íŒë‹¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    íŒë‹¨ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

    1. í•´ë‹¹ ëª©ì°¨ë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•´ í•„ìˆ˜ ìš”ì†Œë“¤ì´ ì¶©ë¶„íˆ í™•ë³´ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    2. ë¶€ì¡±í•œ ì •ë³´ê°€ ìˆë‹¤ë©´,  
    - ì–´ë–¤ ì •ë³´ê°€ ë¶€ì¡±í•œì§€ ë¶„ì„í•˜ê³   
    - ê·¸ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

    3. í•„ìš”í•œ ì •ë³´ê°€ ì´ë¯¸ ì¶©ë¶„í•˜ë‹¤ë©´  
    - ì§ˆë¬¸ì´ í•„ìš”í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.

    ì¶œë ¥ í˜•ì‹:

    [ê²°ë¡ ]
    ASK or NO_ASK

    [ë¶€ì¡±í•œ ì •ë³´ ë¶„ì„]
    - ì–´ë–¤ ì •ë³´ê°€ ë¶€ì¡±í•œì§€ ë˜ëŠ” ì¶©ë¶„í•œì§€ ì„¤ëª…

    [ì§ˆë¬¸ ëª©ë¡]
    - ì¶”ê°€ ì§ˆë¬¸ì´ í•„ìš”í•œ ê²½ìš°: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ bullet í˜•ì‹ìœ¼ë¡œ ë‚˜ì—´  
    - ì§ˆë¬¸ì´ í•„ìš”í•˜ì§€ ì•Šë‹¤ë©´: NONE
    '''

    check_prompt = ChatPromptTemplate.from_template(check_template)
    check_chain = check_prompt | llm | StrOutputParser()
    result = check_chain.invoke({
        'domain': state.get('domain', ''),
        'chapter': current_target,
        'history': state['messages']
    })

    print('check_need_question result: ', result)
    questions = parse_questions(result)
    print('ì¶”ì¶œëœ ì§ˆë¬¸ë“¤: ', questions)

    # ASK íŒë‹¨ ë¡œì§
    if "ASK" in result and "[ê²°ë¡ ]" in result:
        result_lines = result.split('\n')
        for i, line in enumerate(result_lines):
            if '[ê²°ë¡ ]' in line and i + 1 < len(result_lines):
                decision = result_lines[i + 1].strip()
                if decision == "ASK":
                    print(f"ğŸ”„ ì§ˆë¬¸ í•„ìš” â†’ {len(questions)}ê°œ ì§ˆë¬¸ ìƒì„±")
                    return {
                        'sufficiency': False, 
                        'pending_questions': questions,
                        'answered_questions': []  # ì´ˆê¸°í™”
                    }
    
    print("âœ… ì§ˆë¬¸ ë¶ˆí•„ìš” â†’ ë°”ë¡œ writeë¡œ ì´ë™")
    return {"sufficiency": True}


def router_ask_write(state: ProposalGenerationState) -> str:
    return 'write' if state.get('sufficiency') else "ask"


def question(state: ProposalGenerationState) -> ProposalGenerationState:
    print("ë…¸ë“œ ì‹¤í–‰: question")

    history = state.get("messages", [])
    pending = state.get("pending_questions", [])
    answered = state.get("answered_questions", [])

    # ğŸ’¡ ì•„ì§ ë‹µë³€ë°›ì§€ ì•Šì€ ì§ˆë¬¸ í•„í„°ë§
    remaining_questions = [q for q in pending if q not in answered]

    if not remaining_questions:
        print("âš ï¸ ì§ˆë¬¸ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        return {'generated_text': "ì§ˆë¬¸ì´ ë” ì´ìƒ ì—†ìŠµë‹ˆë‹¤."}

    print(f"ğŸ“‹ ë‚¨ì€ ì§ˆë¬¸ ê°œìˆ˜: {len(remaining_questions)}")

    question_template = '''
    [ì§ˆë¬¸ ëª©ë¡]
    {question_list}

    [ì‚¬ìš©ìì™€ì˜ ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬]
    {history}

    ë‹¹ì‹ ì€ 'ì‚¬ì—…ê³„íšì„œ ì‘ì„± ë³´ì¡° ì—ì´ì „íŠ¸'ì…ë‹ˆë‹¤.

    ### ğŸ” ì§ˆë¬¸ ì„ íƒ ê¸°ì¤€
    1. **ì´ë¯¸ íˆìŠ¤í† ë¦¬ì—ì„œ ì§ˆë¬¸ë˜ì—ˆê±°ë‚˜ ë‹µë³€ëœ í•­ëª©ì€ ì œì™¸í•©ë‹ˆë‹¤.**
    2. **ë‚¨ì€ ì§ˆë¬¸ ì¤‘ 'í˜„ì¬ ì •ë³´ íë¦„ì—ì„œ ê°€ì¥ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ì§ˆë¬¸'ì„ ì„ íƒí•©ë‹ˆë‹¤.**
    3. **ì§ˆë¬¸ì€ ë°˜ë“œì‹œ 'ì§ˆë¬¸ ëª©ë¡ì— ìˆëŠ” ë¬¸ì¥ ê·¸ëŒ€ë¡œ' ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.**

    ### ì¶œë ¥ í˜•ì‹
    (ì„ íƒëœ ì§ˆë¬¸ í•œ ë¬¸ì¥ë§Œ ì¶œë ¥)
    '''

    question_prompt = ChatPromptTemplate.from_template(question_template)
    question_chain = question_prompt | llm | StrOutputParser()
    result = question_chain.invoke({
        'question_list': remaining_questions,
        'history': history
    })
    
    print('âœ… ì„ íƒëœ ì§ˆë¬¸: ', result)

    # íˆìŠ¤í† ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
    history.append({"role": "assistant", "content": result})
    
    # ğŸ’¡ ì´ ì§ˆë¬¸ì„ answeredì— ì¶”ê°€
    answered_copy = answered.copy()
    answered_copy.append(result.strip())

    return {
        'generated_text': result,
        'messages': history,
        'answered_questions': answered_copy
    }


def write(state: ProposalGenerationState) -> ProposalGenerationState:
    print("ë…¸ë“œ ì‹¤í–‰: write")
    
    write_template = '''
    ë‹¹ì‹ ì€ ì „ë¬¸ ì‚¬ì—…ê³„íšì„œ ì‘ì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ íƒëœ ëª©ì°¨ì— ëŒ€í•œ ì‚¬ì—…ê³„íšì„œ ë³¸ë¬¸ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    [ì‚¬ìš©ìì™€ì˜ ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬]
    {history}

    [ë„ë©”ì¸ ì§€ì‹]
    {domain}

    [ì‘ì„±í•  ëª©ì°¨]
    {chapter}

    [ì‚¬ì—…ê³„íšì„œ ì‘ì„± ê°€ì´ë“œ]
    {guide}

    ì‘ì„± ê·œì¹™:
    1. ì„ íƒëœ ëª©ì°¨ì˜ ëª©ì ì— ì •í™•íˆ ë¶€í•©í•˜ëŠ” ë‚´ìš©ë§Œ ì‘ì„±
    2. ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬ì™€ ë„ë©”ì¸ ì§€ì‹ì„ ë©´ë°€íˆ ë¶„ì„
    3. ì‚¬ì—…ê³„íšì„œ ì‘ì„± ê°€ì´ë“œì˜ í˜•ì‹Â·í†¤Â·êµ¬ì¡°ë¥¼ ì¤€ìˆ˜
    4. ì „ë¬¸ê°€ í†¤ ìœ ì§€, ëª…í™•í•œ ê·¼ê±° ë° ë…¼ë¦¬ íë¦„

    ìµœì¢… ì¶œë ¥ í˜•ì‹:
    [ë³¸ë¬¸]
    (í•´ë‹¹ ëª©ì°¨ì˜ ì™„ì„±ëœ ì‚¬ì—…ê³„íšì„œ ë³¸ë¬¸)
    '''

    write_prompt = ChatPromptTemplate.from_template(write_template)
    write_chain = write_prompt | llm | StrOutputParser()
    result = write_chain.invoke({
        'domain': state.get('domain', ''),
        'history': state['messages'],
        'chapter': state['target_chapter'],
        'guide': state['guide']
    })

    # ğŸ’¡ ì‘ì„± ì™„ë£Œëœ ëª©ì°¨ë¥¼ completed_chaptersì— ì¶”ê°€
    completed = state.get("completed_chapters", []).copy()
    current_chapter = state.get("target_chapter", "")
    
    if current_chapter and current_chapter not in completed and "NONE" not in current_chapter:
        completed.append(current_chapter)
    
    print(f"âœ… ëª©ì°¨ '{current_chapter}' ì‘ì„± ì™„ë£Œ")
    print(f"ğŸ“š ì™„ë£Œëœ ëª©ì°¨ ëª©ë¡: {completed}")

    return {
        'generated_text': result,
        'completed_chapters': completed,
        'pending_questions': [],  # ğŸ’¡ ë‹¤ìŒ ëª©ì°¨ë¥¼ ìœ„í•´ ì´ˆê¸°í™”
        'answered_questions': []   # ğŸ’¡ ë‹¤ìŒ ëª©ì°¨ë¥¼ ìœ„í•´ ì´ˆê¸°í™”
    }


def create_proposal_graph() -> StateGraph:
    """
    ìƒíƒœ ì§€ì†ì„±ì„ ìœ„í•œ ê·¸ë˜í”„ ìƒì„±
    (checkpointerëŠ” FastAPIì—ì„œ AsyncSqliteSaverë¡œ ì„¤ì •)
    """
    workflow = StateGraph(ProposalGenerationState)

    workflow.add_node("load_data", load_data)
    workflow.add_node("select_chapter", select_chapter)
    workflow.add_node("check_need_question", check_need_question)
    workflow.add_node("question", question)
    workflow.add_node("write", write)

    workflow.add_edge(START, "load_data")    
    workflow.add_edge("load_data", "select_chapter")
    workflow.add_edge("select_chapter", "check_need_question") 

    workflow.add_conditional_edges(
        "check_need_question",
        router_ask_write,
        {
            "write": "write",
            "ask": "question"
        }
    )

    workflow.add_edge("write", END)
    workflow.add_edge("question", END)

    return workflow