# 워크플로우 수정 완료 보고서

## 📋 사용자 요구사항 워크플로우

```
input (채팅) → start
                |
        LLM 판단
        /      \
   생성 경로    질문 경로
   |            |
   채팅히스토리+  질문 생성
   목차+가이드+  |
   도메인지식   |
   |            |
   본문생성     |
   |            |
   end ←--------┘
   |
   채팅으로 출력
   |
   질문에 대한 답변 input
   |
   start로 다시
```

## ✅ 구현 완료 사항

### 1. 새로운 노드 추가: `llm_decision_router.py`
- **위치**: `alice/fastAPI/src/v11_generator/nodes/llm_decision_router.py`
- **기능**: start 노드에서 LLM이 판단하여 생성 경로와 질문 경로로 분기
- **판단 기준**:
  - **GENERATE**: 충분한 정보가 수집되었거나, 사용자가 직접 생성 요청한 경우
  - **ASK_QUESTION**: 추가 정보가 필요한 경우

### 2. 그래프 구조 수정: `graph_builder.py`

#### 변경 전 구조:
```
START → FETCH_CONTEXT → GENERATE_QUERY → ASK_USER → ASSESS_INFO → (생성 또는 질문 루프)
```

#### 변경 후 구조:
```
START → FETCH_CONTEXT → LLM_DECISION
                          |
        ┌─────────────────┴─────────────────┐
        |                                   |
   GENERATE_DRAFT                    GENERATE_QUERY
        |                                   |
        END                            ASK_USER
                                          |
                                    (사용자 답변)
                                          |
                                    LLM_DECISION (다시 판단)
```

### 3. 주요 수정 내용

#### `graph_builder.py`
1. **LLM_DECISION 노드 추가**
   - `FETCH_CONTEXT` 이후에 LLM 판단 노드 실행
   - 판단 결과에 따라 `GENERATE_DRAFT` 또는 `GENERATE_QUERY`로 분기

2. **ASK_USER 라우터 수정**
   - 사용자 답변을 받으면 `LLM_DECISION`으로 다시 돌아감 (start로 돌아감)
   - 사용자 입력 대기 중이면 `END`

3. **생성 경로 단순화**
   - `GENERATE_DRAFT` 후 바로 `END`로 종료
   - 생성된 본문을 채팅으로 출력

#### `generate_draft.py`
- `next_step`을 `"FINISH"`로 설정하여 종료 처리

## 🔄 새로운 워크플로우 상세

### 최초 요청 (threadId 없음)
```
1. 사용자: "기획서 작성해줘"
2. START → FETCH_CONTEXT (목차+가이드+도메인지식 로드)
3. LLM_DECISION (LLM 판단)
   - collected_data가 비어있음 → ASK_QUESTION 선택
4. GENERATE_QUERY (질문 생성)
5. ASK_USER (질문을 채팅으로 출력하고 사용자 입력 대기)
6. END (사용자 입력 대기)
```

### 사용자 답변 후 (threadId 있음)
```
1. 사용자: "우리 회사는 AI 스타트업입니다"
2. ASK_USER (사용자 답변 수신)
3. LLM_DECISION (다시 LLM 판단)
   - collected_data에 정보 추가됨 → 다시 판단
   - 정보가 충분하면 GENERATE 선택
   - 정보가 부족하면 ASK_QUESTION 선택
4. (GENERATE 선택 시) GENERATE_DRAFT → END (본문 생성 후 채팅으로 출력)
5. (ASK_QUESTION 선택 시) GENERATE_QUERY → ASK_USER (다시 질문)
```

## 🎯 핵심 개선 사항

1. **LLM 기반 동적 판단**
   - 매 턴마다 LLM이 현재 상황을 분석하여 최적의 경로 선택
   - 고정된 루프 대신 상황에 맞는 유연한 흐름

2. **단순화된 생성 경로**
   - 충분한 정보가 있으면 바로 본문 생성
   - 불필요한 확인 단계 제거

3. **순환 구조**
   - 사용자 답변을 받으면 다시 LLM 판단으로 돌아가서 재평가
   - 정보가 누적될수록 생성 가능성 증가

## 📝 주의사항

1. **LLM 판단 비용**
   - 매 턴마다 LLM 호출이 발생하므로 비용 고려 필요
   - 캐싱 또는 간소화된 판단 로직 고려 가능

2. **무한 루프 방지**
   - LLM이 계속 ASK_QUESTION을 선택하는 경우 대비
   - 최대 질문 횟수 제한 또는 강제 생성 로직 추가 고려

3. **기존 ASSESS_INFO 노드**
   - 현재는 사용하지 않지만, 필요시 다시 활성화 가능
   - LLM 판단과 함께 사용하여 이중 검증 가능

## 🧪 테스트 방법

1. **최초 요청 테스트**
   - 사용자: "기획서 작성해줘"
   - 예상: LLM이 ASK_QUESTION 선택 → 질문 생성 → 사용자 입력 대기

2. **정보 수집 테스트**
   - 사용자: "우리 회사는 AI 스타트업입니다"
   - 예상: LLM이 다시 판단 → 정보 부족 시 추가 질문, 충분 시 생성

3. **생성 테스트**
   - 충분한 정보 수집 후
   - 예상: LLM이 GENERATE 선택 → 본문 생성 → 채팅으로 출력

## ✅ 완료 체크리스트

- [x] LLM 판단 라우터 노드 생성 (`llm_decision_router.py`)
- [x] 그래프에 LLM_DECISION 노드 추가
- [x] FETCH_CONTEXT → LLM_DECISION 연결
- [x] LLM_DECISION → GENERATE_DRAFT / GENERATE_QUERY 분기
- [x] ASK_USER → LLM_DECISION 순환 구조
- [x] GENERATE_DRAFT → END 단순화
- [x] generate_draft 노드의 next_step 수정



